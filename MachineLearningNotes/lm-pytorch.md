title: lm_pytorch
date: 2024-06-29 21:14:37
tags: LLM-NOTE



# çº¿æ€§ç¥ç»ç½‘ç»œ

##  å‘é‡é“¾å¼æ³•åˆ™

- ### æ ‡é‡é“¾å¼æ³•åˆ™

[![image-20220107231957396](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-01)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-01)

- ### æ‹“å±•åˆ°å‘é‡

  > éœ€è¦æ³¨æ„ç»´æ•°çš„å˜åŒ–
  >
  > ä¸‹å›¾ä¸‰ç§æƒ…å†µåˆ†åˆ«å¯¹åº”ï¼š
  >
  > 1. yä¸ºæ ‡é‡ï¼Œxä¸ºå‘é‡
  > 2. yä¸ºæ ‡é‡ï¼Œxä¸ºçŸ©é˜µ
  > 3. yã€xä¸ºçŸ©é˜µ

[![image-20220107231931153](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-02)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-02)

------

##### ä¾‹1ï¼ˆæ ‡é‡å¯¹å‘é‡æ±‚å¯¼ï¼‰



> è¿™é‡Œåº”è¯¥æ˜¯ç”¨åˆ†å­å¸ƒå±€ï¼Œæ‰€ä»¥æ˜¯Xè½¬ç½®

 [![image-20220107233527373](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-03)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-03)

##### ä¾‹2ï¼ˆæ¶‰åŠåˆ°çŸ©é˜µçš„æƒ…å†µï¼‰



> Xæ˜¯mxnçš„çŸ©é˜µ,wä¸ºnç»´å‘é‡ï¼Œyä¸ºmç»´å‘é‡ï¼› zå¯¹Xw-yåšL2 norm,ä¸ºæ ‡é‡ï¼› è¿‡ç¨‹ä¸ä¾‹ä¸€å¤§ä½“ä¸€è‡´ï¼›

 [![image-20220107233753066](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-04)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-04)

------

> ç”±äºåœ¨ç¥ç»ç½‘ç»œåŠ¨è¾„å‡ ç™¾å±‚ï¼Œæ‰‹åŠ¨è¿›è¡Œé“¾å¼æ±‚å¯¼æ˜¯å¾ˆå›°éš¾çš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å€ŸåŠ©è‡ªåŠ¨æ±‚å¯¼

------

### è‡ªåŠ¨æ±‚å¯¼

- å«ä¹‰ï¼šè®¡ç®—ä¸€ä¸ªå‡½æ•°åœ¨æŒ‡å®šå€¼ä¸Šçš„å¯¼æ•°

- è‡ªåŠ¨æ±‚å¯¼æœ‰åˆ«äº

  - ç¬¦å·æ±‚å¯¼

    ![image-20220107235547201](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-05)

  - æ•°å€¼æ±‚å¯¼

    ![image-20220107235611767](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-06)

ä¸ºäº†æ›´å¥½åœ°ç†è§£è‡ªåŠ¨æ±‚å¯¼ï¼Œä¸‹é¢å¼•å…¥è®¡ç®—å›¾çš„æ¦‚å¿µ

#### è®¡ç®—å›¾

- å°†ä»£ç åˆ†è§£æˆæ“ä½œå­

- å°†è®¡ç®—è¡¨ç¤ºæˆä¸€ä¸ª**æ— ç¯å›¾**

  > ä¸‹å›¾è‡ªåº•å‘ä¸Šå…¶å®å°±ç±»ä¼¼äºé“¾å¼æ±‚å¯¼è¿‡ç¨‹

[![image-20220107235918270](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-07)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-07)



- è®¡ç®—å›¾æœ‰ä¸¤ç§æ„é€ æ–¹å¼

  - æ˜¾ç¤ºæ„é€ 

    > å¯ä»¥ç†è§£ä¸ºå…ˆå®šä¹‰å…¬å¼å†ä»£å€¼
    >
    > Tensorflow/Theano/MXNet

     [![image-20220108000740736](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-08)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-08)

  - éšå¼æ„é€ 

    > ç³»ç»Ÿå°†æ‰€æœ‰çš„è®¡ç®—è®°å½•ä¸‹æ¥
    >
    > Pytorch/MXNet

     [![image-20220108001154208](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-09)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-09)

#### è‡ªåŠ¨æ±‚å¯¼çš„ä¸¤ç§æ¨¡å¼

- æ­£å‘ç´¯ç§¯

   [![image-20220108001506326](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-10)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-10)

- åå‘ç´¯ç§¯ï¼ˆåå‘ä¼ é€’back propagationï¼‰

   [![image-20220108001517029](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-11)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-11)

 **åå‘ç´¯ç§¯è®¡ç®—è¿‡ç¨‹**

[![image-20220108001847175](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-12)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-12)

> åå‘ç´¯ç§¯çš„æ­£å‘è¿‡ç¨‹ï¼šè‡ªåº•å‘ä¸Šï¼Œéœ€è¦å­˜å‚¨ä¸­é—´ç»“æœ
>
> åå‘ç´¯ç§¯çš„åå‘è¿‡ç¨‹ï¼šè‡ªé¡¶å‘ä¸‹ï¼Œå¯ä»¥å»é™¤ä¸éœ€è¦çš„æï¼ˆå›¾ä¸­çš„xåº”ä¸ºwï¼‰
>
>  [![image-20220108002228166](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/07/image-13)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/07/image-13)

#### å¤æ‚åº¦æ¯”è¾ƒ

- åå‘ç´¯ç§¯

  - æ—¶é—´å¤æ‚åº¦ï¼šO(n),næ˜¯æ“ä½œå­æ•°
    - é€šå¸¸æ­£å‘å’Œåå‘çš„ä»£ä»·ç±»ä¼¼
  - ç©ºé—´å¤æ‚åº¦ï¼šO(n)
    - å­˜å‚¨æ­£å‘è¿‡ç¨‹æ‰€æœ‰çš„ä¸­é—´ç»“æœ

- æ­£å‘ç´¯ç§¯

  > æ¯æ¬¡è®¡ç®—ä¸€ä¸ªå˜é‡çš„æ¢¯åº¦æ—¶éƒ½éœ€è¦å°†æ‰€æœ‰èŠ‚ç‚¹æ‰«ä¸€é

  - æ—¶é—´å¤æ‚åº¦ï¼šO(n)
  - ç©ºé—´å¤æ‚åº¦ï¼šO(1)

### ä»£ç éƒ¨åˆ†

```
#å¯¹y = x.Txå…³äºåˆ—å‘é‡xæ±‚å¯¼
import torch

x = torch.arange(4.0)
x
```

```
tensor([0., 1., 2., 3.])
```



```
#å­˜å‚¨æ¢¯åº¦
x.requires_grad_(True)#ç­‰ä»·äºx = torch.arange(4.0,requires_grad=True)
x.grad#é»˜è®¤å€¼æ˜¯None
```

```
y = torch.dot(x,x)
y
#PyTorchéšå¼åœ°æ„é€ è®¡ç®—å›¾ï¼Œgrad_fnç”¨äºè®°å½•æ¢¯åº¦è®¡ç®—
```

```
tensor(14., grad_fn=<DotBackward0>)
```

**é€šè¿‡è°ƒç”¨åå‘ä¼ æ’­å‡½æ•°æ¥è‡ªåŠ¨è®¡ç®—yå…³äºxæ¯ä¸ªåˆ†é‡çš„æ¢¯åº¦**

```
y.backward()
x.grad
```

```
tensor([0., 2., 4., 6.])
```



```
x.grad==2*x#éªŒè¯
```

```
tensor([True, True, True, True])
```



```
# åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼ŒPyTorchä¼šç´¯ç§¯æ¢¯åº¦ï¼Œæˆ‘ä»¬éœ€è¦æ¸…é™¤ä¹‹å‰çš„å€¼
x.grad.zero_()#å¦‚æœæ²¡æœ‰è¿™ä¸€æ­¥ç»“æœå°±ä¼šåŠ ç´¯ä¸Šä¹‹å‰çš„æ¢¯åº¦å€¼ï¼Œå˜ä¸º[1,5,9,13]
y = x.sum()
y.backward()
x.grad
```

```
tensor([1., 1., 1., 1.])
```



```
x.grad.zero_()
y=x*x#å“ˆè¾¾ç›ç§¯ï¼Œå¯¹åº”å…ƒç´ ç›¸ä¹˜

#åœ¨æ·±åº¦å­¦ä¹ ä¸­æˆ‘ä»¬ä¸€èˆ¬ä¸è®¡ç®—å¾®åˆ†çŸ©é˜µ
#è€Œæ˜¯è®¡ç®—æ‰¹é‡ä¸­æ¯ä¸ªæ ·æœ¬å•ç‹¬è®¡ç®—çš„åå¯¼æ•°ä¹‹å’Œ

y.sum().backward()#ç­‰ä»·äºy.backword(torch.ones(len(x)))
x.grad
```

```
tensor([0., 2., 4., 6.])
```



**å°†æŸäº›è®¡ç®—ç§»åŠ¨åˆ°è®°å½•çš„è®¡ç®—å›¾ä¹‹å¤–**

```
# åå¯ç”¨äºç”¨äºå°†ç¥ç»ç½‘ç»œçš„ä¸€äº›å‚æ•°å›ºå®šä½
x.grad.zero_()
y = x*x
u = y.detach()#æŠŠyå½“ä½œå¸¸æ•°
z = u*x

z.sum().backward()
x.grad == u
```

```
tensor([True, True, True, True])
```



```
x.grad.zero_()
y.sum().backward()
x.grad == 2*x
```

```
tensor([True, True, True, True])
```

**å³ä½¿æ„å»ºå‡½æ•°çš„è®¡ç®—å›¾éœ€è¦ç”¨è¿‡Pythonæ§åˆ¶æµï¼Œä»ç„¶å¯ä»¥è®¡ç®—å¾—åˆ°çš„å˜é‡çš„æ¢¯åº¦**

**è¿™ä¹Ÿæ˜¯éšå¼æ„é€ çš„ä¼˜åŠ¿ï¼Œå› ä¸ºå®ƒä¼šå­˜å‚¨æ¢¯åº¦è®¡ç®—çš„è®¡ç®—å›¾ï¼Œå†æ¬¡è®¡ç®—æ—¶æ‰§è¡Œåå‘è¿‡ç¨‹å°±å¯ä»¥**

```
def f(a):
    b = a * 2
    while b.norm()<1000:
        b = b * 2
    if b.sum() > 0:
        c = b
    else:
        c = 100 * b
    return c

a = torch.randn(size=(),requires_grad=True)
d = f(a)
d.backward()

a.grad == d / a
```

## çº¿æ€§å›å½’+åŸºç¡€ä¼˜åŒ–ç®—æ³•

### çº¿æ€§å›å½’

- **çº¿æ€§æ¨¡å‹**

  - è¾“å…¥ï¼š$x=[x_1,x_2,...,x_n]^T$

  - çº¿æ€§æ¨¡å‹éœ€è¦ç¡®å®šä¸€ä¸ªnç»´æƒé‡å’Œä¸€ä¸ªæ ‡é‡åå·®$\omega=[\omega_1,\omega_2,...,\omega_n]^T,b$

  - è¾“å‡º ï¼š$y=\omega_1x_1+\omega_2x_2+...+\omega_nx_n+b$ï¼Œ

    å‘é‡ç‰ˆæœ¬çš„æ˜¯ ğ‘¦=<ğœ”,ğ‘¥>+ğ‘

  - çº¿æ€§æ¨¡å‹å¯ä»¥çœ‹ä½œæ˜¯å•å±‚ç¥ç»ç½‘ç»œ

    > - ç¥ç»ç½‘ç»œæºäºç¥ç»ç§‘å­¦
    > - æœ€æ—©çš„ç¥ç»ç½‘ç»œæ˜¯æºè‡ªç¥ç»ç§‘å­¦çš„ï¼Œä½†æ˜¯æ—¶è‡³ä»Šæ—¥ï¼Œå¾ˆå¤šç¥ç»ç½‘ç»œå·²ç»è¿œè¿œé«˜äºç¥ç»ç§‘å­¦ï¼Œå¯è§£é‡Šæ€§ä¹Ÿä¸æ˜¯å¾ˆå¼ºï¼Œä¸å¿…çº ç»“

- è¡¡é‡ä¼°è®¡è´¨é‡

  - æˆ‘ä»¬éœ€è¦ä¼°è®¡æ¨¡å‹çš„é¢„ä¼°å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œä¾‹å¦‚æˆ¿å±‹å”®ä»·å’Œè‚¡ä»·

  - å‡è®¾$y$æ˜¯çœŸå®å€¼ï¼Œ$\tilde{y}$æ˜¯ä¼°è®¡å€¼ï¼Œæˆ‘ä»¬å¯ä»¥æ¯”è¾ƒ

    ğ‘™(ğ‘¦,$\tilde{y}$)=(1/2)*(ğ‘¦âˆ’$\tilde{y}$)2ï¼Œè¿™ä¸ªå«åš**å¹³æ–¹æŸå¤±**

- **è®­ç»ƒæ•°æ®**

  - æ”¶é›†ä¸€äº›æ•°æ®ç‚¹æ¥å†³å®šå‚æ•°å€¼ï¼ˆæƒé‡$\omega$å’Œåå·®$b$ï¼‰ï¼Œä¾‹å¦‚6ä¸ªæœˆå†…è¢«å–æ‰çš„æˆ¿å­ã€‚

  - è¿™è¢«ç§°ä¹‹ä¸ºè®­ç»ƒæ•°æ®

  - é€šå¸¸è¶Šå¤šè¶Šå¥½ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç°å®ä¸–ç•Œçš„æ•°æ®éƒ½æ˜¯æœ‰é™çš„ï¼Œä½†æ˜¯ä¸ºäº†è®­ç»ƒå‡ºç²¾ç¡®çš„å‚æ•°å¾€å¾€éœ€è¦è®­ç»ƒæ•°æ®è¶Šå¤šè¶Šå¥½ï¼Œå½“è®­ç»ƒæ•°æ®ä¸è¶³çš„æ—¶å€™ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è¿›è¡Œé¢å¤–å¤„ç†ã€‚

  - å‡è®¾æˆ‘ä»¬æœ‰nä¸ªæ ·æœ¬ï¼Œè®°ä¸º

    ğ‘‹=[ğ‘¥1,ğ‘¥2,...,ğ‘¥ğ‘›]ğ‘‡,ğ‘¦=[ğ‘¦1,ğ‘¦2,...ğ‘¦ğ‘›]ğ‘‡

    ğ‘‹çš„æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªæ ·æœ¬ï¼Œ$y$çš„æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªè¾“å‡ºçš„å®æ•°å€¼ã€‚

- **å‚æ•°å­¦ä¹ **

  - **è®­ç»ƒæŸå¤±**ã€‚ä½†æˆ‘ä»¬è®­ç»ƒå‚æ•°çš„æ—¶å€™ï¼Œéœ€è¦å®šä¹‰ä¸€ä¸ªæŸå¤±å‡½æ•°æ¥è¡¡é‡å‚æ•°çš„å¥½åï¼Œåº”ç”¨å‰æ–‡æè¿‡çš„å¹³æ–¹æŸå¤±æœ‰å…¬å¼ï¼š

  - ![image-20240701223140819](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240701223140819.png)

     ğ‘™(ğ‘‹,ğ‘¥,ğœ”,ğ‘)=(1/2ğ‘›)*âˆ‘(ğ‘¦ğ‘–âˆ’$\tilde{y}$)^2=(1/2ğ‘›)*||ğ‘¦iâˆ’ğ‘‹ğœ”âˆ’ğ‘||^2

  - **æœ€å°åŒ–æŸå¤±æ¥å­¦ä¹ å‚æ•°**ã€‚è®­ç»ƒå‚æ•°çš„ç›®çš„å°±æ˜¯ä½¿æŸå¤±å‡½æ•°çš„å€¼å°½å¯èƒ½å°ï¼ˆè¿™æ„å‘³ç€é¢„ä¼°å€¼å’ŒçœŸå®å€¼æ›´æ¥è¿‘ï¼‰ã€‚æœ€åæ±‚å¾—çš„å‚æ•°å€¼å¯è¡¨ç¤ºä¸ºï¼š

    $\omega^*,b^*=argmin_{\omega,b}l(X,x,\omega,b)$

- **æ˜¾ç¤ºè§£** 

  - çº¿æ€§å›å½’æœ‰æ˜¾ç¤ºè§£ï¼Œå³å¯ä»¥ç›´æ¥çŸ©é˜µæ•°å­¦è¿ç®—ï¼Œå¾—åˆ°å‚æ•°wå’Œbçš„æœ€ä¼˜è§£ï¼Œè€Œä¸æ˜¯ç”¨æ¢¯åº¦ä¸‹é™ï¼Œç‰›é¡¿æ³•ç­‰å‚æ•°ä¼˜åŒ–æ–¹å¼ä¸€ç‚¹ç‚¹é€¼è¿‘æœ€ä¼˜è§£ã€‚

  - **æ¨å¯¼è¿‡ç¨‹**ï¼š

    - ä¸ºäº†æ–¹ä¾¿çŸ©é˜µè¡¨ç¤ºå’Œè®¡ç®—ï¼Œå°†åå·®åŠ å…¥æƒé‡ï¼Œ$X\gets[X,1],\omega\gets[\omega,b]$

    - æŸå¤±å‡½æ•°æ˜¯å‡¸å‡½æ•°ï¼Œæœ€ä¼˜è§£æ»¡è¶³å¯¼æ•°ä¸º0ï¼Œå¯è§£å‡ºæ˜¾ç¤ºè§£

      ä»¤$\frac{\partial}{\partial\omega} l(X,y,\omega)=0$

      æœ‰$\frac{1}{n}(y-X\omega)^TX=0$

      è§£å¾—$\omega^*=(X^TX)^{-1}X^Ty$

- æ€»ç»“

  - çº¿æ€§å›å½’æ˜¯å¯¹nç»´è¾“å…¥çš„åŠ æƒï¼Œå¤–åŠ åå·®
  - ä½¿ç”¨**å¹³æ–¹æŸå¤±**æ¥è¡¡é‡é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹é—´çš„è¯¯å·®
  - **çº¿æ€§å›å½’æœ‰æ˜¾ç¤ºè§£**
  - çº¿æ€§å›å½’å¯ä»¥çœ‹ä½œå•å±‚ç¥ç»ç½‘ç»œ

### åŸºç¡€ä¼˜åŒ–ç®—æ³•

- **æ¢¯åº¦ä¸‹é™**

  - å½“æ¨¡å‹æ²¡æœ‰æ˜¾ç¤ºè§£çš„æ—¶å€™ï¼Œåº”ç”¨æ¢¯åº¦ä¸‹é™æ³•é€¼è¿‘æœ€ä¼˜è§£ã€‚
  - æ¢¯åº¦ä¸‹é™æ³•çš„å…·ä½“æ­¥éª¤ï¼š
    - æŒ‘é€‰ä¸€ä¸ªåˆå§‹å€¼$\omega_0$
    - é‡å¤è¿­ä»£å‚æ•°ï¼Œè¿­ä»£å…¬å¼ä¸ºï¼š$\omega_t=\omega_{t-1}-\lambda\frac{\partial l}{\partial\omega_{t-1} } $
      - **âˆ’ğœ•ğ‘™ğœ•ğœ”ğ‘¡âˆ’1ä¸ºå‡½æ•°å€¼ä¸‹é™æœ€å¿«çš„æ–¹å‘ï¼Œå­¦ä¹ ç‡$\lambda$ä¸ºå­¦ä¹ æ­¥é•¿ã€‚**
  - é€‰æ‹©å­¦ä¹ ç‡
    - å­¦ä¹ ç‡$\lambda$ä¸ºå­¦ä¹ æ­¥é•¿ï¼Œä»£è¡¨äº†æ²¿è´Ÿæ¢¯åº¦æ–¹å‘èµ°äº†å¤šè¿œï¼Œè¿™æ˜¯è¶…å‚æ•°ï¼ˆäººä¸ºæŒ‡å®šçš„çš„å€¼ï¼Œä¸æ˜¯è®­ç»ƒå¾—åˆ°çš„ï¼‰
    - å­¦ä¹ ç‡ä¸èƒ½å¤ªå¤§ï¼Œä¹Ÿä¸èƒ½å¤ªå°ï¼Œéœ€è¦é€‰å–é€‚å½“ã€‚

- **å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™**

  - åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šç®—æ¢¯åº¦å¤ªè´µäº†

    - åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¾ˆå°‘ç›´æ¥åº”ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼Œè¿™æ˜¯å› ä¸ºæ¯æ¬¡æ›´æ–°éƒ½éœ€è¦è®¡ç®—è®­ç»ƒé›†ä¸Šæ‰€æœ‰çš„æ ·æœ¬ï¼Œè€—è´¹æ—¶é—´å¤ªé•¿ã€‚ä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œè¿­ä»£ä¸€æ¬¡å¯èƒ½éœ€è¦æ•°åˆ†é’Ÿç”šè‡³æ•°å°æ—¶ã€‚

  - ä¸ºäº†å‡å°‘è¿ç®—ä»£ä»·ï¼Œæˆ‘ä»¬å¯ä»¥==éšæœºé‡‡æ ·==bä¸ªæ ·æœ¬$i_1,i_2,...,i_b$æ¥è¿‘ä¼¼æŸå¤±ï¼ŒæŸå¤±å‡½æ•°ä¸ºï¼š

     1ğ‘âˆ‘ğ‘–âˆˆğ¼ğ‘ğ‘™(ğ‘¥ğ‘–,ğ‘¦ğ‘–,ğœ”) ,

    å…¶ä¸­**bæ˜¯æ‰¹é‡å¤§å°(batch size)ï¼Œä¹Ÿæ˜¯è¶…å‚æ•°**

  - **é€‰æ‹©æ‰¹é‡å¤§å°**

    - bä¹Ÿä¸èƒ½å¤ªå¤§ï¼šå†…å­˜æ¶ˆè€—å¢åŠ ï¼›æµªè´¹è®¡ç®—èµ„æºï¼Œä¸€ä¸ªæç«¯çš„æƒ…å†µæ˜¯å¯èƒ½ä¼šé‡å¤é€‰å–å¾ˆå¤šå·®ä¸å¤šçš„æ ·æœ¬ï¼Œæµªè´¹è®¡ç®—èµ„æº
    - bä¹Ÿä¸èƒ½å¤ªå°ï¼šæ¯æ¬¡è®¡ç®—é‡å¤ªå°ï¼Œå¾ˆéš¾ä»¥å¹¶è¡Œï¼Œä¸èƒ½æœ€å¤§é™åº¦åˆ©ç”¨GPUèµ„æº

- **æ€»ç»“**

  - æ¢¯åº¦ä¸‹é™é€šè¿‡ä¸æ–­**æ²¿ç€è´Ÿæ¢¯åº¦æ–¹å‘**æ›´æ–°å‚æ•°æ±‚è§£
  - å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™æ˜¯æ·±åº¦å­¦ä¹ é»˜è®¤çš„æ±‚è§£ç®—æ³•ï¼ˆç®€å•ï¼Œç¨³å®šï¼‰
  - **ä¸¤ä¸ªé‡è¦çš„è¶…å‚æ•°ï¼šæ‰¹é‡å¤§å°ï¼ˆbatch sizeï¼‰ï¼Œå­¦ä¹ ç‡ï¼ˆlrï¼‰**

### çº¿æ€§å›å½’çš„ä»é›¶å¼€å§‹å®ç°

```
import random
import torch
from d2l import torch as d2l

def synthetic_data(w, b, num_examples):
    # ç”Ÿæˆç‰¹å¾çŸ©é˜µ Xï¼Œå½¢çŠ¶ä¸º (num_examples, len(w))
    X = torch.normal(0, 1, (num_examples, len(w)))
    # ç”Ÿæˆæ ‡ç­¾ y
    y = torch.matmul(X, w) + b
    # å‘æ ‡ç­¾æ·»åŠ å™ªå£°
    y += torch.normal(0, 0.01, y.shape)
    # è¿”å›ç‰¹å¾å’Œæ ‡ç­¾ï¼Œæ ‡ç­¾çš„å½¢çŠ¶è°ƒæ•´ä¸º (-1, 1)
    return X, y.reshape((-1, 1))

# å®šä¹‰çœŸå®çš„æƒé‡å’Œåç½®
true_w = torch.tensor([2, -3.4])
true_b = 4.2
# ç”Ÿæˆç‰¹å¾å’Œæ ‡ç­¾
features, labels = synthetic_data(true_w, true_b, 1000)

# æ‰“å°å‰äº”ä¸ªç‰¹å¾å’Œæ ‡ç­¾
print("Features:", features[:5])
print("Labels:", labels[:5])

d2l.set_figsize()
d2l.plt.scatter(features[:,1].detach().numpy(),labels.detach().numpy(),1)
```

```
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i:min(i + batch_size, num_examples)]
        )
        yield features[batch_indices], labels[batch_indices]

# æµ‹è¯•æ•°æ®è¿­ä»£å™¨
batch_size = 10
for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
```

```
#åˆå§‹åŒ–å‚æ•°
w =torch.normal(0,0.01,(2,1),requires_grad=true)
b = torch.zeros(1,requires_grad=true)

#å®šä¹‰æ¨¡å‹
def linreg(x,w,b):
	return torch.matmul(x,w)+b 
	
#å®šä¹‰æŸå¤±å‡½æ•°
def squared_loss(y_hat,y):
	return (y_hat-y.reshape(y_hat.shape))**2/2

#å®šä¹‰ä¼˜åŒ–ç®—æ³•
def sgd(params,lr,batch_size):
	with torch.no_grad():
		for param in params:
			param-=lr*param.grad/batch_size
			param.grad.zeros_()
```



```
## è®­ç»ƒè¿‡ç¨‹
lr = 0.03
num_epoches = 3
net = linreg
loss = squared_loss
for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)  # è®¡ç®—æŸå¤±
        l.sum().backward()  # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
        sgd([w, b], lr, batch_size)  # æ›´æ–°å‚æ•°
    with torch.no_grad():  # ç¦æ­¢è‡ªåŠ¨è®¡ç®—æ¢¯åº¦
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')  # æ‰“å°æ¯ä¸ª epoch çš„æŸå¤±

```

### æ–°å‹å›å½’çš„ç®€æ´å®ç°

```
import numpy as np
import torch
from torch.utils import data
from d2l import torch as d2l

true_w = torch.tensor([2, -3.4])
true_b = 4.2
# ç”Ÿæˆç‰¹å¾å’Œæ ‡ç­¾
features, labels = synthetic_data(true_w, true_b, 1000)
```

è°ƒç”¨æ¡†æ¶ä¸­ç°æœ‰çš„APIæ¥è¯»å–æ•°æ®

```
import torch
from torch.utils.data import TensorDataset, DataLoader

def load_array(data_arrays, batch_size, is_train=True):
    dataset = TensorDataset(*data_arrays)
    return DataLoader(dataset, batch_size=batch_size, shuffle=is_train)

batch_size = 10
data_iter = load_array((features, labels), batch_size)
```

ä½¿ç”¨æ¡†æ¶çš„é¢„å®šä¹‰å¥½çš„å±‚

```
from torch import nn
net = nn.Sequential(nn.Linear(2,1))

net[0].weight.data.normal(0,0.01)
net[0].bias.data.fill_(0)
```

```
# è®¡ç®—å‡æ–¹è¯¯å·®ä½¿ç”¨MSELossç±»
loss = nn.MSELoss()

# å®ä¾‹åŒ–SGD
trainer = torch.optim.SGD(net.parameters(),lr=0.03)
```

```
num_epochs=3
for epoch in range(num_epochs):
	for X ,y in data_iter:
		l = loss(net(X),y)
		trainer.zero_grad()
		l.backward()
		trainer.step()
	l = loss(net(features),labels)
	print(f'epoch {epoch + 1},loss {l:f}')
```



## Softmax å›å½’ + æŸå¤±å‡½æ•° + å›¾ç‰‡åˆ†ç±»æ•°æ®é›†

### å›å½’VSåˆ†ç±»ï¼š

- å›å½’ä¼°è®¡ä¸€ä¸ªè¿ç»­å€¼
- åˆ†ç±»é¢„æµ‹ä¸€ä¸ªç¦»æ•£ç±»åˆ«

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-01.png)

#### ä»å›å½’åˆ°å¤šç±»åˆ†ç±»ï¼š

##### å›å½’ï¼š

- å•è¿ç»­æ•°å€¼è¾“å‡º
- è‡ªç„¶åŒºé—´R
- è·ŸçœŸå®å€¼çš„åŒºåˆ«ä½œä¸ºæŸå¤±

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-02.png)

#### åˆ†ç±»ï¼š

- é€šå¸¸å¤šä¸ªè¾“å‡º

- è¾“å‡ºiæ˜¯é¢„æµ‹ä¸ºç¬¬iç±»çš„ç½®ä¿¡åº¦

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-03.png)

##### å‡æ–¹æŸå¤±ï¼š



- å¯¹ç±»åˆ«è¿›è¡Œä¸€ä½æœ‰æ•ˆç¼–ç 

  ![image-20240702004009211](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240702004009211.png)

- ä½¿ç”¨å‡æ–¹æŸå¤±è®­ç»ƒ

- æœ€å¤§å€¼ä¸ºé¢„æµ‹ ![](http://latex.codecogs.com/gif.latex?\\ \hat{y}=\underset {i}{argmax}\quad o^{i} )

##### æ— æ ¡éªŒæ¯”ä¾‹

- å¯¹ç±»åˆ«è¿›è¡Œä¸€ä½æœ‰æ•ˆç¼–ç 
- æœ€å¤§å€¼ä¸ºé¢„æµ‹ ![](http://latex.codecogs.com/gif.latex?\\ \hat{y}=\underset {i}{argmax}\quad o^{i} )
- éœ€è¦æ›´ç½®ä¿¡çš„è¯†åˆ«æ­£ç¡®ç±»ï¼ˆå¤§ä½™é‡ï¼‰ ![](http://latex.codecogs.com/gif.latex?\\ o_y-o_i\geq\Delta(y,i) )

##### æ ¡éªŒæ¯”ä¾‹

- è¾“å‡ºåŒ¹é…æ¦‚ç‡ï¼ˆéè´Ÿï¼Œå’Œä¸º1ï¼‰ ![](http://latex.codecogs.com/gif.latex?\\ \hat{y}=softmax(o) )

  ![](http://latex.codecogs.com/gif.latex?\\ \hat{y_i}=\frac{exp(o_i)}{\sum_{k} exp(o_k)} )

- æ¦‚ç‡yå’Œ$\hat{y}$çš„åŒºåˆ«ä½œä¸ºæŸå¤±

### Softmaxå’Œäº¤å‰ç†µæŸå¤±

- äº¤å‰ç†µç”¨æ¥è¡¡é‡ä¸¤ä¸ªæ¦‚ç‡çš„åŒºåˆ«$H(p,q)=\sum_{i} -p_{i}log(q_i)$
- å°†å®ƒä½œä¸ºæŸå¤± ![](http://latex.codecogs.com/gif.latex?\\ l(y,\hat{y})=-\sum_{i}y_{i}log\hat{y_{i}}=-log\hat{y_y} )
- å…¶æ¢¯åº¦æ˜¯çœŸå®æ¦‚ç‡å’Œé¢„æµ‹æ¦‚ç‡çš„åŒºåˆ« ![](http://latex.codecogs.com/gif.latex?\\ \partial_{o_{i}}l(y,\hat{y})=softmax(o)*{i}-y*{i} )

> Softmaxå›å½’æ˜¯ä¸€ä¸ªå¤šç±»åˆ†ç±»æ¨¡å‹
>
> ä½¿ç”¨Softmaxæ“ä½œå­å¾—åˆ°æ¯ä¸ªç±»çš„é¢„æµ‹ç½®ä¿¡åº¦
>
> ä½¿ç”¨äº¤å‰ç†µæ¥è¡¡é‡å’Œé¢„æµ‹æ ‡å·çš„åŒºåˆ«

### æŸå¤±å‡½æ•°



[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-04.png)

#### L2 Loss

![](http://latex.codecogs.com/gif.latex?\\ l(y,y^{'})=\frac{1}{2}(y-y^{'})^2 )

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-05.png)

> æ¢¯åº¦ä¼šéšç€ç»“æœé€¼è¿‘è€Œä¸‹é™

#### L1 Loss



![](http://latex.codecogs.com/gif.latex?\\ l(y,y^{'})=\lvert y-y^{'}\rvert )

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-06.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-06.png)

> æ¢¯åº¦ä¿æŒä¸å˜ï¼Œä½†åœ¨0å¤„æ¢¯åº¦éšæœº

#### Huber's Robust Loss



[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-07.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-07.png)

> ç»“åˆL1 Losså’ŒL2 Lossçš„ä¼˜ç‚¹

### å›¾ç‰‡åˆ†ç±»æ•°æ®é›†

#### Fashion-MNISTæ•°æ®é›†ï¼š

```
import torchvision
import torch
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l 

d2l.use_svg_display()
```

- è¯»å–æ•°æ®é›†

  ```
  # å›¾ç‰‡ç±»å‹è½¬å˜
  trans=transforms.ToTensor()
  
  mnist_train=torchvision.datasets.FashionMNIST(root="../data",train=True,                                              transform=trans,download=True)
  mnist_test=torchvision.datasets.FashionMNIST(root="../data",train=False,                                             transform=trans,download=True)
  ```

- æ•°æ®é›†å†…å›¾ç‰‡å¤§å°

  ```
  mnist_train[0][0].shape
  torch.Size([1, 28, 28])
  ```

  è¡¨ç¤ºå›¾ç‰‡ä¸ºå•é€šé“ï¼ˆé»‘ç™½ï¼‰çš„28X28çš„å›¾ç‰‡

- æ˜¾ç¤ºæ•°æ®é›†å›¾åƒ

  ```
  X,y = next(iter(data.DataLoader(mnist_train,batch_size=18)))
  show_images(X.reshape(18,28,28),2,9,titles=get_fashion_mnist_labels(y))
  ```

  

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-08.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-[Notes/blob/main/imgs/09/09-08.png)

  è¯»å–ä¸€å°æ‰¹æ•°æ®

```python
batch_size = 256
def get_dataloader_workers():
	return 4
train_iter = data.Dataloader(mnist_train,batch_size,shuffle=True,num_workers=get_dataLoader_workers())

timer = d2l.Timer()
for X,y in train_iter:
	continue
f'{timer.stop():.2f} sec'
```

### ä»é›¶å®ç°softmaxå›å½’

#### softmax:

$$ softmax(X)*{ij}=\frac{exp(X*{ij})}{\sum_{k} exp(X_{ik})} $$

```
import torch
from IPthon import display
from d2l import torch as d2l 

batch_size = 256
train_iter,test_iter = d2l.load_data_fasion_mnist(batch_size) 
```

å°†å›¾åƒå±•å¹³ï¼Œæ¯ä¸ªå›¾åƒçœ‹åšé•¿åº¦ä¸º784çš„å‘é‡ï¼Œå› ä¸ºæ•°æ®é›†æœ‰åä¸ªç±»åˆ«ï¼Œæ‰€ä»¥ç½‘ç»œè¾“å‡ºç»´åº¦ä¸º10ã€‚ä»¥æ­¤è®¾å®šå‚æ•°å¤§å°å¹¶åˆå§‹åŒ–ï¼š

```
num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)
```

å®ç°softmaxå›å½’æ¨¡å‹ï¼š

```
def softmax(X):
    X_exp = torch.exp(X)
    partition = X_exp.sum(1, keepdim=True)
    return X_exp / partition
#  çŸ©é˜µä¸­çš„éå¸¸å¤§æˆ–éå¸¸å°çš„å…ƒç´ å¯èƒ½é€ æˆæ•°å€¼ä¸Šæº¢æˆ–ä¸‹æº¢

def net(X):
    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)
```

 å®ç°äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼š

```
def cross_entropy(y_hat, y):
    return - torch.log(y_hat[range(len(y_hat)), y])
```

è®¡ç®—æ­£ç¡®ç‡ï¼š

```
def accuracy(y_hat, y):  
    """è®¡ç®—é¢„æµ‹æ­£ç¡®çš„æ•°é‡"""
    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype) == y
    return float(cmp.type(y.dtype).sum())
 
```

è¯„ä¼°netç²¾åº¦

```
def evaluate_accuracy(net, data_iter):  
    """è®¡ç®—åœ¨æŒ‡å®šæ•°æ®é›†ä¸Šæ¨¡å‹çš„ç²¾åº¦"""
    if isinstance(net, torch.nn.Module):
        net.eval()
    metric = Accumulator(2)
    with torch.no_grad():
        for X, y in data_iter:
            metric.add(accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]
```

```
class Accumulator:  
    """åœ¨nä¸ªå˜é‡ä¸Šç´¯åŠ """
    def __init__(self, n):
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]
```

softmaxå›å½’çš„è®­ç»ƒ

```
def train_epoch_ch3(net, train_iter, loss, updater):  #@save
    """è®­ç»ƒæ¨¡å‹ä¸€ä¸ªè¿­ä»£å‘¨æœŸï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰"""
    # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œä¸å†è®¡ç®—gradä¹‹ç±»çš„å†…å®¹
    if isinstance(net, torch.nn.Module):
        net.train()
    # è®­ç»ƒæŸå¤±æ€»å’Œã€è®­ç»ƒå‡†ç¡®åº¦æ€»å’Œã€æ ·æœ¬æ•°
    metric = Accumulator(3)
    for X, y in train_iter:
        # è®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°
        y_hat = net(X)
        l = loss(y_hat, y)
        if isinstance(updater, torch.optim.Optimizer):
            # ä½¿ç”¨PyTorchå†…ç½®çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
            updater.zero_grad()
            l.mean().backward()
            updater.step()
        else:
            # ä½¿ç”¨å®šåˆ¶çš„ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
            l.sum().backward()
            updater(X.shape[0])
        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    # è¿”å›è®­ç»ƒæŸå¤±å’Œè®­ç»ƒç²¾åº¦
    return metric[0] / metric[2], metric[1] / metric[2]
```

å®šä¹‰ä¸€ä¸ªåœ¨åŠ¨ç”»ä¸­ç»˜åˆ¶æ•°æ®çš„å®ç”¨ç¨‹åºç±»

```
class Animator:  #@save
    """åœ¨åŠ¨ç”»ä¸­ç»˜åˆ¶æ•°æ®"""
    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,
                 ylim=None, xscale='linear', yscale='linear',
                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,
                 figsize=(3.5, 2.5)):
        # å¢é‡åœ°ç»˜åˆ¶å¤šæ¡çº¿
        if legend is None:
            legend = []
        d2l.use_svg_display()
        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)
        if nrows * ncols == 1:
            self.axes = [self.axes, ]
        # ä½¿ç”¨lambdaå‡½æ•°æ•è·å‚æ•°
        self.config_axes = lambda: d2l.set_axes(
            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)
        self.X, self.Y, self.fmts = None, None, fmts

    def add(self, x, y):
        # å‘å›¾è¡¨ä¸­æ·»åŠ å¤šä¸ªæ•°æ®ç‚¹
        if not hasattr(y, "__len__"):
            y = [y]
        n = len(y)
        if not hasattr(x, "__len__"):
            x = [x] * n
        if not self.X:
            self.X = [[] for _ in range(n)]
        if not self.Y:
            self.Y = [[] for _ in range(n)]
        for i, (a, b) in enumerate(zip(x, y)):
            if a is not None and b is not None:
                self.X[i].append(a)
                self.Y[i].append(b)
        self.axes[0].cla()
        for x, y, fmt in zip(self.X, self.Y, self.fmts):
            self.axes[0].plot(x, y, fmt)
        self.config_axes()
        display.display(self.fig)
        display.clear_output(wait=True)
```

å®šä¹‰è®­ç»ƒæ¨¡å‹ï¼š

```
def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  
    """è®­ç»ƒæ¨¡å‹ï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰"""
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train loss', 'train acc', 'test acc'])
                        
    for epoch in range(num_epochs):
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc,))
    train_loss, train_acc = train_metrics
    
    assert train_loss < 0.5, train_loss
    assert train_acc <= 1 and train_acc > 0.7, train_acc
    assert test_acc <= 1 and test_acc > 0.7, test_acc
```

å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–æ¨¡å‹çš„æŸå¤±å‡½æ•°

```
lr = 0.1

def updater(batch_size):
    return d2l.sgd([W, b], lr, batch_size)
```

é¢„æµ‹ï¼š

```
def predict_ch3(net, test_iter, n=6):  
    """é¢„æµ‹æ ‡ç­¾ï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰"""
    for X, y in test_iter:
        break
    trues = d2l.get_fashion_mnist_labels(y)
    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))
    titles = [true +'\n' + pred for true, pred in zip(trues, preds)]
    d2l.show_images(
        X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])

predict_ch3(net, test_iter)
```

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/09/09-09.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/09/09-09.png)

### softmaxçš„ç®€æ´å®ç°

> è°ƒç”¨torchå†…çš„ç½‘ç»œå±‚

```
import torch
from torch import nn
from d2l import torch as d2l

batch_size=256
train_iter,test_iter=d2l.load_data_fashion_mnist(batch_size)
# PyTorchä¸ä¼šéšå¼åœ°è°ƒæ•´è¾“å…¥çš„å½¢çŠ¶ã€‚å› æ­¤ï¼Œ
# æˆ‘ä»¬åœ¨çº¿æ€§å±‚å‰å®šä¹‰äº†å±•å¹³å±‚ï¼ˆflattenï¼‰ï¼Œæ¥è°ƒæ•´ç½‘ç»œè¾“å…¥çš„å½¢çŠ¶
net=nn.Sequential(nn.Flatten(),nn.Linear(784,10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight,std=0.01)

net.apply(init_weights)
## åœ¨äº¤å‰ç†µæŸå¤±å‡½æ•°ä¸­ä¼ é€’æœªå½’ä¸€åŒ–çš„é¢„æµ‹ï¼Œå¹¶åŒæ—¶è®¡ç®—softmaxåŠå…¶å¯¹æ•°
loss=nn.CrossEntropyLoss()

trainer=torch.optim.SGD(net.parameters(),lr=0.1)

num_epochs=10
d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,trainer)
```



# å¤šå±‚æ„ŸçŸ¥æœº

## å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰

### æ„ŸçŸ¥æœº

#### å®šä¹‰

ä»ç°åœ¨çš„è§‚ç‚¹æ¥çœ‹ï¼Œæ„ŸçŸ¥æœºå®é™…ä¸Šå°±æ˜¯ç¥ç»ç½‘ç»œä¸­çš„ä¸€ä¸ªç¥ç»å•å…ƒ

[![æ„ŸçŸ¥æœº](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/10/%E6%84%9F%E7%9F%A5%E6%9C%BA.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/10/æ„ŸçŸ¥æœº.png)

æ„ŸçŸ¥æœºèƒ½è§£å†³äºŒåˆ†ç±»é—®é¢˜ï¼Œä½†ä¸çº¿æ€§å›å½’å’Œsoftmaxå›å½’æœ‰æ‰€åŒºåˆ«ï¼šçº¿æ€§å›å½’ä¸softmaxå›å½’çš„è¾“å‡ºå‡ä¸ºå®æ•°ï¼Œsoftmaxå›å½’çš„è¾“å‡ºåŒæ—¶è¿˜æ»¡è¶³æ¦‚ç‡å…¬ç†ã€‚

#### è®­ç»ƒ

è®­ç»ƒæ„ŸçŸ¥æœºçš„ä¼ªä»£ç å¦‚ä¸‹ï¼š

```
initialize w = 0 and b = 0
repeat
    #æ­¤å¤„è¡¨è¾¾å¼å°äº0ä»£è¡¨é¢„æµ‹ç»“æœé”™è¯¯ï¼Œè¡¨ç¤ºé¢„æµ‹å€¼ä¸çœŸå®å€¼åŒå·
    #ç­‰ä»·batchsizeä¸º1çš„æ¢¯åº¦ä¸‹é™
    if y_i[<w,x_i>+b] <= 0 then
        w=w + yixi
        b=b + yi
    end if
until all classified correctly
```

å¯ä»¥çœ‹å‡ºè¿™ç­‰ä»·äºä½¿ç”¨å¦‚ä¸‹æŸå¤±å‡½æ•°çš„éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆbatch_size=1ï¼‰: $$ \ell(y,\bold x,\bold w)=max(0,-y<\bold w,\bold x>)\ =max(0,-y\bold w^T\bold x) $$ å½“é¢„æµ‹é”™è¯¯æ—¶ï¼Œåå¯¼æ•°ä¸º $$ \frac{\partial \ell}{\partial \bold w}=-y\cdot \bold x $$

æ³¨ï¼šæ­¤å¤„ä¸ºäº†æ–¹ä¾¿è®¡ç®—ï¼Œå°†åç½®é¡¹bå½’å…¥wä¸­çš„æœ€åä¸€ç»´ï¼Œå¹¶åœ¨ç‰¹å¾xä¸­ç›¸åº”çš„æœ€åä¸€ç»´åŠ å…¥å¸¸æ•°1

#### æ”¶æ•›å®šç†

è®¾æ•°æ®åœ¨ç‰¹å¾ç©ºé—´èƒ½è¢«åŠå¾„ä¸ºrçš„åœ†ï¼ˆçƒï¼‰è¦†ç›–ï¼Œå¹¶ä¸”åˆ†ç±»æ—¶æœ‰ä½™é‡ï¼ˆå³$\sigma$å‡½æ•°çš„è¾“å…¥ä¸ä¼šå–ä½¿è¾“å‡ºæ¨¡æ£±ä¸¤å¯çš„å€¼ï¼‰$y(\bold x^T\bold w)\geq \rho$ï¼Œè‹¥åˆå§‹å‚æ•°æ»¡è¶³$|\bold w|^2+b^2 \leq 1$ï¼Œåˆ™æ„ŸçŸ¥æœºä¿è¯åœ¨$\frac{r^2+1}{\rho ^2}$æ­¥å†…æ”¶æ•›

[æ”¶æ•›æ€§çš„è¯æ˜](https://zhuanlan.zhihu.com/p/46762820)

åœ¨å‰é¢çš„è¯¾ç¨‹ä¸­æˆ‘ä»¬å­¦ä¹ äº†softmaxå›å½’ï¼Œçº¿æ€§å›å½’ï¼Œä»–ä»¬æœ‰å°†è¾“å…¥å‘é‡ä¸ä¸€ä¸ªæƒé‡å‘é‡åšå†…ç§¯å†ä¸ä¸€ä¸ªåç½®ç›¸åŠ å¾—åˆ°ä¸€ä¸ªå€¼çš„è¿‡ç¨‹ï¼š $$ O =W^TX+b $$ è¿™ä¸ªè¿‡ç¨‹è¢«ç§°ä¸ºä»¿å°„å˜æ¢ï¼Œå®ƒæ˜¯ä¸€ä¸ªå¸¦æœ‰åç½®é¡¹çš„çº¿æ€§å˜æ¢ï¼Œå®ƒæœ€ç»ˆäº§ç”Ÿçš„æ¨¡å‹è¢«ç§°ä¸ºçº¿æ€§æ¨¡å‹ï¼Œçº¿æ€§æ¨¡å‹çš„ç‰¹ç‚¹æ˜¯åªèƒ½ä»¥çº¿æ€§çš„æ–¹å¼å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œåˆ’åˆ†ï¼š

[![çº¿æ€§åŒ–åˆ†](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/10/%E7%BA%BF%E6%80%A7%E5%88%92%E5%88%86.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/10/çº¿æ€§åˆ’åˆ†.png)

ç„¶è€Œï¼Œè¿™ç§çº¿æ€§åˆ’åˆ†ä¾èµ–äºçº¿æ€§å‡è®¾ï¼Œæ˜¯éå¸¸ä¸å¯é çš„

- çº¿æ€§å‡è®¾æ„å‘³ç€å•è°ƒå‡è®¾ï¼Œè¿™æ˜¯ä¸å¯é çš„ï¼š
  - å¯¹äºäººä½“çš„ä½“æ¸©ä¸å¥åº·æƒ…å†µçš„å»ºæ¨¡ï¼Œäººä½“åœ¨37â„ƒæ—¶æœ€ä¸ºå¥åº·ï¼Œè¿‡å°è¿‡å¤§å‡æœ‰é£é™©ï¼Œç„¶è€Œè¿™ä¸æ˜¯å•è°ƒçš„
- çº¿æ€§å‡è®¾æ„å‘³ç€ç‰¹å¾ä¸é¢„æµ‹å­˜åœ¨çº¿æ€§ç›¸å…³æ€§ï¼Œè¿™ä¹Ÿæ˜¯ä¸å¯é çš„ï¼š
  - å¦‚æœé¢„æµ‹ä¸€ä¸ªäººå¿è¿˜å€ºåŠ¡çš„å¯èƒ½æ€§ï¼Œé‚£è¿™ä¸ªäººçš„èµ„äº§ä»0ä¸‡å…ƒå¢è‡³5ä¸‡å…ƒå’Œä»100ä¸‡å…ƒå¢è‡³105ä¸‡å…ƒå¯¹åº”çš„å¿è¿˜å€ºåŠ¡çš„å¯èƒ½æ€§çš„å¢å¹…è‚¯å®šæ˜¯ä¸ç›¸ç­‰çš„ï¼Œä¹Ÿå°±æ˜¯ä¸çº¿æ€§ç›¸å…³çš„
- çº¿æ€§æ¨¡å‹çš„è¯„ä¼°æ ‡å‡†æ˜¯æœ‰ä½ç½®ä¾èµ–æ€§çš„ï¼Œè¿™æ˜¯ä¸å¯é çš„ï¼š
  - å¦‚æœéœ€è¦åˆ¤æ–­å›¾ç‰‡ä¸­çš„åŠ¨ç‰©æ˜¯çŒ«è¿˜æ˜¯ç‹—ï¼Œå¯¹äºå›¾ç‰‡ä¸­ä¸€ä¸ªåƒç´ çš„æƒé‡çš„æ”¹å˜æ°¸è¿œæ˜¯ä¸å¯é çš„ï¼Œå› ä¸ºå¦‚æœå°†å›¾ç‰‡ç¿»è½¬ï¼Œå®ƒçš„ç±»åˆ«ä¸ä¼šæ”¹å˜ï¼Œä½†æ˜¯çº¿æ€§æ¨¡å‹ä¸å…·å¤‡è¿™ç§æ€§è´¨ï¼Œåƒç´ çš„æƒé‡å°†ä¼šå¤±æ•ˆ

è¯¾ç¨‹ä¸­æ‰€æåˆ°çš„ä¾‹å­æ˜¯XORé—®é¢˜ï¼Œå³å¸Œæœ›æ¨¡å‹èƒ½é¢„æµ‹å‡ºXORåˆ†ç±»ï¼ˆåˆ†å‰²å›¾ç‰‡ä¸­çš„ä¸€ä¸‰è±¡é™ä¸äºŒå››è±¡é™ï¼‰ï¼š

[![XORé—®é¢˜](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/10/XOR%E9%97%AE%E9%A2%98.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/10/XORé—®é¢˜.png)

### å¤šå±‚æ„ŸçŸ¥æœº

#### XORé—®é¢˜çš„å¤šå±‚æ¬¡è§£å†³

ä»ä»¥XORé—®é¢˜ä¸ºä¾‹ï¼ŒXORé—®é¢˜çš„ä¸€ä¸ªè§£å†³æ€è·¯æ˜¯åˆ†ç±»ä¸¤æ¬¡ï¼Œå…ˆæŒ‰xè½´åˆ†ç±»ä¸º+å’Œ-ï¼Œå†æŒ‰yè½´åˆ†ç±»ä¸º+å’Œ-ï¼Œæœ€åå°†ä¸¤ä¸ªåˆ†ç±»ç»“æœç›¸ä¹˜ï¼Œ+å³ä¸ºä¸€ä¸‰è±¡é™ï¼Œ-å³ä¸ºäºŒå››è±¡é™ï¼š

[![å¤šå±‚åˆ†ç±»XOR1](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/10/%E5%A4%9A%E5%B1%82%E5%88%86%E7%B1%BBXOR1.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/10/å¤šå±‚åˆ†ç±»XOR1.png)

[![å¤šå±‚åˆ†ç±»XOR2](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/10/%E5%A4%9A%E5%B1%82%E5%88%86%E7%B1%BBXOR2.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/10/å¤šå±‚åˆ†ç±»XOR2.png)

è¿™å®é™…ä¸Šå°†ä¿¡æ¯è¿›è¡Œäº†å¤šå±‚æ¬¡çš„ä¼ é€’ï¼š

[![XORä¿¡æ¯å¤šå±‚æ¬¡ä¼ é€’](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/10/XOR%E4%BF%A1%E6%81%AF%E5%A4%9A%E5%B1%82%E6%AC%A1%E4%BC%A0%E9%80%92.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/10/XORä¿¡æ¯å¤šå±‚æ¬¡ä¼ é€’.png)

å…¶ä¸­è“è‰²ä¸ºæŒ‰Xåæ ‡çš„æ­£è´Ÿè¿›è¡Œçš„åˆ†ç±»ï¼Œæ©™è‰²ä¸ºæŒ‰Yåæ ‡çš„æ­£è´Ÿè¿›è¡Œçš„åˆ†ç±»ï¼Œç°è‰²ä¸ºå°†äºŒè€…ä¿¡æ¯çš„ç»¼åˆï¼Œè¿™å°±å®ç°äº†ç”¨å¤šå±‚æ¬¡çš„çº¿æ€§æ¨¡å‹å¯¹éçº¿æ€§è¿›è¡Œé¢„æµ‹

#### å¤šå±‚æ„ŸçŸ¥æœº

æœ‰äº†XORé—®é¢˜çš„è§£å†³ç»éªŒï¼Œå¯ä»¥æƒ³åˆ°å¦‚æœå°†å¤šä¸ªæ„ŸçŸ¥æœºå †å èµ·æ¥ï¼Œå½¢æˆå…·æœ‰å¤šä¸ªå±‚æ¬¡çš„ç»“æ„ï¼Œå¦‚å›¾ï¼š

[![å•éšè—å±‚](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/10/%E5%8D%95%E9%9A%90%E8%97%8F%E5%B1%82.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/10/å•éšè—å±‚.png)

è¿™é‡Œçš„æ¨¡å‹ç§°ä¸ºå¤šå±‚æ„ŸçŸ¥æœºï¼Œç¬¬ä¸€å±‚åœ†åœˆ$x_1,x_2,x_3,x_4$ç§°ä¸ºè¾“å…¥ï¼ˆå®é™…ä¸Šä»–å¹¶éæ„ŸçŸ¥æœºï¼‰ï¼Œä¹‹åçš„ä¸€å±‚ç§°ä¸ºéšè—å±‚ï¼Œç”±5ä¸ªæ„ŸçŸ¥æœºæ„æˆï¼Œä»–ä»¬å‡ä»¥å‰ä¸€å±‚çš„ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼Œæœ€åæ˜¯è¾“å‡ºå±‚ï¼Œä»¥å‰ä¸€å±‚éšè—å±‚çš„ç»“æœä½œä¸ºè¾“å…¥ã€‚é™¤äº†è¾“å…¥çš„ä¿¡æ¯å’Œæœ€åä¸€å±‚çš„æ„ŸçŸ¥æœºä»¥å¤–ï¼Œå…¶ä½™çš„å±‚å‡ç§°ä¸ºéšè—å±‚ï¼Œéšè—å±‚çš„è®¾ç½®ä¸ºæ¨¡å‹ä¸€ä¸ªé‡è¦çš„è¶…å‚æ•°ï¼Œè¿™é‡Œçš„æ¨¡å‹æœ‰ä¸€ä¸ªéšè—å±‚ã€‚

#### æ¿€æ´»å‡½æ•°

ä½†æ˜¯ä»…ä»…æœ‰çº¿æ€§å˜æ¢æ˜¯ä¸å¤Ÿçš„ï¼Œå¦‚æœæˆ‘ä»¬ç®€å•çš„å°†å¤šä¸ªçº¿æ€§å˜æ¢æŒ‰å±‚æ¬¡å åŠ ï¼Œç”±äºçº¿æ€§å˜æ¢çš„ç»“æœä»ä¸ºçº¿æ€§å˜æ¢ï¼Œæ‰€ä»¥æœ€ç»ˆçš„ç»“æœç­‰ä»·äºçº¿æ€§å˜æ¢ï¼Œä¸å•ä¸ªæ„ŸçŸ¥æœºå¹¶æ— åŒºåˆ«ï¼Œåè€ŒåŠ å¤§äº†æ¨¡å‹ï¼Œæµªè´¹äº†èµ„æºï¼Œä¸ºäº†é˜²æ­¢è¿™ä¸ªé—®é¢˜ï¼Œéœ€è¦å¯¹æ¯ä¸ªå•å…ƒï¼ˆæ„ŸçŸ¥æœºï¼‰çš„è¾“å‡ºé€šè¿‡æ¿€æ´»å‡½æ•°è¿›è¡Œå¤„ç†å†äº¤ç”±ä¸‹ä¸€å±‚çš„æ„ŸçŸ¥æœºè¿›è¡Œè¿ç®—ï¼Œè¿™äº›æ¿€æ´»å‡½æ•°å°±æ˜¯è§£å†³éçº¿æ€§é—®é¢˜çš„å…³é”®ã€‚

*æ¿€æ´»å‡½æ•°*ï¼ˆactivation functionï¼‰é€šè¿‡è®¡ç®—åŠ æƒå’Œå¹¶åŠ ä¸Šåç½®æ¥ç¡®å®šç¥ç»å…ƒæ˜¯å¦åº”è¯¥è¢«æ¿€æ´»ï¼Œå®ƒä»¬å°†è¾“å…¥ä¿¡å·è½¬æ¢ä¸ºè¾“å‡ºçš„å¯å¾®è¿ç®—ã€‚å¤§å¤šæ•°æ¿€æ´»å‡½æ•°éƒ½æ˜¯éçº¿æ€§çš„ã€‚

ä¸»è¦çš„æ¿€æ´»å‡½æ•°æœ‰ï¼š

##### ReLUå‡½æ•°

æœ€å—æ¬¢è¿çš„æ¿€æ´»å‡½æ•°æ˜¯*ä¿®æ­£çº¿æ€§å•å…ƒ*ï¼ˆRectified linear unitï¼Œ*ReLU*ï¼‰ï¼Œå› ä¸ºå®ƒå®ç°ç®€å•ï¼ŒåŒæ—¶åœ¨å„ç§é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚**ReLUæä¾›äº†ä¸€ç§éå¸¸ç®€å•çš„éçº¿æ€§å˜æ¢**ã€‚ç»™å®šå…ƒç´ $x$ï¼ŒReLUå‡½æ•°è¢«å®šä¹‰ä¸ºè¯¥å…ƒç´ ä¸$0$çš„æœ€å¤§å€¼ï¼š $$ \operatorname{ReLU}(x) = \max(x, 0) $$ ReLUå‡½æ•°é€šè¿‡å°†ç›¸åº”çš„æ´»æ€§å€¼è®¾ä¸º0ï¼Œä»…ä¿ç•™æ­£å…ƒç´ å¹¶ä¸¢å¼ƒæ‰€æœ‰è´Ÿå…ƒç´ ã€‚ä¸ºäº†ç›´è§‚æ„Ÿå—ä¸€ä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”»å‡ºå‡½æ•°çš„æ›²çº¿å›¾ã€‚æ­£å¦‚ä»å›¾ä¸­æ‰€çœ‹åˆ°ï¼Œæ¿€æ´»å‡½æ•°æ˜¯åˆ†æ®µçº¿æ€§çš„ã€‚ä½¿ç”¨ReLUçš„åŸå› æ˜¯ï¼Œå®ƒæ±‚å¯¼è¡¨ç°å¾—ç‰¹åˆ«å¥½ï¼šè¦ä¹ˆè®©å‚æ•°æ¶ˆå¤±ï¼Œè¦ä¹ˆè®©å‚æ•°é€šè¿‡ã€‚è¿™ä½¿å¾—ä¼˜åŒ–è¡¨ç°çš„æ›´å¥½ï¼Œå¹¶ä¸”ReLUå‡è½»äº†å›°æ‰°ä»¥å¾€ç¥ç»ç½‘ç»œçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜

##### sigmoidå‡½æ•°

**å¯¹äºä¸€ä¸ªå®šä¹‰åŸŸåœ¨$\mathbb{R}$ä¸­çš„è¾“å…¥ï¼Œ\*sigmoidå‡½æ•°\*å°†è¾“å…¥å˜æ¢ä¸ºåŒºé—´(0,1)ä¸Šçš„è¾“å‡º**ã€‚ å› æ­¤ï¼Œsigmoidé€šå¸¸ç§°ä¸º*æŒ¤å‹å‡½æ•°*ï¼ˆsquashing functionï¼‰ï¼šå®ƒå°†èŒƒå›´$ï¼ˆ-\infty, \inftyï¼‰$ä¸­çš„ä»»æ„è¾“å…¥å‹ç¼©åˆ°åŒºé—´ï¼ˆ0,1ï¼‰ä¸­çš„æŸä¸ªå€¼ï¼š $$ \operatorname{sigmoid}(x) = \frac{1}{1 + e^{-x}}. $$ åœ¨åŸºäºæ¢¯åº¦çš„å­¦ä¹ ä¸­ï¼Œsigmoidå‡½æ•°æ˜¯ä¸€ä¸ªè‡ªç„¶çš„é€‰æ‹©ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå¹³æ»‘çš„ã€å¯å¾®çš„é˜ˆå€¼å•å…ƒè¿‘ä¼¼ã€‚å½“æˆ‘ä»¬æƒ³è¦å°†è¾“å‡ºè§†ä½œäºŒå…ƒåˆ†ç±»é—®é¢˜çš„æ¦‚ç‡æ—¶ï¼Œsigmoidä»ç„¶è¢«å¹¿æ³›ç”¨ä½œè¾“å‡ºå•å…ƒä¸Šçš„æ¿€æ´»å‡½æ•°ï¼ˆä½ å¯ä»¥å°†sigmoidè§†ä¸ºsoftmaxçš„ç‰¹ä¾‹ï¼‰ã€‚ç„¶è€Œï¼Œsigmoidåœ¨éšè—å±‚ä¸­å·²ç»è¾ƒå°‘ä½¿ç”¨ï¼Œå®ƒåœ¨å¤§éƒ¨åˆ†æ—¶å€™è¢«æ›´ç®€å•ã€æ›´å®¹æ˜“è®­ç»ƒçš„ReLUæ‰€å–ä»£ã€‚

##### tanhå‡½æ•°

ä¸sigmoidå‡½æ•°ç±»ä¼¼ï¼Œ**tanh(åŒæ›²æ­£åˆ‡)å‡½æ•°ä¹Ÿèƒ½å°†å…¶è¾“å…¥å‹ç¼©è½¬æ¢åˆ°åŒºé—´(-1,1)ä¸Š**ã€‚tanhå‡½æ•°çš„å…¬å¼å¦‚ä¸‹ï¼š $$ \operatorname{tanh}(x) = \frac{1 - e^{-2x}}{1 + e^{-2x}} $$

### ä»£ç å®ç°

#### ä»é›¶å®ç°

```
import torch
from torch import nn
from d2l import torch as d2l

batch_size=256
train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size)
```

å®ç°ä¸€ä¸ªå…·æœ‰å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºï¼Œå…·æœ‰256ä¸ªéšè—å•å…ƒã€‚

Fashion-MNISTä¸­çš„æ¯ä¸ªå›¾åƒç”± 28Ã—28=784ä¸ªç°åº¦åƒç´ å€¼ç»„æˆã€‚ æ‰€æœ‰å›¾åƒå…±åˆ†ä¸º10ä¸ªç±»åˆ«ã€‚ å¿½ç•¥åƒç´ ä¹‹é—´çš„ç©ºé—´ç»“æ„ï¼Œ æˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªå›¾åƒè§†ä¸ºå…·æœ‰784ä¸ªè¾“å…¥ç‰¹å¾ å’Œ10ä¸ªç±»çš„ç®€å•åˆ†ç±»æ•°æ®é›†ã€‚

```
num_inputs, num_outputs, num_hiddens = 784, 10, 256

W1 = nn.Parameter(torch.radn(num_inputs,num_hiddens,requires_grad = True)* 0.01)
b1 = nn.Parameter(torch.zeros(num_hiddens,requires_grad = True))
W2 = nn.Parameter(torch.randn(num_hiddens,num_outputs,requires_grad = True)* 0.01)
b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))

params = [W1, b1, W2, b2]
```

å®ç°ReLUæ¿€æ´»å‡½æ•°

```
def relu(X):
    a = torch.zeros_like(X)
    return torch.max(X, a)
```

å®ç°æ¨¡å‹

```
def net(X):
	X = X.reshape((-1,num_inputs))
	H = relu(X@W1 + b1)
	return (H@W2 + b2)
```

æŸå¤±å‡½æ•° ç›´æ¥ä½¿ç”¨é«˜çº§APIä¸­çš„å†…ç½®å‡½æ•°æ¥è®¡ç®—softmaxå’Œäº¤å‰ç†µæŸå¤±

```
loss = nn.CrossEntropyLoss(reduction='none')
```

```
num_epochs, lr = 10, 0.1
updater = torch.optim.SGD(params, lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)
```

#### ç®€åŒ–ä»£ç 

```
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights)

batch_size, lr, num_epochs = 256, 0.1, 10
loss = nn.CrossEntropyLoss(reduction='none')
trainer = torch.optim.SGD(net.parameters(), lr=lr)

train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```





## æ¨¡å‹é€‰æ‹© + è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ

### æ¦‚å¿µåŒºåˆ†

#### è®­ç»ƒè¯¯å·®ä¸æ³›åŒ–è¯¯å·®

è®­ç»ƒè¯¯å·®åŸºäºè®­ç»ƒé›†ï¼Œæ˜¯åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„è¯¯å·®

æ³›åŒ–è¯¯å·®åŸºäºæµ‹è¯•é›†ï¼Œæ˜¯åœ¨æ–°æ•°æ®ä¸Šçš„è¯¯å·®

#### éªŒè¯æ•°æ®é›†ä¸æµ‹è¯•æ•°æ®é›†

éªŒè¯æ•°æ®é›†ï¼šä¸€ä¸ªç”¨æ¥è¯„ä¼°æ¨¡å‹å¥½åçš„æ•°æ®é›†

æµ‹è¯•æ•°æ®é›†ï¼šåªç”¨ä¸€æ¬¡çš„æ•°æ®é›†

### K-åˆ™äº¤å‰éªŒè¯

ï¼ˆåœ¨æ²¡æœ‰è¶³å¤Ÿå¤šæ•°æ®æ—¶ä½¿ç”¨ï¼‰

ç®—æ³•ï¼š

â€‹	å°†è®­ç»ƒæ•°æ®åˆ†å‰²æˆKå—

â€‹	ä½¿ç”¨ç¬¬iå—ä½œä¸ºéªŒè¯æ•°æ®é›†ï¼Œå…¶ä½™ä½œä¸ºè®­ç»ƒæ•°æ®é›†

â€‹	æŠ¥å‘Škä¸ªéªŒè¯é›†è¯¯å·®çš„å¹³å‡ï¼Œå¸¸ç”¨k=5/10

### è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆ

![image-20240702223819681](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240702223819681.png)

![image-20240702224134621](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240702224134621.png)

#### ä¼°è®¡æ¨¡å‹å®¹é‡

##### éš¾ä»¥åœ¨ä¸åŒçš„ç§ç±»ç®—æ³•ä¹‹é—´æ¯”è¾ƒ

ä¾‹å¦‚æ ‘æ¨¡å‹å’Œç¥ç»ç½‘ç»œ

##### ç»™å®šä¸€ä¸ªæ¨¡å‹ç§ç±»ï¼Œå°†æœ‰ä¸¤ä¸ªä¸»è¦å› ç´ 

å‚æ•°ä¸ªæ•°

å‚æ•°å€¼çš„é€‰æ‹©èŒƒå›´

#### æ•°æ®å¤æ‚åº¦

æ ·æœ¬ä¸ªæ•°

æ ·æœ¬çš„å…ƒç´ ä¸ªæ•°

æ—¶é—´/ç©ºé—´ç»“æ„

å¤šæ ·æ€§

### ä»£ç ï¼ˆå¤šé¡¹å¼å›å½’ï¼‰

![image-20240702225202168](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240702225202168.png)

```
import math
import numpy as np
import torch
from torch import nn
from d2l import torch as d2l

max_degree = 20  # å¤šé¡¹å¼çš„æœ€å¤§é˜¶æ•°
n_train, n_test = 100, 100  # è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†å¤§å°
true_w = np.zeros(max_degree)  # åˆ†é…å¤§é‡çš„ç©ºé—´
true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])  #åé¢å…¨æ˜¯å™ªéŸ³

## æ„é€ æ•°æ®é›†
features = np.random.normal(size=(n_train + n_test, 1))  #éšæœºæ­£æ€åˆ†å¸ƒç”Ÿæˆæ•°æ®ä¸æµ‹è¯•é›†
np.random.shuffle(features)    #éšæœºåŒ–
poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))   #ç”Ÿæˆå¹‚æŒ‡æ•°
for i in range(max_degree):
    poly_features[:, i] /= math.gamma(i + 1)  # gamma(n)=(n-1)!
# labelsçš„ç»´åº¦:(n_train+n_test,)
labels = np.dot(poly_features, true_w)
labels += np.random.normal(scale=0.1, size=labels.shape)

# NumPy ndarrayè½¬æ¢ä¸ºtensor
true_w, features, poly_features, labels = [torch.tensor(x, dtype=
    torch.float32) for x in [true_w, features, poly_features, labels]]
```

å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•

```
def evaluate_loss(net, data_iter, loss):  #@save
    """è¯„ä¼°ç»™å®šæ•°æ®é›†ä¸Šæ¨¡å‹çš„æŸå¤±"""
    metric = d2l.Accumulator(2)  # æŸå¤±çš„æ€»å’Œ,æ ·æœ¬æ•°é‡
    for X, y in data_iter:
        out = net(X)
        y = y.reshape(out.shape)
        l = loss(out, y)
        metric.add(l.sum(), l.numel())
    return metric[0] / metric[1]
```

**å®šä¹‰è®­ç»ƒå‡½æ•°**

```
def train(train_features, test_features, train_labels, test_labels,num_epochs=400):
    loss = nn.MSELoss(reduction='none')
    input_shape = train_features.shape[-1]
    # ä¸è®¾ç½®åç½®ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨å¤šé¡¹å¼ä¸­å®ç°äº†å®ƒ
    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))
    batch_size = min(10, train_labels.shape[0])
    train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),batch_size)
    test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),batch_size, is_train=False)
    trainer = torch.optim.SGD(net.parameters(), lr=0.01)
    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',xlim=[1, num_epochs], ylim=[1e-3, 1e2],legend=['train', 'test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == 0 or (epoch + 1) % 20 == 0:
            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),evaluate_loss(net, test_iter, loss)))
    print('weight:', net[0].weight.data.numpy())
```



## æƒé‡è¡°é€€ï¼ˆæ­£åˆ™åŒ–æ¨¡å‹çš„æŠ€æœ¯ï¼‰

åœ¨è®­ç»ƒå‚æ•°åŒ–æœºå™¨å­¦ä¹ æ¨¡å‹æ—¶ï¼Œ *æƒé‡è¡°å‡*ï¼ˆweight decayï¼‰æ˜¯æœ€å¹¿æ³›ä½¿ç”¨çš„æ­£åˆ™åŒ–çš„æŠ€æœ¯ä¹‹ä¸€ï¼Œ å®ƒé€šå¸¸ä¹Ÿè¢«ç§°ä¸ºğ¿2*æ­£åˆ™åŒ–*ã€‚ è¿™é¡¹æŠ€æœ¯é€šè¿‡å‡½æ•°ä¸é›¶çš„è·ç¦»æ¥è¡¡é‡å‡½æ•°çš„å¤æ‚åº¦ï¼Œ å› ä¸ºåœ¨æ‰€æœ‰å‡½æ•°ğ‘“ä¸­ï¼Œå‡½æ•°ğ‘“=0ï¼ˆæ‰€æœ‰è¾“å…¥éƒ½å¾—åˆ°å€¼0ï¼‰ åœ¨æŸç§æ„ä¹‰ä¸Šæ˜¯æœ€ç®€å•çš„ã€‚

ä¸€ç§ç®€å•çš„æ–¹æ³•æ˜¯é€šè¿‡çº¿æ€§å‡½æ•° ğ‘“(ğ‘¥)=ğ‘¤âŠ¤ğ‘¥ ä¸­çš„æƒé‡å‘é‡çš„æŸä¸ªèŒƒæ•°æ¥åº¦é‡å…¶å¤æ‚æ€§ï¼Œ ä¾‹å¦‚âˆ¥ğ‘¤âˆ¥2ã€‚ è¦ä¿è¯æƒé‡å‘é‡æ¯”è¾ƒå°ï¼Œ æœ€å¸¸ç”¨æ–¹æ³•æ˜¯å°†å…¶èŒƒæ•°ä½œä¸ºæƒ©ç½šé¡¹åŠ åˆ°æœ€å°åŒ–æŸå¤±çš„é—®é¢˜ä¸­ã€‚ å°†åŸæ¥çš„è®­ç»ƒç›®æ ‡*æœ€å°åŒ–è®­ç»ƒæ ‡ç­¾ä¸Šçš„é¢„æµ‹æŸå¤±*ï¼Œ è°ƒæ•´ä¸º*æœ€å°åŒ–é¢„æµ‹æŸå¤±å’Œæƒ©ç½šé¡¹ä¹‹å’Œ*ã€‚ ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬çš„æƒé‡å‘é‡å¢é•¿çš„å¤ªå¤§ï¼Œ æˆ‘ä»¬çš„å­¦ä¹ ç®—æ³•å¯èƒ½ä¼šæ›´é›†ä¸­äºæœ€å°åŒ–æƒé‡èŒƒæ•°âˆ¥ğ‘¤âˆ¥2ã€‚

### ç¡¬æ€§é™åˆ¶/ç›´è§‚ç†è§£

**ä½¿ç”¨å‡æ–¹èŒƒæ•°ä½œä¸ºç¡¬æ€§é™åˆ¶**

æˆ‘ä»¬çš„ä¼˜åŒ–ç›®æ ‡ä»ç„¶æ˜¯[![img](https://camo.githubusercontent.com/c268c1ccd2378c3872e8678310498cca00c9fd8f26bfdb0ce3cf4e983d7a1d56/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f6d696e2535437370616365253543656c6c28253543626f6c64253742772537442c6229)](https://camo.githubusercontent.com/c268c1ccd2378c3872e8678310498cca00c9fd8f26bfdb0ce3cf4e983d7a1d56/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f6d696e2535437370616365253543656c6c28253543626f6c64253742772537442c6229)ï¼Œåªæ˜¯é¢å¤–å¯¹[![img](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)æ·»åŠ ä¸€ä¸ªé™åˆ¶æ¡ä»¶[![img](https://camo.githubusercontent.com/60135f218d6eff45f9d2a2b226b09f667b1e5862c12b77709fe9fe000ce42fdf/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253743253743253543626f6c6425374277253744253743253743253545322535436c6571736c616e742535437468657461)](https://camo.githubusercontent.com/60135f218d6eff45f9d2a2b226b09f667b1e5862c12b77709fe9fe000ce42fdf/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253743253743253543626f6c6425374277253744253743253743253545322535436c6571736c616e742535437468657461)ï¼Œå³æƒé‡çš„å„é¡¹å¹³æ–¹å’Œå°äºä¸€ä¸ªç‰¹å®šçš„å¸¸æ•°[![img](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)ã€‚é‚£ä¹ˆè®¾å®šä¸€ä¸ªè¾ƒå°çš„[![img](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)å°±ä¼šä½¿å¾—[![img](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)ä¸­æ¯ä¸ªå…ƒç´ çš„å€¼éƒ½ä¸ä¼šå¤ªå¤§ã€‚

é€šå¸¸ä¸ä¼šé™åˆ¶åç§»bï¼Œç†è®ºä¸Šè®²bè¡¨ç¤ºæ•´ä¸ªæ•°æ®åœ¨é›¶ç‚¹ä¸Šçš„åç§»ï¼Œå› æ­¤æ˜¯ä¸åº”è¯¥é™åˆ¶çš„ï¼Œä½†å®è·µä¸­é™åˆ¶ä¸å¦å¯¹ç»“æœéƒ½æ²¡ä»€ä¹ˆå½±å“ã€‚

**å´æ©è¾¾è¯¾ç¨‹ä¸­å¯¹è¿™ä¸€ç°è±¡çš„è§£é‡Šæ˜¯wæ˜¯é«˜ç»´å‘é‡ï¼Œå·²ç»åŒ… å«äº†ç»å¤§å¤šæ•°å‚æ•°è¶³ä»¥è¡¨è¾¾é«˜æ–¹å·®é—®é¢˜ï¼Œbä½œä¸ºå•ä¸ªæ•°å­—å¯¹ç»“æœçš„å½±å“å°±ä¼šå¾ˆå°.**

**å°çš„[![img](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)æ„å‘³ç€æ›´å¼ºçš„æ­£åˆ™é¡¹**ï¼Œå¯¹äºç›¸åŒçš„[![img](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)ï¼Œ[![img](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)ä¸­å…ƒç´ è¶Šå¤šåˆ™å•ä¸ªå…ƒç´ çš„å€¼ä¼šè¶Šå°ã€‚

### æŸ”æ€§é™åˆ¶/å®é™…åº”ç”¨



ä¸Šæ–‡è¯´çš„ç¡¬æ€§é™åˆ¶åœ¨å®é™…ä½¿ç”¨æ—¶æ¯”è¾ƒéº»çƒ¦ï¼Œå®é™…ä¸Šå¸¸ç”¨çš„å‡½æ•°æ˜¯

[![img](https://camo.githubusercontent.com/aca2480d2e63e33df193ee69d1869f501c3cc3e4123bee06c3510ca892890098/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f6d696e2535437370616365253543656c6c28253543626f6c64253742772537442c62292b253543667261632537422535436c616d62646125374425374232253744253743253743253543626f6c642537427725374425374325374325354532)](https://camo.githubusercontent.com/aca2480d2e63e33df193ee69d1869f501c3cc3e4123bee06c3510ca892890098/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f6d696e2535437370616365253543656c6c28253543626f6c64253742772537442c62292b253543667261632537422535436c616d62646125374425374232253744253743253743253543626f6c642537427725374425374325374325354532)

å¯ä»¥é€šè¿‡æ‹‰æ ¼æœ—æ—¥ä¹˜å­è¯æ˜å¯¹äºæ¯ä¸ª[![img](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)](https://camo.githubusercontent.com/2ee9f22d00819650d1da57b8e92428653b1baaeb0a5efbd4f95ee745612fc9a7/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535437468657461)éƒ½å¯ä»¥æ‰¾åˆ°[![img](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)ä½¿å¾—ç¡¬æ€§é™åˆ¶çš„ç›®æ ‡å‡½æ•°ç­‰ä»·äºä¸Šå¼ã€‚

å…¶ä¸­[![img](https://camo.githubusercontent.com/db89c02a9c53b868fba4f1c0c9e4e7d986adeb498d5324dcb072189d24ad3904/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543667261632537422535436c616d62646125374425374232253744253743253743253543626f6c642537427725374425374325374325354532)](https://camo.githubusercontent.com/db89c02a9c53b868fba4f1c0c9e4e7d986adeb498d5324dcb072189d24ad3904/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543667261632537422535436c616d62646125374425374232253744253743253743253543626f6c642537427725374425374325374325354532)è¿™ä¸€é¡¹è¢«ç§°ä¸ºç½š(penalty)ï¼Œ[![img](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)**æ˜¯è¶…å‚æ•°ï¼Œæ§åˆ¶äº†æ­£åˆ™é¡¹çš„é‡è¦ç¨‹åº¦**ã€‚

å½“[![img](https://camo.githubusercontent.com/bc056ceedf61585d3b6a3f773ef4edf48c1311f60f335d60d30ba6060270c40c/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d6264613d30)](https://camo.githubusercontent.com/bc056ceedf61585d3b6a3f773ef4edf48c1311f60f335d60d30ba6060270c40c/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d6264613d30)æ—¶æ— ä½œç”¨ï¼Œ[![img](https://camo.githubusercontent.com/61cf8e5887264e92d223f8e3044131588ab79b6276c3c73935362d73f6fa9cc3/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d62646125354372696768746172726f77253543696e667479)](https://camo.githubusercontent.com/61cf8e5887264e92d223f8e3044131588ab79b6276c3c73935362d73f6fa9cc3/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d62646125354372696768746172726f77253543696e667479)æ—¶æœ€ä¼˜è§£[![img](https://camo.githubusercontent.com/5deec64969e5a58e2d4259232575940bfbbdf093a0472cea94e2a5305d3739ba/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c64253742772537442535452a25354372696768746172726f7730)](https://camo.githubusercontent.com/5deec64969e5a58e2d4259232575940bfbbdf093a0472cea94e2a5305d3739ba/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c64253742772537442535452a25354372696768746172726f7730)ï¼Œä¹Ÿå°±æ˜¯è¯´[![img](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)è¶Šå¤§æ¨¡å‹å¤æ‚åº¦å°±è¢«æ§åˆ¶çš„è¶Šä½ã€‚

[![12-01](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/12/12-01.JPG)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/12/12-01.JPG)

ä»¥[![img](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)](https://camo.githubusercontent.com/ff9b452cab8da34e38960130e11bdb43c17681b4d715f35495b631be82f83c1d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c6425374277253744)ä¸­åªæœ‰ä¸¤ä¸ªå‚æ•°ä¸ºä¾‹ï¼Œå…¶ä¸­ç»¿è‰²çš„éƒ¨åˆ†æ˜¯åŸæœ¬æŸå¤±å‡½æ•°å‡½æ•°å€¼çš„â€œç­‰é«˜çº¿â€ï¼Œé»„è‰²éƒ¨åˆ†å¯ä»¥çœ‹ä½œæ˜¯æ­£åˆ™é¡¹å¯¹åº”å‡½æ•°å€¼çš„â€œç­‰é«˜çº¿â€ ï¼Œä½¿ç”¨æƒé‡è¡°å‡åéœ€è¦ä¼˜åŒ–çš„æŸå¤±å‡½æ•°ç›¸å½“äºå›¾ä¸­ä¸¤ç»„ç­‰é«˜çº¿å åŠ ã€‚åŸæœ¬æœ€ä¼˜è§£ä½äºç»¿è‰²ä¸­å¿ƒï¼Œç°åœ¨è¿™ä¸€ä½ç½®åœ¨å¯¹äºæ­£åˆ™é¡¹æœ‰å¾ˆé«˜çš„æŸå¤±ï¼Œè€Œæ­£åˆ™é¡¹æœ€å°å€¼ä½äºåŸç‚¹ï¼Œå› æ­¤ç°åœ¨çš„æœ€ç»ˆä¼˜åŒ–è§£ä¼šæ›´é è¿‘åŸç‚¹ï¼Œè€Œå½“æ‰€æœ‰å‚æ•°éƒ½æ›´é è¿‘åŸç‚¹æ—¶æ¨¡å‹çš„è§„æ¨¡ä¹Ÿå°±æ›´å°ã€‚

ï¼ˆæˆ‘ä»¬ç”¨å‚æ•°å€¼çš„èŒƒå›´æ¥è¡¡é‡æ¨¡å‹çš„å¤§å°ï¼‰

### å‚æ•°æ›´æ–°

#### è®¡ç®—æ¢¯åº¦ 



[![img](https://camo.githubusercontent.com/816e5c55c47c5414a4ddafeae7feaccbd6446371d3719dcd4bb12b53196747da/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543667261632537422535437061727469616c2537422537442537442537422535437061727469616c253742253543626f6c642537427725374425374425374428253543656c6c28253543626f6c64253742772537442c62292b253543667261632537422535436c616d62646125374425374232253744253743253743253543626f6c642537427725374425374325374325354532293d253543667261632537422535437061727469616c253742253543656c6c28253543626f6c64253742772537442c62292537442537442537422537422535437061727469616c253742253543626f6c64253742772537442537442537442537442b2535436c616d626461253543626f6c6425374277253744)](https://camo.githubusercontent.com/816e5c55c47c5414a4ddafeae7feaccbd6446371d3719dcd4bb12b53196747da/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543667261632537422535437061727469616c2537422537442537442537422535437061727469616c253742253543626f6c642537427725374425374425374428253543656c6c28253543626f6c64253742772537442c62292b253543667261632537422535436c616d62646125374425374232253744253743253743253543626f6c642537427725374425374325374325354532293d253543667261632537422535437061727469616c253742253543656c6c28253543626f6c64253742772537442c62292537442537442537422537422535437061727469616c253742253543626f6c64253742772537442537442537442537442b2535436c616d626461253543626f6c6425374277253744)ã€

#### æ›´æ–°å‚æ•°



å°†ä¸Šå¼ç»“æœå¸¦å…¥æ›´æ–°å‚æ•°å…¬å¼æ•´ç†å¯å¾—

[![img](https://camo.githubusercontent.com/221e250a978f50f162533c2a1f5bc34e70bfd1751255e95b1c11eaf4bfdec1a1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c64253742772537445f253742742b312537443d28312d2535436574612535436c616d62646129253543626f6c64253742772537445f253742742537442d253543657461253543667261632537422535437061727469616c253742253543656c6c28253543626f6c64253742772537445f742c625f74292537442537442537422537422535437061727469616c253742253543626f6c64253742772537445f25374274253744253744253744253744)](https://camo.githubusercontent.com/221e250a978f50f162533c2a1f5bc34e70bfd1751255e95b1c11eaf4bfdec1a1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c64253742772537445f253742742b312537443d28312d2535436574612535436c616d62646129253543626f6c64253742772537445f253742742537442d253543657461253543667261632537422535437061727469616c253742253543656c6c28253543626f6c64253742772537445f742c625f74292537442537442537422537422535437061727469616c253742253543626f6c64253742772537445f25374274253744253744253744253744)

æ³¨æ„åˆ°è¿™ä¸ªå…¬å¼ä¸­åä¸€é¡¹ä¸åŸæ¥æ›´æ–°å‚æ•°çš„å…¬å¼æ²¡æœ‰åŒºåˆ«ï¼Œä»…ä»…æ˜¯åœ¨å‰ä¸€é¡¹[![img](https://camo.githubusercontent.com/779be9c1d70105fed3cfa9549c24c591ab988cf098abfce4af42c0d069c64c18/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c64253742772537445f25374274253744)](https://camo.githubusercontent.com/779be9c1d70105fed3cfa9549c24c591ab988cf098abfce4af42c0d069c64c18/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f253543626f6c64253742772537445f25374274253744) ä¸ŠåŠ äº†ä¸€ä¸ªç³»æ•°[![img](https://camo.githubusercontent.com/36e26287fd68d846aa72c6befe07fbaf4130e11a2a7a5a45c8eb4fe552993054/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f28312d2535436574612535436c616d62646129)](https://camo.githubusercontent.com/36e26287fd68d846aa72c6befe07fbaf4130e11a2a7a5a45c8eb4fe552993054/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f28312d2535436574612535436c616d62646129)ã€‚é€šå¸¸[![img](https://camo.githubusercontent.com/4c3bff3b6dcd9ffc7a7122b114f60f2f3687b910cebc2f00f751b30a4071f11d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436574612535436c616d62646125334331)](https://camo.githubusercontent.com/4c3bff3b6dcd9ffc7a7122b114f60f2f3687b910cebc2f00f751b30a4071f11d/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436574612535436c616d62646125334331) ï¼Œä¹Ÿå°±æ˜¯è¯´ç”±äºå¼•å…¥äº†[![img](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)ï¼Œæ¯æ¬¡æ›´æ–°å‚æ•°å‰å…ˆç»™å¾…æ›´æ–°å‚æ•°ä¹˜ä¸Šä¸€ä¸ªå°äº1çš„æƒé‡å†æ›´æ–°ï¼Œæƒé‡è¡°é€€ç”±æ­¤å¾—åã€‚

ï¼ˆç”±äºlambdaçš„å¼•å…¥ï¼Œæˆ‘ä»¬æ¯æ¬¡çš„wéƒ½ä¼šå…ˆè¿›è¡Œè¡°é€€å†å‡å»å­¦ä¹ ç‡*æ­¥é•¿ï¼‰

### æ€»ç»“

- æƒé‡è¡°é€€é€šè¿‡L2æ­£åˆ™é¡¹ä½¿å¾—æ¨¡å‹å‚æ•°ä¸ä¼šè¿‡å¤§ï¼Œä»è€Œæ§åˆ¶æ¨¡å‹å¤æ‚åº¦
- æ­£åˆ™é¡¹æƒé‡ï¼ˆ[![img](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)](https://camo.githubusercontent.com/2ec5723e26bb86479707648ec0b1b1f9183674b99e31bcce5cbe2835d1e7f9e1/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436c616d626461)ï¼‰æ˜¯æ§åˆ¶æ¨¡å‹å¤æ‚åº¦çš„è¶…å‚æ•°

### ä»£ç 

ç”Ÿæˆæ•°æ®

![image-20240703012706882](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240703012706882.png)

```
import torch
from torch import nn
from d2l import torch as d2l

n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5
true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05
train_data = d2l.synthetic_data(true_w, true_b, n_train)
train_iter = d2l.load_array(train_data, batch_size)
test_data = d2l.synthetic_data(true_w, true_b, n_test)
test_iter = d2l.load_array(test_data, batch_size, is_train=False)
```

åˆå§‹åŒ–æ¨¡å‹å‚æ•°

```
def init_params():
	w = torch.normal(0, 1, size=(num_inputs, 1),											requires_grad=True)
	b = torch.zeros(1,requires_grad=True)
	return [w,b]
```

å®šä¹‰L2èŒƒæ•°

```
def L2_penalty():
	return torch.sum(w.pow(2))/2
```

å®šä¹‰è®­ç»ƒä»£ç å®ç°

```
def train(lambd):
    w, b = init_params()
    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss
    num_epochs, lr = 100, 0.003
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            # å¢åŠ äº†L2èŒƒæ•°æƒ©ç½šé¡¹ï¼Œ
            # å¹¿æ’­æœºåˆ¶ä½¿l2_penalty(w)æˆä¸ºä¸€ä¸ªé•¿åº¦ä¸ºbatch_sizeçš„å‘é‡
            l = loss(net(X), y) + lambd * l2_penalty(w)
            l.sum().backward()
            d2l.sgd([w, b], lr, batch_size)
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),d2l.evaluate_loss(net, test_iter, loss)))
    print('wçš„L2èŒƒæ•°æ˜¯ï¼š', torch.norm(w).item())
	
```

ç®€ä»‹å®ç°

```
def train_concise(wd):
    net = nn.Sequential(nn.Linear(num_inputs, 1))
    for param in net.parameters():
        param.data.normal_()
    loss = nn.MSELoss(reduction='none')
    num_epochs, lr = 100, 0.003
    # åç½®å‚æ•°æ²¡æœ‰è¡°å‡
    trainer = torch.optim.SGD([
        {"params":net[0].weight,'weight_decay': wd},
        {"params":net[0].bias}], lr=lr)
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',
                            xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.mean().backward()
            trainer.step()
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1,
                         (d2l.evaluate_loss(net, train_iter, loss),
                          d2l.evaluate_loss(net, test_iter, loss)))
    print('wçš„L2èŒƒæ•°ï¼š', net[0].weight.norm().item())
```







## ä¸¢å¼ƒæ³•

### ä¸¢å¼ƒæ³•åŠ¨æœºã€å®ç°åŠåŸåˆ™

#### åŠ¨æœº

- ä¸€ä¸ªå¥½çš„æ¨¡å‹éœ€è¦å¯¹è¾“å…¥æ•°æ®çš„æ‰°åŠ¨é²æ£’ï¼ˆå¥å£®æ€§ï¼‰

#### [![13-02](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/13/13-02.jpg)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/13/13-02.jpg) [![13-03](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/13/13-03.jpg)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/13/13-03.jpg)

#### å¦‚ä½•å®ç°æ¨¡å‹çš„è¿™ä¸€èƒ½åŠ›

- ä½¿ç”¨æœ‰å™ªéŸ³çš„æ•°æ®ã€‚
- ä¸¢å¼ƒæ³•ï¼šåœ¨å±‚ä¹‹é—´åŠ å…¥å™ªéŸ³ã€‚

#### åŠ å…¥å™ªéŸ³çš„åŸåˆ™

æ— åå·®çš„åŠ å…¥å™ªéŸ³

[![13-01](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/13/13-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/13/13-01.png)

- ä¾‹å¦‚æ¨¡å‹çš„åŠŸèƒ½æ˜¯è¯†åˆ«çŒ«çŒ«ï¼ŒåŠ å…¥å™ªéŸ³å¯ä»¥æ˜¯è¾“å…¥æ¨¡ç³Šçš„çŒ«çŒ«å›¾ç‰‡ï¼Œä½†å°½é‡ä¸è¦æ˜¯ç‹—ç‹—çš„å›¾ç‰‡ã€‚

### ä¸¢å¼ƒæ³•å†…å®¹

- ä¸¢å¼ƒæ³•å¯¹æ¯ä¸ªå…ƒç´ ä½œå¦‚ä¸‹æ‰°åŠ¨

[![13-04](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/13/13-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/13/13-04.png)

- èƒ½å¤Ÿæ»¡è¶³åŠ å…¥å™ªéŸ³çš„æœŸæœ›ç›¸åŒåŸåˆ™

[![13-05](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/13/13-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/13/13-05.png)

### ä¸¢å¼ƒæ³•ä½¿ç”¨

#### ä¸¢å¼ƒæ³•çš„ä½¿ç”¨ä½ç½®

é€šå¸¸å°†ä¸¢å¼ƒæ³•ä½œç”¨åœ¨éšè—å…¨è¿æ¥å±‚çš„è¾“å‡ºä¸Š

[![13-06](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/13/13-06.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/13/13-06.png)

éšæœºé€‰ä¸­æŸäº›ç¥ç»å…ƒå°†å…¶è¾“å‡ºç½®ä½0ï¼Œå› æ­¤æ¨¡å‹ä¸ä¼šè¿‡åˆ†ä¾èµ–æŸäº›ç¥ç»å…ƒ

[![13-07](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/13/13-07.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/13/13-07.png)

#### è®­ç»ƒä¸­çš„ä¸¢å¼ƒæ³•

- æ­£åˆ™é¡¹ï¼ˆä¸¢å¼ƒæ³•ï¼‰ä»…åœ¨è®­ç»ƒä¸­ä½¿ç”¨ï¼šå½±å“æ¨¡å‹å‚æ•°çš„æ›´æ–°ï¼Œé¢„æµ‹çš„æ—¶å€™ä¾¿ä¸å†ä½¿ç”¨

### æ€»ç»“

- ä¸¢å¼ƒæ³•å°†ä¸€äº›è¾“å‡ºé¡¹éšæœºç½®0æ¥æ§åˆ¶æ¨¡å‹å¤æ‚åº¦
- å¸¸ä½œç”¨åœ¨å¤šå±‚æ„ŸçŸ¥æœºçš„éšè—å±‚è¾“å‡ºä¸Š
- ä¸¢å¼ƒæ¦‚ç‡æ˜¯æ§åˆ¶æ¨¡å‹å¤æ‚åº¦çš„è¶…å‚æ•°ï¼ˆå¸¸å–0.9ï¼Œ0.5ï¼Œ0.1ï¼‰

### ä»£ç éƒ¨åˆ†

#### Drpoutéƒ¨åˆ†

```
import torch
from torch import nn
from d2l import torch as d2l

# Xä¸ºdropoutå±‚çš„è¾“å…¥ï¼Œdropoutä¸ºè®¾ç½®çš„ä¸¢å¼ƒæ¦‚ç‡
def dropout_layer (X,dropout)ï¼š  
    assert 0<=dropout<=1        #ä¸¢å¼ƒæ¦‚ç‡ä»‹äº0ï¼Œ1ä¹‹é—´
    if dropout == 1:
       return torch.zeros_like(x) #è‹¥ä¸¢å¼ƒæ¦‚ç‡ä¸º1ï¼Œåˆ™Xçš„å…¨éƒ¨é¡¹å‡è¢«ç½®0
    if dropout == 0:
       return X                   #è‹¥ä¸¢å¼ƒæ¦‚ç‡ä¸º0ï¼Œä¸å¯¹Xä½œä¸¢å¼ƒæ“ä½œï¼Œç›´æ¥è¿”å›X
       
    mask=(torch.randn(X.shape)>dropout).float() 
    return mask*X/(1-dropout) 
    #å°†maskä¸Xç›¸ä¹˜å®ç°ä¸¢å¼ƒæ“ä½œï¼Œå¹¶é™¤ä»¥(1-dropout)ï¼Œ
    è¿™é‡Œä¸ä½¿ç”¨é€‰ä¸­Xä¸­å…ƒç´ ç½®0çš„åŸå› æ˜¯ç›¸ä¹˜æ“ä½œç›¸æ¯”é€‰ä¸­æ“ä½œæ›´å¿«
```

#### åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨ä¸¢å¼ƒæ³•

```
num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256

dropout1, dropout2 = 0.2, 0.5

class Net(nn.Module)
    # ç¡®è®¤æ˜¯åœ¨è®­ç»ƒé˜¶æ®µ
    def _init_(self,num_inputs,num_outputs,
    num_outputs,num_hiddens1,num_hiddens2,is_training=True):
       super(Net,self)._init_()
       self.num_inputs=num_inputs
       self.training=is_training
       self.lin1=nn.Linear(num_inputs,num_hiddens1)
       self.lin2=nn.Linear(num_hiddens1,num_hiddens2)
       self.lin2=nn.Linear(num_hiddens2,num_outputs)
       self.relu=nn.ReLU()
    
    def forward(self,X):
      H1=self.relu(self.lin1(X.reshape((-1,self.num_inputs))))
       if self.training == True:  #ä¸¢å¼ƒæ³•ä»…åœ¨è®­ç»ƒä¸­ä½¿ç”¨
           H1=dropout_layer(H1,dropout1)
       H2=self.relu(self.lin2(H1))
       if self.training == True: #ä¸¢å¼ƒæ³•ä»…åœ¨è®­ç»ƒä¸­ä½¿ç”¨
           H2=dropout_layer(H2,dropout2)
       out=self.lin3(H2)  #outputå±‚ä¸å†ä½¿ç”¨ä¸¢å¼ƒæ³•
       return out
```

ç®€æ´å®ç°

```
net = nn.Sequential(nn.Flatten(),
        nn.Linear(784, 256),
        nn.ReLU(),
        # åœ¨ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚
        nn.Dropout(dropout1),
        nn.Linear(256, 256),
        nn.ReLU(),
        # åœ¨ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚
        nn.Dropout(dropout2),
        nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights);
```







## æ•°å€¼ç¨³å®šæ€§ + æ¨¡å‹åˆå§‹åŒ–å’Œæ¿€æ´»å‡½æ•°

### æ•°å€¼ç¨³å®šæ€§

æ•°å€¼ç¨³å®šæ€§æ˜¯æ·±åº¦å­¦ä¹ ä¸­æ¯”è¾ƒé‡è¦çš„ç‚¹ï¼Œç‰¹åˆ«æ˜¯å½“ç¥ç»ç½‘ç»œå˜å¾—å¾ˆæ·±çš„æ—¶å€™ï¼Œæ•°å€¼é€šå¸¸å¾ˆå®¹æ˜“å˜å¾—ä¸ç¨³å®šã€‚

#### ç¥ç»ç½‘ç»œçš„æ¢¯åº¦

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-01.png)

**è€ƒè™‘då±‚ç¥ç»ç½‘ç»œ**

- tè¡¨ç¤ºå±‚æ•°ï¼Œ[![h^{t-1}](https://camo.githubusercontent.com/a71cebb102ebd87361c6309af0486f84cf349a20dec37eb3f2cae5bc0b90b22a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b742d317d)](https://camo.githubusercontent.com/a71cebb102ebd87361c6309af0486f84cf349a20dec37eb3f2cae5bc0b90b22a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b742d317d)è¡¨ç¤ºç¬¬*t-1*å±‚çš„è¾“å‡ºï¼Œç»è¿‡ä¸€ä¸ª[![f_{t}](https://camo.githubusercontent.com/ea7eda19f58ecfb0aa08ee4f8aa706c973834f1d814cfd6cc862932921b2ea4b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f665f7b747d)](https://camo.githubusercontent.com/ea7eda19f58ecfb0aa08ee4f8aa706c973834f1d814cfd6cc862932921b2ea4b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f665f7b747d)å‡½æ•°åï¼Œå¾—åˆ°ç¬¬*t*å±‚çš„è¾“å‡ºã€‚
- æœ€ç»ˆè¾“å‡ºyçš„è¡¨ç¤ºï¼šè¾“å…¥xç»è¿‡è‹¥å¹²å±‚(*d*å±‚)çš„å‡½æ•°ä½œç”¨ï¼Œæœ€åè¢«æŸå¤±å‡½æ•°ä½œç”¨å¾—åˆ°è¾“å‡ºyã€‚

**è®¡ç®—æŸå¤±å‡½æ•°\*L\*å…³äºç¬¬\*t\*å±‚å‚æ•°[![W_{t} ](https://camo.githubusercontent.com/cd456da509cd823ff05c8a8147686bebe7f70b0479d17469c343f39a9cc2a8d7/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575f7b747d2673706163653b)](https://camo.githubusercontent.com/cd456da509cd823ff05c8a8147686bebe7f70b0479d17469c343f39a9cc2a8d7/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575f7b747d2673706163653b)çš„æ¢¯åº¦**

- ç”±é“¾å¯¼æ³•åˆ™å¾—åˆ°ä¸Šå›¾ä¸­ä¹˜ç§¯å…¬å¼
- éœ€è¦è¿›è¡Œd-tæ¬¡**çŸ©é˜µä¹˜æ³•**ï¼ˆä¸ºä»€ä¹ˆæ˜¯çŸ©é˜µä¹˜æ³•ï¼Ÿç­”ï¼šç”±äºæ‰€æœ‰çš„*h*éƒ½æ˜¯ä¸€äº›**å‘é‡**ï¼Œå¯¼æ•°ä¸­åˆ†å­åˆ†æ¯å‡ä¸ºå‘é‡ï¼Œæ‰€ä»¥æ±‚å¯¼å¾—åˆ°çš„æ˜¯çŸ©é˜µï¼Œç»´æ•°ä¸º[åˆ†å­ç»´åº¦]x[åˆ†æ¯ç»´åº¦]ï¼Œå¯ä»¥å‚è€ƒç¬¬6èŠ‚[è§†é¢‘](https://www.bilibili.com/video/BV1eZ4y1w7PY)å’Œ[ç¬”è®°](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/notes/06-çŸ©é˜µè®¡ç®—.md)ï¼‰ã€‚è¿™ä¹Ÿæ˜¯å¯¼è‡´æ•°å€¼ç¨³å®šæ€§é—®é¢˜çš„**ä¸»è¦å› ç´ **ï¼Œç”±äºåšäº†å¤ªå¤šæ¬¡çš„çŸ©é˜µä¹˜æ³•ã€‚

#### æ•°å€¼ç¨³å®šæ€§çš„å¸¸è§ä¸¤ä¸ªé—®é¢˜

**æ¢¯åº¦çˆ†ç‚¸**

å‡è®¾æ¢¯åº¦éƒ½æ˜¯ä¸€äº›æ¯”1å¤§çš„æ•°æ¯”å¦‚1.5ï¼Œåš100æ¬¡ä¹˜ç§¯ä¹‹åå¾—åˆ°[![4\times 10^{17}](https://camo.githubusercontent.com/cb03a67eca0aab939a881ca6e61c07bfa0c7a014080a832c6ef22dba43c45436/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f345c74696d65732673706163653b31305e7b31377d)](https://camo.githubusercontent.com/cb03a67eca0aab939a881ca6e61c07bfa0c7a014080a832c6ef22dba43c45436/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f345c74696d65732673706163653b31305e7b31377d)ï¼Œè¿™ä¸ªæ•°å­—å¾ˆå®¹æ˜“å¸¦æ¥ä¸€äº›æµ®ç‚¹æ•°ä¸Šé™çš„é—®é¢˜ï¼ˆéœ€äº†è§£æ›´å¤šè¯·å‚è€ƒè®¡ç®—æœºç³»ç»Ÿ-è®¡ç®—æœºä¸­æµ®ç‚¹æ•°çš„å­˜å‚¨æ–¹å¼ï¼‰ã€‚

**æ¢¯åº¦æ¶ˆå¤±**

å‡è®¾æ¢¯åº¦éƒ½æ˜¯ä¸€äº›æ¯”1å°çš„æ•°æ¯”å¦‚0.8ï¼Œåš100æ¬¡ä¹˜ç§¯ä¹‹åå¾—åˆ°[![2\times10^{-10}](https://camo.githubusercontent.com/a231a5a2891622e8dc7f0d3a45b8e4c5fc159338ba446402166557ea948d16e4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f325c74696d657331305e7b2d31307d)](https://camo.githubusercontent.com/a231a5a2891622e8dc7f0d3a45b8e4c5fc159338ba446402166557ea948d16e4/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f325c74696d657331305e7b2d31307d)ï¼Œä¹Ÿå¯èƒ½ä¼šå¸¦æ¥æµ®ç‚¹æ•°ä¸‹æº¢çš„é—®é¢˜ã€‚

#### ä¾‹å­ï¼šMLP

æ­¤å¤„æˆ‘ä»¬ç€é‡æ¢è®¨[1.1èŠ‚](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/notes/14-æ•°å€¼ç¨³å®šæ€§.md#11-ç¥ç»ç½‘ç»œçš„æ¢¯åº¦)ä¸­æ‰€è¿°çš„æ±‚æ¢¯åº¦æ—¶æ‰€åšçš„d-tæ¬¡çŸ©é˜µä¹˜æ³•ï¼Œå¹¶ä»¥ä¸€ä¸ªå®ä¾‹MLPæ¥æ¢è®¨å…¶ç»“æœçš„å…·ä½“å½¢å¼ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-02.png)

- ç¬¬ä¸€è¡Œå…¬å¼ï¼Œå®šä¹‰[![h^{t}](https://camo.githubusercontent.com/be807542e1881c650372a6b6555cb672468be104bb488370e96db8ac22417766/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b747d)](https://camo.githubusercontent.com/be807542e1881c650372a6b6555cb672468be104bb488370e96db8ac22417766/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b747d)å’Œ[![h^{t-1}](https://camo.githubusercontent.com/a71cebb102ebd87361c6309af0486f84cf349a20dec37eb3f2cae5bc0b90b22a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b742d317d)](https://camo.githubusercontent.com/a71cebb102ebd87361c6309af0486f84cf349a20dec37eb3f2cae5bc0b90b22a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b742d317d)(å‡ä¸ºå‘é‡)çš„å‡½æ•°å…³ç³»[![f_{t}](https://camo.githubusercontent.com/ea7eda19f58ecfb0aa08ee4f8aa706c973834f1d814cfd6cc862932921b2ea4b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f665f7b747d)](https://camo.githubusercontent.com/ea7eda19f58ecfb0aa08ee4f8aa706c973834f1d814cfd6cc862932921b2ea4b/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f665f7b747d)ï¼Œç¬¬tå±‚çš„æƒé‡çŸ©é˜µä½œç”¨äºt-1å±‚çš„è¾“å‡º[![h^{t-1}](https://camo.githubusercontent.com/a71cebb102ebd87361c6309af0486f84cf349a20dec37eb3f2cae5bc0b90b22a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b742d317d)](https://camo.githubusercontent.com/a71cebb102ebd87361c6309af0486f84cf349a20dec37eb3f2cae5bc0b90b22a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b742d317d)åç»è¿‡æ¿€æ´»å‡½æ•°[![\sigma ](https://camo.githubusercontent.com/ebf39e7aad643a5167823309290a6aafec495508d69747797eb052e48131fded/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7369676d612673706163653b)](https://camo.githubusercontent.com/ebf39e7aad643a5167823309290a6aafec495508d69747797eb052e48131fded/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7369676d612673706163653b)å¾—åˆ°[![h^{t}](https://camo.githubusercontent.com/be807542e1881c650372a6b6555cb672468be104bb488370e96db8ac22417766/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b747d)](https://camo.githubusercontent.com/be807542e1881c650372a6b6555cb672468be104bb488370e96db8ac22417766/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685e7b747d)ï¼Œæ³¨æ„æ¿€æ´»å‡½æ•°[![\sigma ](https://camo.githubusercontent.com/ebf39e7aad643a5167823309290a6aafec495508d69747797eb052e48131fded/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7369676d612673706163653b)](https://camo.githubusercontent.com/ebf39e7aad643a5167823309290a6aafec495508d69747797eb052e48131fded/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7369676d612673706163653b)é€å…ƒç´ è®¡ç®—ã€‚

- ç¬¬äºŒè¡Œå…¬å¼ï¼šè¿™é‡Œç”¨åˆ°é“¾å¯¼æ³•åˆ™ï¼Œæ¿€æ´»å‡½æ•°[![\sigma ](https://camo.githubusercontent.com/ebf39e7aad643a5167823309290a6aafec495508d69747797eb052e48131fded/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7369676d612673706163653b)](https://camo.githubusercontent.com/ebf39e7aad643a5167823309290a6aafec495508d69747797eb052e48131fded/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7369676d612673706163653b)å…ˆå¯¹å†…éƒ¨å‘é‡é€å…ƒç´ æ±‚å¯¼ï¼Œç„¶åæŠŠæ±‚å¯¼åè¿™ä¸ªå‘é‡å˜æˆå¯¹è§’çŸ©é˜µï¼ˆå¯ä»¥ç†è§£ä¸ºé“¾å¯¼æ³•åˆ™ä¸­å†…éƒ¨å‘é‡[![W_{t}h_{t-1}](https://camo.githubusercontent.com/2e6701f04d89ef9b5335964cbec64476b9ddadb5b6ca6bc64d73b2b8009f06c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575f7b747d685f7b742d317d)](https://camo.githubusercontent.com/2e6701f04d89ef9b5335964cbec64476b9ddadb5b6ca6bc64d73b2b8009f06c9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575f7b747d685f7b742d317d)å¯¹è‡ªèº«è¿›è¡Œæ±‚å¯¼ï¼Œå˜æˆä¸€ä¸ªnxnçš„å¯¹è§’çŸ©é˜µï¼Œæ›´å¤šè¯·å‚è€ƒ[é‚±é”¡é¹ ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹](https://nndl.github.io/nndl-book.pdf)[1](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/notes/14-æ•°å€¼ç¨³å®šæ€§.md#user-content-fn-å›¾ç‰‡1-2bb18940390e507adda6b4ee943dcd6a)ï¼‰

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-03.png)

- è§†é¢‘ä¸­**å‹˜è¯¯è¯´æ˜**ï¼šé“¾å¯¼æ³•åˆ™ä¸­ [![\frac{\partial W^{t}h^{t-1}}{\partial h^{t-1}}= W^{t}](https://camo.githubusercontent.com/71fa9f16c839f40f6fe979e6f72bc88ddf24c3d304e576cf6463c3ad09e6a010/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c667261637b5c7061727469616c2673706163653b575e7b747d685e7b742d317d7d7b5c7061727469616c2673706163653b685e7b742d317d7d3d2673706163653b575e7b747d)](https://camo.githubusercontent.com/71fa9f16c839f40f6fe979e6f72bc88ddf24c3d304e576cf6463c3ad09e6a010/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c667261637b5c7061727469616c2673706163653b575e7b747d685e7b742d317d7d7b5c7061727469616c2673706163653b685e7b742d317d7d3d2673706163653b575e7b747d) è€Œä¸æ˜¯[![\left (W^{t} \right )^{T}](https://camo.githubusercontent.com/83dc04c534c36c75a02d9516553d3555aef6df231859509223a9953a04942948/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c6c6566742673706163653b28575e7b747d2673706163653b2673706163653b5c72696768742673706163653b295e7b547d)](https://camo.githubusercontent.com/83dc04c534c36c75a02d9516553d3555aef6df231859509223a9953a04942948/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c6c6566742673706163653b28575e7b747d2673706163653b2673706163653b5c72696768742673706163653b295e7b547d)ï¼ˆè¿™ç‚¹ç”±åˆ†å­åˆ†æ¯ç»´åº¦ä¹Ÿå®¹æ˜“æ¨å‡ºï¼‰ï¼Œæ•…æœ€ç»ˆæ±‚å¯¼ç»“æœåŒ…å«[![W^{t}](https://camo.githubusercontent.com/90fa60edb85fc018d18ff5c3e21e28f3c075a514b1c31cba204dba5995760657/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575e7b747d)](https://camo.githubusercontent.com/90fa60edb85fc018d18ff5c3e21e28f3c075a514b1c31cba204dba5995760657/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575e7b747d)ï¼Œè€Œä¸æ˜¯å…¶è½¬ç½®ã€‚

#### æ¢¯åº¦çˆ†ç‚¸

##### ä½¿ç”¨ReLUä½œä¸ºæ¿€æ´»å‡½æ•°



[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-04.png)

ç”±äºæ¿€æ´»å‡½æ•°Reluæ±‚å¯¼åæˆ–è€…æ˜¯1æˆ–è€…æ˜¯0ï¼Œå˜ä¸ºå¯¹è§’çŸ©é˜µçš„æ–œå¯¹è§’çº¿å…ƒç´ åï¼Œä¸[![W^{i}](https://camo.githubusercontent.com/b672ed6c4894aead93fb0506d22544a527353e71b36e572f7dd042825883dbb3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575e7b697d)](https://camo.githubusercontent.com/b672ed6c4894aead93fb0506d22544a527353e71b36e572f7dd042825883dbb3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575e7b697d)åšä¹˜ç§¯ï¼Œæ–œå¯¹è§’çº¿ä¸º1çš„éƒ¨åˆ†ä¼šä½¿å¾—Wä¸­å…ƒç´ ä¿ç•™ï¼Œæœ€ç»ˆè¯¥è¿ä¹˜å¼ä¸­æœ‰ä¸€äº›å…ƒç´ æ¥è‡ª[![\prod\left ( W^{i} \right ) ](https://camo.githubusercontent.com/4eb293144f80b51159f7c69a62a047aad97e5d9bbe61e83f4fe6234323f63360/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c70726f645c6c6566742673706163653b282673706163653b575e7b697d2673706163653b5c72696768742673706163653b292673706163653b)](https://camo.githubusercontent.com/4eb293144f80b51159f7c69a62a047aad97e5d9bbe61e83f4fe6234323f63360/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c70726f645c6c6566742673706163653b282673706163653b575e7b697d2673706163653b5c72696768742673706163653b292673706163653b)ï¼Œå¦‚æœå¤§éƒ¨åˆ†[![W^{i}](https://camo.githubusercontent.com/b672ed6c4894aead93fb0506d22544a527353e71b36e572f7dd042825883dbb3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575e7b697d)](https://camo.githubusercontent.com/b672ed6c4894aead93fb0506d22544a527353e71b36e572f7dd042825883dbb3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f575e7b697d)ä¸­ å€¼éƒ½å¤§äº1ï¼Œä¸”å±‚æ•°æ¯”è¾ƒå¤§ï¼Œé‚£ä¹ˆè¿ä¹˜ä¹‹åå¯èƒ½å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ã€‚

##### æ¢¯åº¦çˆ†ç‚¸é—®é¢˜

- å€¼è¶…å‡ºå€¼åŸŸï¼ˆinfinityï¼‰
  - å¯¹äº16ä½æµ®ç‚¹æ•°å°¤ä¸ºä¸¥é‡ï¼ˆæ•°å€¼åŒºé—´ [6e-5 , 6e4]ï¼‰ï¼ŒGPUç”¨16ä½æµ®ç‚¹æ•°æ›´å¿«
- å¯¹å­¦ä¹ ç‡æ•æ„Ÿ
  - å¦‚æœå­¦ä¹ ç‡å¤ªå¤§â†’å¤§å‚æ•°å€¼â†’æ›´å¤§çš„æ¢¯åº¦ï¼Œå¦‚æ­¤å¾ªç¯å‡ æ¬¡ï¼Œå®¹æ˜“å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
  - å¦‚æœå­¦ä¹ ç‡å¤ªå°â†’è®­ç»ƒæ— è¿›å±•
  - æˆ‘ä»¬å¯èƒ½éœ€è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­è°ƒæ•´å­¦ä¹ ç‡

#### æ¢¯åº¦æ¶ˆå¤±

##### ä½¿ç”¨Sigmoidä½œä¸ºæ¿€æ´»å‡½æ•°

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-05.png)

- è“è‰²æ›²çº¿ä¸ºå‡½æ•°å€¼
- é»„è‰²æ›²çº¿ä¸ºæ¢¯åº¦ï¼Œæ³¨æ„åˆ°å½“è¾“å…¥xå€¼å–Â±6æ—¶ï¼Œæ­¤æ—¶æ¢¯åº¦å·²ç»å˜å¾—å¾ˆå°ï¼Œç”±å›¾ä¹Ÿå¯ä»¥çœ‹å‡ºï¼Œå½“è¾“å…¥å€¼ç¨å¤§æˆ–ç¨å°éƒ½å¾ˆå®¹æ˜“å¼•èµ·å°æ¢¯åº¦ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-06.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-06.png)

æ‰€ä»¥æœ€ç»ˆè¿ä¹˜å¼ä¸­[![\prod diag\left ( \sigma ^{'}\left ( W^{i}h^{i-1} \right ) \right ) ](https://camo.githubusercontent.com/ed117f76d7cda611a8d81fcae67f6bf383bce937de9b079c5ccaaf30bdb6c5b8/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c70726f642673706163653b646961675c6c6566742673706163653b282673706163653b5c7369676d612673706163653b5e7b277d5c6c6566742673706163653b282673706163653b575e7b697d685e7b692d317d2673706163653b5c72696768742673706163653b292673706163653b5c72696768742673706163653b292673706163653b)](https://camo.githubusercontent.com/ed117f76d7cda611a8d81fcae67f6bf383bce937de9b079c5ccaaf30bdb6c5b8/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c70726f642673706163653b646961675c6c6566742673706163653b282673706163653b5c7369676d612673706163653b5e7b277d5c6c6566742673706163653b282673706163653b575e7b697d685e7b692d317d2673706163653b5c72696768742673706163653b292673706163653b5c72696768742673706163653b292673706163653b)é¡¹ä¹˜å‡ºæ¥ä¼šå¾ˆå°ï¼Œå¯¼è‡´æ•´ä¸ªæ¢¯åº¦å¾ˆå°ï¼Œäº§ç”Ÿæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚

##### æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜

- æ¢¯åº¦å€¼å˜ä¸º0
  - å¯¹16ä½æµ®ç‚¹æ•°å°¤ä¸ºä¸¥é‡
- è®­ç»ƒæ²¡æœ‰è¿›å±•
  - ä¸ç®¡å¦‚ä½•é€‰æ‹©å­¦ä¹ ç‡ï¼Œç”±äºæ¢¯åº¦å·²ç»ä¸º0äº†ï¼Œå­¦ä¹ ç‡xæ¢¯åº¦=0
- å¯¹äºåº•éƒ¨å±‚å°¤ä¸ºä¸¥é‡
  - ä»…ä»…é¡¶éƒ¨å±‚è®­ç»ƒå¾—è¾ƒå¥½ã€‚ç¬¬*t*å±‚å¯¼æ•°åŒ…å«d-tä¸ªçŸ©é˜µä¹˜ç§¯ï¼Œè¶Šå¾€åº•å±‚èµ°ï¼Œtè¶Šå°ï¼Œä¹˜å¾—è¶Šå¤šï¼Œæ¢¯åº¦æ¶ˆå¤±è¶Šä¸¥é‡ï¼Œæ‰€ä»¥åº•éƒ¨å±‚æ•ˆæœæ›´å·®ã€‚
  - æ— æ³•è®©ç¥ç»ç½‘ç»œæ›´æ·±ã€‚åªèƒ½æŠŠé¡¶éƒ¨å±‚è®­ç»ƒå¾—æ¯”è¾ƒå¥½ï¼Œåº•éƒ¨å±‚è·‘ä¸åŠ¨ï¼Œè¿™å’Œç»™ä¸€ä¸ªæµ…çš„ç¥ç»ç½‘ç»œæ²¡æœ‰ä»€ä¹ˆåŒºåˆ«ã€‚

### æ¨¡å‹åˆå§‹åŒ–å’Œæ¿€æ´»å‡½æ•°

#### è®©è®­ç»ƒæ›´åŠ ç¨³å®š

æˆ‘ä»¬çš„ä¸€ä¸ªæ ¸å¿ƒç›®æ ‡æ˜¯å¦‚ä½•è®©è®­ç»ƒæ›´ç¨³å®šï¼Œæ¢¯åº¦å€¼ä¸è¦å¤ªå¤§ä¹Ÿä¸è¦å¤ªå°

- ç›®æ ‡ï¼šè®©æ¢¯åº¦å€¼åœ¨åˆç†çš„èŒƒå›´å†…
  - ä¾‹å¦‚ [1e-6, 1e3]
- å¸¸ç”¨æ–¹æ³•ï¼š
  - å°†ä¹˜æ³•å˜åŠ æ³•ï¼š
    - ResNetï¼ˆè·³è·ƒè¿æ¥ï¼Œå¦‚æœå¾ˆå¤šå±‚ï¼ŒåŠ å…¥åŠ æ³•è¿›å»ï¼‰
    - LSTMï¼ˆå¼•å…¥è®°å¿†ç»†èƒï¼Œæ›´æ–°é—¨ï¼Œé—å¿˜é—¨ï¼Œé€šè¿‡é—¨æƒé‡æ±‚å’Œï¼Œæ§åˆ¶ä¸‹ä¸€æ­¥æ˜¯å¦æ›´æ–°ï¼‰
  - å½’ä¸€åŒ–ï¼š
    - æ¢¯åº¦å½’ä¸€åŒ–ï¼ˆå½’ä¸€åŒ–å‡å€¼ï¼Œæ–¹å·®ï¼‰
    - æ¢¯åº¦è£å‰ª(clipping)ï¼šæ¯”å¦‚å¤§äº/å°äºä¸€ä¸ªå›ºå®šçš„é˜ˆå€¼ï¼Œå°±è®©æ¢¯åº¦ç­‰äºè¿™ä¸ªé˜ˆå€¼ï¼Œå°†æ¢¯åº¦é™åˆ¶åœ¨ä¸€ä¸ªèŒƒå›´ä¸­ã€‚ï¼ˆå¯ä»¥ç¼“è§£æ¢¯åº¦çˆ†ç‚¸ï¼‰
  - åˆç†çš„æƒé‡åˆå§‹å’Œæ¿€æ´»å‡½æ•°ï¼šæœ¬èŠ‚è¯¾è®²è¿°é‡ç‚¹

**ä¸‹é¢æˆ‘ä»¬é‡ç‚¹æ¢è®¨æœ€åä¸€ç§æ–¹æ³•ï¼šåˆç†çš„æƒé‡åˆå§‹å’Œæ¿€æ´»å‡½æ•°**

#### åŸºæœ¬å‡è®¾ï¼šè®©æ¯å±‚çš„å‡å€¼/æ–¹å·®æ˜¯ä¸€ä¸ªå¸¸æ•°

- **å°†æ¯å±‚çš„è¾“å‡ºå’Œæ¢¯åº¦éƒ½çœ‹åšéšæœºå˜é‡**

  æ¯”å¦‚ç¬¬iå±‚æœ‰100ç»´ï¼Œå°±å°†è¾“å‡ºå’Œæ¢¯åº¦åˆ†åˆ«çœ‹æˆ100ä¸ªéšæœºå˜é‡

- **è®©å®ƒä»¬çš„å‡å€¼å’Œæ–¹å·®éƒ½ä¿æŒä¸€è‡´**

  æˆ‘ä»¬çš„ç›®æ ‡ï¼Œè¿™æ ·ä¸ç®¡ç¥ç»ç½‘ç»œå¤šæ·±ï¼Œæœ€åä¸€å±‚æ€»ä¸ç¬¬ä¸€å±‚å·®ä¸å¤šï¼Œä»è€Œä¸ä¼šæ¢¯åº¦çˆ†ç‚¸å’Œæ¶ˆå¤±

æ ¹æ®æˆ‘ä»¬çš„å‡è®¾ï¼Œå¯ä»¥åˆ—å‡ºå¦‚ä¸‹æ–¹ç¨‹å¼ï¼š

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-07.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-07.png)

#### æƒé‡åˆå§‹åŒ–

- åœ¨åˆç†å€¼åŒºé—´é‡Œéšæœºåˆå§‹å‚æ•°

- è®­ç»ƒ

  å¼€å§‹

  çš„æ—¶å€™æ›´å®¹æ˜“æœ‰æ•°å€¼ä¸ç¨³å®š

  - è¿œç¦»æœ€ä¼˜è§£çš„åœ°æ–¹æŸå¤±å‡½æ•°è¡¨é¢å¯èƒ½å¾ˆå¤æ‚
  - æœ€ä¼˜è§£é™„è¿‘è¡¨é¢ä¼šæ¯”è¾ƒå¹³

- ä½¿ç”¨N(0, 0.01)åˆ†å¸ƒæ¥åˆå§‹å¯èƒ½å¯¹å°ç½‘ç»œæ²¡é—®é¢˜ï¼Œä½†ä¸èƒ½ä¿è¯æ·±åº¦ç¥ç»ç½‘ç»œ

#### ä¾‹å­ï¼šMLP

ä¸‹é¢æˆ‘ä»¬ä»¥MLPä¸ºä¾‹ï¼Œè€ƒè™‘éœ€è¦ä»€ä¹ˆæ¡ä»¶ï¼Œæ‰èƒ½æ»¡è¶³[2.2èŠ‚](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/notes/14-æ•°å€¼ç¨³å®šæ€§.md#22-åŸºæœ¬å‡è®¾ï¼šè®©æ¯å±‚çš„å‡å€¼/æ–¹å·®æ˜¯ä¸€ä¸ªå¸¸æ•°)çš„å‡è®¾ã€‚

##### æ¨¡å‹å‡è®¾

- æ¯ä¸€å±‚**æƒé‡**ä¸­çš„å˜é‡å‡ä¸º**ç‹¬ç«‹åŒåˆ†å¸ƒ**ï¼Œå¹¶è®¾å‡ºå‡å€¼ã€æ–¹å·®ã€‚
- æ¯ä¸€å±‚**è¾“å…¥**çš„å˜é‡**ç‹¬ç«‹äº**è¯¥å±‚**æƒé‡**å˜é‡ã€‚åŒæ—¶**è¾“å…¥å˜é‡**ä¹‹é—´**ç‹¬ç«‹åŒåˆ†å¸ƒ**ã€‚
- å‡è®¾æ²¡æœ‰æ¿€æ´»å‡½æ•°(å…ˆç®€åŒ–åˆ†æï¼Œä¹‹åä¼šè€ƒè™‘æœ‰æ¿€æ´»å‡½æ•°çš„æƒ…å†µ)ï¼Œå¯ä»¥æ±‚å¾—è¯¥å±‚è¾“å‡ºçš„æœŸæœ›ä¸º0ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-08.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-08.png)

æ­¤å¤„ç”¨åˆ°äº†ä¸€ä¸ªé‡è¦æ€§è´¨ï¼š

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-09.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-09.png)

æ›´å¤šå‡å€¼ã€æ–¹å·®è¿ç®—å¯ä»¥å‚è€ƒ[æœŸæœ›ã€æ–¹å·®ã€åæ–¹å·®åŠç›¸å…³ç³»æ•°çš„åŸºæœ¬è¿ç®—](https://blog.csdn.net/MissXy_/article/details/80705828)

##### æ­£å‘æ–¹å·®

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-10.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-10.png)

- ç¬¬äºŒè¡Œçš„è®¡ç®—ä¸­ä»ç„¶ç”¨åˆ°äº†[2.4.1èŠ‚](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/notes/241æ¨¡å‹å‡è®¾)çš„æœŸæœ›çš„é‡è¦æ€§è´¨ï¼šå¦‚æœä¸¤ä¸ªå˜é‡ç‹¬ç«‹ï¼Œå®ƒä»¬ä¹˜ç§¯çš„å‡å€¼=å‡å€¼çš„ä¹˜ç§¯ï¼Œå†ç»“åˆwçš„æœŸæœ›ä¸º0(æ³¨æ„wå’Œhç‹¬ç«‹ï¼Œwä¹‹é—´ç‹¬ç«‹åŒåˆ†å¸ƒ)ï¼Œå³æœ‰ç¬¬äºŒè¡Œæœ«é¡¹æœŸæœ›ä¸º0ã€‚
- æœ€åä¸€è¡Œç”±äºwi,jç‹¬ç«‹åŒåˆ†å¸ƒï¼Œæ–¹å·®ç›¸åŒï¼ŒåŠ ä¸Šåšäº†hjç‹¬ç«‹åŒåˆ†å¸ƒçš„å‡è®¾ï¼Œæ‰€ä»¥å¯ä»¥å†™æˆ **[t-1å±‚è¾“å‡ºç»´åº¦] x [tå±‚æƒé‡æ–¹å·®] x [t-1å±‚è¾“å‡ºæ–¹å·®]** çš„å½¢å¼
- æ­¤æ—¶ï¼Œæˆ‘ä»¬å›è¿‡å¤´æ¥çœ‹æˆ‘ä»¬çš„ç»ˆæç›®æ ‡[2.2èŠ‚](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/notes/14-æ•°å€¼ç¨³å®šæ€§.md#22-åŸºæœ¬å‡è®¾ï¼šè®©æ¯å±‚çš„å‡å€¼/æ–¹å·®æ˜¯ä¸€ä¸ªå¸¸æ•°)çš„å‡è®¾ï¼Œæ¯å±‚è¾“å‡ºæœŸæœ›ä¸º0æˆ‘ä»¬å·²ç»å¯ä»¥æ»¡è¶³(2.4.1èŠ‚å·²ç»æ¨å¯¼å‡º)ï¼Œè€Œæ–¹å·®ç›¸åŒè¿™ä¸€ç›®æ ‡ï¼Œé€šè¿‡ä¸Šå›¾çš„æ¨å¯¼ï¼Œæˆ‘ä»¬å‘ç°éœ€è¦[![ n_{t-1}\gamma _{t}=1 ](https://camo.githubusercontent.com/f78bf82d006b08b156283f8f36616c89d1f31532215546b92819e2cc772c773a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b742d317d5c67616d6d612673706163653b5f7b747d3d312673706163653b)](https://camo.githubusercontent.com/f78bf82d006b08b156283f8f36616c89d1f31532215546b92819e2cc772c773a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b742d317d5c67616d6d612673706163653b5f7b747d3d312673706163653b)ã€‚

##### åå‘å‡å€¼å’Œæ–¹å·®

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-11.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-11.png)

åå‘çš„æƒ…å†µå’Œæ­£å‘çš„ç±»ä¼¼ï¼Œä¸è¿‡æ­¤æ—¶æˆ‘ä»¬éœ€è¦æ»¡è¶³çš„å¼å­å˜ä¸º[![ n_{t}\gamma _{t}=1 ](https://camo.githubusercontent.com/9b5cf0aa698dc23314756d854eac930e1469588685dffa3b9fbefeec54b963a6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b747d5c67616d6d612673706163653b5f7b747d3d312673706163653b)](https://camo.githubusercontent.com/9b5cf0aa698dc23314756d854eac930e1469588685dffa3b9fbefeec54b963a6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b747d5c67616d6d612673706163653b5f7b747d3d312673706163653b)ã€‚

##### Xavieråˆå§‹

- ä¸Šè¿°æ¨å¯¼å¸¦æ¥çš„é—®é¢˜ï¼šéš¾ä»¥åŒæ—¶æ»¡è¶³[![ n_{t-1}\gamma _{t}=1 ](https://camo.githubusercontent.com/f78bf82d006b08b156283f8f36616c89d1f31532215546b92819e2cc772c773a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b742d317d5c67616d6d612673706163653b5f7b747d3d312673706163653b)](https://camo.githubusercontent.com/f78bf82d006b08b156283f8f36616c89d1f31532215546b92819e2cc772c773a/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b742d317d5c67616d6d612673706163653b5f7b747d3d312673706163653b)å’Œ[![ n_{t}\gamma _{t}=1 ](https://camo.githubusercontent.com/9b5cf0aa698dc23314756d854eac930e1469588685dffa3b9fbefeec54b963a6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b747d5c67616d6d612673706163653b5f7b747d3d312673706163653b)](https://camo.githubusercontent.com/9b5cf0aa698dc23314756d854eac930e1469588685dffa3b9fbefeec54b963a6/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f2673706163653b6e5f7b747d5c67616d6d612673706163653b5f7b747d3d312673706163653b)ã€‚ï¼ˆéœ€è¦æ¯å±‚è¾“å‡ºçš„ç»´åº¦éƒ½ç›¸åŒï¼‰

- é‡‡ç”¨XavieræŠ˜ä¸­è§£å†³ï¼Œä¸èƒ½åŒæ—¶æ»¡è¶³ä¸Šé¢ä¸¤å¼ï¼Œè½¬è€Œæ»¡è¶³ [**ä¸Šé¢ä¸¤å¼åšåŠ æ³•åé™¤ä»¥2**] å¾—åˆ°çš„å¼å­ï¼Œç”¨ä¸¤ç§åˆ†å¸ƒè¿›è¡Œåˆå§‹åŒ–ï¼ˆæ¯å±‚æ–¹å·®ã€å‡å€¼æ»¡è¶³æ¨å¯¼å¼ï¼‰ã€‚

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-12.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-12.png)

- å¦‚æœèƒ½ç¡®å®šæ¯å±‚è¾“å…¥ã€è¾“å‡ºç»´åº¦å¤§å°ï¼Œåˆ™èƒ½ç¡®å®šè¯¥å±‚æƒé‡çš„æ–¹å·®å¤§å°ã€‚

- æƒé‡åˆå§‹åŒ–æ–¹å¼ï¼šæ­£æ€åˆ†å¸ƒã€å‡åŒ€åˆ†å¸ƒï¼Œå‡å€¼/æ–¹å·®æ»¡è¶³Xavierçš„å‡è®¾ã€‚

##### å‡è®¾çº¿æ€§çš„æ¿€æ´»å‡½æ•°

çœŸå®æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¹¶ä¸ä¼šç”¨çº¿æ€§çš„æ¿€æ´»å‡½æ•°ï¼ˆè¿™æ ·ç›¸å½“äºæ²¡æœ‰è¿›è¡Œæ¿€æ´»ï¼‰ï¼Œè¿™é‡Œä¸ºäº†ç®€åŒ–é—®é¢˜ï¼Œå‡è®¾æ¿€æ´»å‡½æ•°æ˜¯çº¿æ€§çš„ã€‚

- **æ­£å‘**

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-13.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-13.png)

ä¸Šè¿°æ¨å¯¼è¡¨æ˜ï¼Œä¸ºäº†ä½¿å¾—å‰å‘ä¼ æ’­çš„å‡å€¼ä¸º0ï¼Œæ–¹å·®å›ºå®šçš„è¯ï¼Œæ¿€æ´»å‡½æ•°å¿…é¡»f(x)=xï¼Œè¿™ç§æ’ç­‰æ˜ å°„ã€‚

- **åå‘**

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-14.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-14.png)

PPTä¸Šçš„æ¨å¯¼ä¼¼ä¹æœ‰ç‚¹é—®é¢˜ï¼ˆä¸Šå›¾ä¸­ç¬¬äºŒè¡Œæ–¹ç¨‹ï¼‰ï¼Œç¬”è€…é‡æ–°è¿›è¡Œäº†ä¸‹è¿°æ¨å¯¼ï¼Œè¯»è€…ä¹Ÿå¯è‡ªè¡Œæ¨å¯¼éªŒè¯ï¼š

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-15.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-15.png)

**é€šè¿‡æ­£å‘å’Œåå‘çš„æ¨å¯¼ï¼Œæˆ‘ä»¬å¯ä»¥å¾—å‡ºçš„ã€ç»“è®ºã€‘æ˜¯ï¼šå½“æ¿€æ´»å‡½æ•°ä¸ºf(x)=xï¼Œè¿™ç§æ’ç­‰æ˜ å°„æ›´æœ‰åˆ©äºç»´æŒç¥ç»ç½‘ç»œçš„ç¨³å®šæ€§ã€‚**

##### æ£€æŸ¥å¸¸ç”¨æ¿€æ´»å‡½æ•°

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/14/14-16.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/14/14-16.png)

å¯¹äºå¸¸ç”¨æ¿€æ´»å‡½æ•°ï¼štanhï¼Œreluæ»¡è¶³åœ¨é›¶ç‚¹é™„è¿‘æœ‰f(x)=xï¼Œè€Œsigmoidå‡½æ•°åœ¨é›¶ç‚¹é™„è¿‘ä¸æ»¡è¶³è¦æ±‚ï¼Œå¯ä»¥å¯¹sigmoidå‡½æ•°è¿›è¡Œè°ƒæ•´ï¼ˆæ ¹æ®Taylorå±•å¼€å¼ï¼Œè°ƒæ•´å…¶è¿‡åŸç‚¹ï¼‰

### æ€»ç»“

- å½“æ•°å€¼è¿‡å¤§æˆ–è€…è¿‡å°æ—¶ï¼Œä¼šå¯¼è‡´æ•°å€¼é—®é¢˜ã€‚
- å¸¸å‘ç”Ÿåœ¨æ·±åº¦æ¨¡å‹ä¸­ï¼Œå› ä¸ºå…¶ä¼šå¯¹nä¸ªæ•°ç´¯ä¹˜ã€‚
- åˆç†çš„æƒé‡åˆå§‹å€¼(å¦‚Xavier)å’Œæ¿€æ´»å‡½æ•°çš„é€‰å–(å¦‚relu, tanh, è°ƒæ•´åçš„sigmoid)å¯ä»¥æå‡æ•°å€¼ç¨³å®šæ€§ã€‚





## å®æˆ˜

```
import hashlib  #è¿™ä¸ªæ¨¡å—å¯ä»¥ç”¨äºç”Ÿæˆæ–‡ä»¶å“ˆå¸Œå€¼
import os  #å¤„ç†æ–‡ä»¶å’Œç›®å½•
import tarfile  #å¤„ç†.tarå’Œ.tar.gzæ–‡ä»¶
import zipfile  #ç”¨äºå¤„ç†.zipæ–‡ä»¶
import requests  

DATA_HUB = dict()
DATA_URL = ###

# cache_dirä¸ºç¼“å­˜ç›®å½•ï¼Œé»˜è®¤å€¼ä¸º.../data
def download(name,cache_dir=os.path.join('..','data')):
	# æ£€æŸ¥åå­—æ˜¯å¦å­˜åœ¨
	assert name in DATA_HUB,f"{name} ä¸å­˜åœ¨äº {DATA_HUB}"
	# è·å–æ•°æ®é›†çš„ URL å’Œ SHA1 å“ˆå¸Œå€¼
	url,sha1_hash = DATA_HUB[name]
	# åˆ›å»ºç¼“å­˜ç›®å½•
	os.makedirs(cash_dir,exist_ok=True)
	fname = os.path.join(cach_dir,url.split('/')[-1])
	if os.path.exists(fname):
		sha1 = hashlib.sha1()
			with open(fname,'rb') as f:
                while True:
                    data = f.read(1048576):
                    if not data:
                        break
                    sha1.update(data)
            if sha1.hexdigest() == sha1_hash:
            	return fname
    print(f'æ­£åœ¨ä»{url}ä¸‹è½½{fname}...')
    r = requests.get(url, stream=True, verify=True)
    with open(fname, 'wb') as f:
        f.write(r.content)
    return fname

def download_extract(name, folder=None):  #@save
    """ä¸‹è½½å¹¶è§£å‹zip/taræ–‡ä»¶"""
    fname = download(name)
    base_dir = os.path.dirname(fname)
    data_dir, ext = os.path.splitext(fname)
    if ext == '.zip':
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('.tar', '.gz'):
        fp = tarfile.open(fname, 'r')
    else:
        assert False, 'åªæœ‰zip/taræ–‡ä»¶å¯ä»¥è¢«è§£å‹ç¼©'
    fp.extractall(base_dir)
    return os.path.join(base_dir, folder) if folder else data_dir

def download_all():  #@save
    """ä¸‹è½½DATA_HUBä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
    for name in DATA_HUB:
        download(name)
```

æ•°æ®å±•ç¤º-æ•°æ®å¤„ç†ï¼ˆä¸éœ€è¦çš„æ•°å€¼åˆ é™¤ï¼Œç¼ºå¤±å€¼æ›¿æ¢ï¼Œå¤„ç†ç¦»æ•£å€¼æˆ‘ä»¬ç”¨one-hotç¼–ç æ¥æ›¿æ¢å®ƒä»¬ï¼‰-ä»pandasæ ¼å¼ä¸­æå–NUMPYæ ¼å¼ï¼Œå¹¶å°†å…¶è½¬åŒ–æˆå¼ é‡å½¢å¼

å¯¹äºæ•°æ®é¢„å¤„ç†éƒ¨åˆ†ï¼š

![image-20240703193142034](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240703193142034.png)

```
import numpy as np
import pandas as pd
import torch
from torch import nn
from d2l import torch as d2l

#è¯»å–æ•°æ®
train_data = pd.read.csv((download('kaggle_house_train'))
test_data = pd.read_csv(download('kaggle_house_test'))

#è¯»å–æ•°æ®é›†å½¢çŠ¶
print(train_data.shape)
print(test_data.shape)

# è¯»å–æ•°æ®é›†ç‰¹å¾åŠå¯¹åº”æ ‡ç­¾
print(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])

ç”±äºIDä¸æ•°æ®é›†æœ¬èº«æ— å¤ªå¤§å…³è”ï¼ˆä¸æºå¸¦é¢„æµ‹ä¿¡æ¯ï¼‰
all_features = pd.concat((train_data.iloc[:,1:-1],test_data[:,1:]))

## æ•°æ®é¢„å¤„ç†
# å°†æ‰€æœ‰ç¼ºå¤±çš„å€¼æ›¿æ¢ä¸ºç›¸åº”ç‰¹å¾çš„å¹³å‡å€¼ã€‚é€šè¿‡å°†ç‰¹å¾é‡æ–°ç¼©æ”¾åˆ°é›¶å‡å€¼å’Œå•ä½æ–¹å·®æ¥æ ‡å‡†åŒ–æ•°æ®
# è‹¥æ— æ³•è·å¾—æµ‹è¯•æ•°æ®ï¼Œåˆ™å¯æ ¹æ®è®­ç»ƒæ•°æ®è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
numeric_features = all_features.dtype[all_features.dtype!='object'].index
all_features[numeric_features] = all_features[numeric_features].apply(lambd x:(x-x.mean())/x.std())
# åœ¨æ ‡å‡†åŒ–æ•°æ®ä¹‹åï¼Œæ‰€æœ‰å‡å€¼æ¶ˆå¤±ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥å°†ç¼ºå¤±å€¼è®¾ç½®ä¸º0
all_features[numeric_features] = all_features[numeric_features].fillna(0)


# å¤„ç†ç¦»æ•£å€¼ è‹¥ç‰¹å¾ä»…æœ‰ä¸¤ä¸ªå€¼1åˆ™ä¸€ä¸ªçœ‹ä½œ0ï¼Œå¦ä¸€ä¸ªçœ‹ä½œ1
# ä½¿ç”¨ pd.get_dummies å‡½æ•°è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼ˆOne-Hot Encodingï¼‰å’Œå¤„ç†ç¼ºå¤±å€¼çš„ç›®çš„æ˜¯å°†ç±»åˆ«å‹ç‰¹å¾è½¬æ¢ä¸ºé€‚åˆæœºå™¨å­¦ä¹ ç®—æ³•çš„æ•°å€¼æ ¼å¼ã€‚
# â€œDummy_na=Trueâ€å°†â€œnaâ€ï¼ˆç¼ºå¤±å€¼ï¼‰è§†ä¸ºæœ‰æ•ˆçš„ç‰¹å¾å€¼ï¼Œå¹¶ä¸ºå…¶åˆ›å»ºæŒ‡ç¤ºç¬¦ç‰¹å¾
all_features = pd.get_dummies(all_features,dummy_na=True)
all_features.shape


## é€šè¿‡valueså±æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ [ä»pandasæ ¼å¼ä¸­æå–NumPyæ ¼å¼ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¼ é‡è¡¨ç¤º]ç”¨äºè®­ç»ƒã€‚
n_train= train.data.shape[0]
train_featrue = torch.tensor(all_features[:n_train].values,dtype=torch.float32)
test_featrue = torch.tensor(all_features[n_train:].values,dtype=torch.float32)
train_labels = torch.tensor(train_data.SalePrices.values.reshape(-1:1),dtype=torch.float32)
```

è®­ç»ƒ

![image-20240703195033844](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240703195033844.png)

```
#å¸¦æŸå¤±å¹³æ–¹çš„çº¿æ€§æ¨¡å‹ï¼ˆbaseï¼‰
loss = nn.MSELoss
in_features = train_features.shape[1]

def get_nn():
	net = nn.Sequential(nn.linear(infeatures,1))
	return net
	
	
# ä½¿ç”¨ç›¸å¯¹è¯¯å·®ï¼ˆç”±äºæ•°æ®å€¼ç›¸å·®è¾ƒå¤§ï¼‰
def log_rmse(net, features, labels):
    # ä½¿ç”¨ torch.clamp å‡½æ•°å°†é¢„æµ‹å€¼é™åˆ¶åœ¨ [1, âˆ) ä¹‹é—´ï¼Œé¿å…å¯¹æ•°è®¡ç®—ä¸­çš„è´Ÿå€¼æˆ–é›¶
    clipped_preds = torch.clamp(net(features), 1,float('inf'))
    # è®¡ç®— log(RMSE)
    rmse = torch.sqrt(nn.MSELoss()(torch.log(clipped_preds), torch.log(labels)))
    return rmse.item()
	
	
# è®­ç»ƒå‡½æ•°å€ŸåŠ©ADAMä¼˜åŒ–å™¨
def train(net, train_features, train_labels, test_features, test_labels, num_epochs, weight_decay, learning_rate, batch_size):
	# ç”¨äºä¿å­˜æ¯ä¸ª epoch çš„è®­ç»ƒå’Œæµ‹è¯•æŸå¤±ã€‚
    train_ls, test_ls = [], []
    train_iter = d2l.load_array((train_features, train_labels), batch_size)
    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)
    loss_fn = nn.MSELoss()  # å‡è®¾æ‚¨ä½¿ç”¨ MSE ä½œä¸ºæŸå¤±å‡½æ•°
    
    for epoch in range(num_epochs):
        net.train()  # è®¾ç½®ç½‘ç»œä¸ºè®­ç»ƒæ¨¡å¼
        for X, y in train_iter:
            optimizer.zero_grad()
            l = loss_fn(net(X), y)
            l.backward()
            optimizer.step()
        net.eval()  # è®¾ç½®ç½‘ç»œä¸ºè¯„ä¼°æ¨¡å¼
        train_ls.append(log_rmse(net, train_features, train_labels))
        if test_labels is not None:
            test_ls.append(log_rmse(net, test_features, test_labels))
    return train_ls, test_ls
    
    
# KæŠ˜äº¤å‰éªŒè¯
def get_k_fold_data(k,i,X,y):
	assert k>1
	flod_size = X.shape[0] // k
	X_train,y_train=None,None
	for j in range(k):
		idx = slice(j*fold_size,(j+1)*fold_size)
		X_part,y_part = X[idx,:],y[idx,:]
		if j==i:
			X_valid,y_valid=X_part,y_part
		elif X_train is None:
            X_train, y_train = X_part, y_part
        else:
        #å°†å½“å‰æŠ˜çš„æ•°æ®ä¸å·²æœ‰çš„è®­ç»ƒé›†æ•°æ®æ‹¼æ¥èµ·æ¥ã€‚
        X_train = torch.cat([X_train,X_part],0)
        y_train = torch.cat([y_train, y_part], 0)
    return X_train, y_train, X_valid, y_valid

def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,batch_size):
	train_l_sum,valid_l_sum=0,0
	for i in range(k):
		data =  get_k_fold_data(k, i, X_train, y_train)
		net = get_net()
		train_ls, valid_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)
		train_l_sum += train_ls[-1]
        valid_l_sum += valid_ls[-1]
    if i == 0:
            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],
                     xlabel='epoch', ylabel='rmse', xlim=[1, num_epochs],
                     legend=['train', 'valid'], yscale='log')
        print(f'æŠ˜{i + 1}ï¼Œè®­ç»ƒlog rmse{float(train_ls[-1]):f}, '
              f'éªŒè¯log rmse{float(valid_ls[-1]):f}')
    return train_l_sum / k, valid_l_sum / k
```

æäº¤é¢„æµ‹









# æ·±åº¦å­¦ä¹ è®¡ç®—

## PyTorch ç¥ç»ç½‘ç»œåŸºç¡€

### å±‚å’Œå—

åœ¨ä¹‹å‰çš„å†…å®¹ä¸­ï¼Œæˆ‘ä»¬è®¤è¯†äº†ä¸€äº›ç¥ç»ç½‘ç»œï¼Œæ¯”å¦‚ï¼šçº¿æ€§å›å½’ï¼ŒSoftmaxå›å½’ï¼Œå¤šå±‚æ„ŸçŸ¥æœºï¼›ä»–ä»¬æœ‰çš„æ˜¯æ•´ä¸ªæ¨¡å‹ï¼Œæœ‰çš„æ˜¯ä¸€å±‚ç¥ç»ç½‘ç»œï¼Œæœ‰çš„ç”šè‡³åªæ˜¯ä¸€ä¸ªå•å…ƒï¼Œä»–ä»¬çš„åŠŸèƒ½ä»¥åŠå¤æ‚ç¨‹åº¦ä¹Ÿå„ä¸ç›¸åŒï¼Œä½†ä»–ä»¬éƒ½æœ‰ç€å¦‚ä¸‹ä¸‰ä¸ªç‰¹å¾ï¼š

- æ¥å—ä¸€äº›è¾“å…¥
- äº§ç”Ÿå¯¹åº”çš„è¾“å‡º
- ç”±ä¸€ç»„å¯è°ƒæ•´å‚æ•°æè¿°

å¯¹äºä¸€äº›å¤æ‚çš„ç½‘ç»œï¼Œç ”ç©¶è®¨è®ºæ¯”å±‚å¤§ä½†æ¯”æ•´ä¸ªæ¨¡å‹å°çš„éƒ¨åˆ†å¾ˆæœ‰æ„ä¹‰ï¼Œå› ä¸ºå¤æ‚çš„ç½‘ç»œä¸­ç»å¸¸æœ‰é‡å¤å‡ºç°çš„éƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†ä¹Ÿå¸¸å¸¸æœ‰è‡ªå·±çš„åŠŸèƒ½ã€‚è€ƒè™‘åˆ°ä¸Šé¢çš„ä¸‰ä¸ªç‰¹å¾ï¼Œè¿™å°±ä½¿å¾—æˆ‘ä»¬æ€è€ƒæ˜¯å¦å¯ä»¥å¯¹è¿™äº›éƒ¨åˆ†è¿›è¡Œä¸€ä¸ªæŠ½è±¡ï¼Œè¿™å°±å¾—åˆ°äº†å—çš„æ¦‚å¿µï¼šå—æŒ‡å•ä¸ªå±‚ï¼Œå¤šä¸ªå±‚ç»„æˆçš„éƒ¨åˆ†ï¼Œæˆ–è€…æ•´ä¸ªæ¨¡å‹æœ¬èº«ã€‚ä½¿ç”¨å—å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œæè¿°å°±ç®€ä¾¿è®¸å¤šï¼Œè¿™ä¸€è¿‡ç¨‹æ˜¯é€’å½’çš„ï¼Œå—çš„å†…éƒ¨è¿˜å¯ä»¥åˆ’åˆ†ä¸ºå¤šä¸ªå—ï¼Œç›´è‡³æ»¡è¶³éœ€è¦ä¸ºæ­¢ã€‚

PyTorchå¸®æˆ‘ä»¬å®ç°äº†å—çš„å¤§éƒ¨åˆ†æ‰€éœ€åŠŸèƒ½ï¼ŒåŒ…æ‹¬è‡ªåŠ¨æ±‚å¯¼ï¼Œæˆ‘ä»¬åªéœ€ä»nn.Moduleç»§æ‰¿å¹¶æ”¹å†™å…¶ä¸­çš„ä¸€éƒ¨åˆ†å°±èƒ½å¾—åˆ°æˆ‘ä»¬éœ€è¦çš„å—ä»¥åŠæ¨¡å‹ã€‚

**`nn.Sequential`**

**å®šä¹‰äº†ä¸€ç§ç‰¹æ®Šçš„`Module`**ï¼Œ å³åœ¨PyTorchä¸­è¡¨ç¤ºä¸€ä¸ªå—çš„ç±»ï¼Œ å®ƒç»´æŠ¤äº†ä¸€ä¸ªç”±`Module`ç»„æˆçš„æœ‰åºåˆ—è¡¨ã€‚ 

#### **è‡ªå®šä¹‰å—**

**æ¯ä¸ªå—å¿…é¡»æä¾›çš„åŸºæœ¬åŠŸèƒ½ï¼š**

1. å°†è¾“å…¥æ•°æ®ä½œä¸ºå…¶å‰å‘ä¼ æ’­å‡½æ•°çš„å‚æ•°ã€‚
2. é€šè¿‡å‰å‘ä¼ æ’­å‡½æ•°æ¥ç”Ÿæˆè¾“å‡ºã€‚è¯·æ³¨æ„ï¼Œè¾“å‡ºçš„å½¢çŠ¶å¯èƒ½ä¸è¾“å…¥çš„å½¢çŠ¶ä¸åŒã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä¸Šé¢æ¨¡å‹ä¸­çš„ç¬¬ä¸€ä¸ªå…¨è¿æ¥çš„å±‚æ¥æ”¶ä¸€ä¸ª20ç»´çš„è¾“å…¥ï¼Œä½†æ˜¯è¿”å›ä¸€ä¸ªç»´åº¦ä¸º256çš„è¾“å‡ºã€‚
3. è®¡ç®—å…¶è¾“å‡ºå…³äºè¾“å…¥çš„æ¢¯åº¦ï¼Œå¯é€šè¿‡å…¶åå‘ä¼ æ’­å‡½æ•°è¿›è¡Œè®¿é—®ã€‚é€šå¸¸è¿™æ˜¯è‡ªåŠ¨å‘ç”Ÿçš„ã€‚
4. å­˜å‚¨å’Œè®¿é—®å‰å‘ä¼ æ’­è®¡ç®—æ‰€éœ€çš„å‚æ•°ã€‚
5. æ ¹æ®éœ€è¦åˆå§‹åŒ–æ¨¡å‹å‚æ•°ã€‚

**å®ä¾‹

```
import torch
from torch import nn
import torch.nn.functional as F

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.hidden_layer = nn.Linear(20, 256)
        self.out_layer = nn.Linear(256, 10)

    def forward(self, X):
        X = F.relu(self.hidden_layer(X))
        return self.out_layer(X)

# ç¤ºä¾‹ï¼šå¦‚ä½•ä½¿ç”¨è¯¥æ¨¡å‹
# å‡è®¾è¾“å…¥æ•°æ®æœ‰ 20 ä¸ªç‰¹å¾
model = MLP()
X = torch.rand(5, 20)  # ç”Ÿæˆ 5 ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰ 20 ä¸ªç‰¹å¾
output = model(X)
print(output)

```

##### é¡ºåºå—

ç°åœ¨æˆ‘ä»¬å¯ä»¥æ›´ä»”ç»†åœ°çœ‹çœ‹`Sequential`ç±»æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œ å›æƒ³ä¸€ä¸‹`Sequential`çš„è®¾è®¡æ˜¯ä¸ºäº†æŠŠå…¶ä»–æ¨¡å—ä¸²èµ·æ¥ã€‚ ä¸ºäº†æ„å»ºæˆ‘ä»¬è‡ªå·±çš„ç®€åŒ–çš„`MySequential`ï¼Œ æˆ‘ä»¬åªéœ€è¦å®šä¹‰ä¸¤ä¸ªå…³é”®å‡½æ•°ï¼š

1. ä¸€ç§å°†å—é€ä¸ªè¿½åŠ åˆ°åˆ—è¡¨ä¸­çš„å‡½æ•°ï¼›
2. ä¸€ç§å‰å‘ä¼ æ’­å‡½æ•°ï¼Œç”¨äºå°†è¾“å…¥æŒ‰è¿½åŠ å—çš„é¡ºåºä¼ é€’ç»™å—ç»„æˆçš„â€œé“¾æ¡â€ã€‚

```
class mySequential(nn.Module):
	def __init__(self,**args):
		super().__init__
		for idx,module in enumerate(args):
			self._modules[str(idx)] = module
	
	def forward(self,X):
		for block in self._module.values:
			X = block(X)
		return X
```

##### **åœ¨å‰å‘ä¼ æ’­å‡½æ•°ä¸­æ‰§è¡Œä»£ç **

`Sequential`ç±»ä½¿æ¨¡å‹æ„é€ å˜å¾—ç®€å•ï¼Œ å…è®¸æˆ‘ä»¬ç»„åˆæ–°çš„æ¶æ„ï¼Œè€Œä¸å¿…å®šä¹‰è‡ªå·±çš„ç±»ã€‚ ç„¶è€Œï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„æ¶æ„éƒ½æ˜¯ç®€å•çš„é¡ºåºæ¶æ„ã€‚ å½“éœ€è¦æ›´å¼ºçš„çµæ´»æ€§æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰è‡ªå·±çš„å—ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›åœ¨å‰å‘ä¼ æ’­å‡½æ•°ä¸­æ‰§è¡ŒPythonçš„æ§åˆ¶æµã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›æ‰§è¡Œä»»æ„çš„æ•°å­¦è¿ç®—ï¼Œ è€Œä¸æ˜¯ç®€å•åœ°ä¾èµ–é¢„å®šä¹‰çš„ç¥ç»ç½‘ç»œå±‚ã€‚

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œ æˆ‘ä»¬ç½‘ç»œä¸­çš„æ‰€æœ‰æ“ä½œéƒ½å¯¹ç½‘ç»œçš„æ¿€æ´»å€¼åŠç½‘ç»œçš„å‚æ•°èµ·ä½œç”¨ã€‚ ç„¶è€Œï¼Œæœ‰æ—¶æˆ‘ä»¬å¯èƒ½å¸Œæœ›åˆå¹¶æ—¢ä¸æ˜¯ä¸Šä¸€å±‚çš„ç»“æœä¹Ÿä¸æ˜¯å¯æ›´æ–°å‚æ•°çš„é¡¹ï¼Œ æˆ‘ä»¬ç§°ä¹‹ä¸º*å¸¸æ•°å‚æ•°*ï¼ˆconstant parameterï¼‰ã€‚ ä¾‹å¦‚ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè®¡ç®—å‡½æ•° ğ‘“(ğ‘¥,ğ‘¤)=ğ‘â‹…ğ‘¤âŠ¤ğ‘¥çš„å±‚ï¼Œ å…¶ä¸­ğ‘¥æ˜¯è¾“å…¥ï¼Œ ğ‘¤æ˜¯å‚æ•°ï¼Œ ğ‘æ˜¯æŸä¸ªåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­æ²¡æœ‰æ›´æ–°çš„æŒ‡å®šå¸¸é‡ã€‚ å› æ­¤æˆ‘ä»¬å®ç°äº†ä¸€ä¸ª`FixedHiddenMLP`ç±»ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```
class FixedHiddenMLP(nn.Module):
    def __init__(self):
        super().__init__()
        # ä¸è®¡ç®—æ¢¯åº¦çš„éšæœºæƒé‡å‚æ•°ã€‚å› æ­¤å…¶åœ¨è®­ç»ƒæœŸé—´ä¿æŒä¸å˜
        self.rand_weight = torch.rand((20, 20), requires_grad=False)
        self.linear = nn.Linear(20, 20)

    def forward(self, X):
        X = self.linear(X)
        # ä½¿ç”¨åˆ›å»ºçš„å¸¸é‡å‚æ•°ä»¥åŠreluå’Œmmå‡½æ•°
        X = F.relu(torch.mm(X, self.rand_weight) + 1)
        # å¤ç”¨å…¨è¿æ¥å±‚ã€‚è¿™ç›¸å½“äºä¸¤ä¸ªå…¨è¿æ¥å±‚å…±äº«å‚æ•°
        X = self.linear(X)
        # æ§åˆ¶æµ
        while X.abs().sum() > 1:
            X /= 2
        return X.sum()
```

### å‚æ•°ç®¡ç†

åœ¨é€‰æ‹©äº†æ¶æ„å¹¶è®¾ç½®äº†è¶…å‚æ•°åï¼Œæˆ‘ä»¬å°±è¿›å…¥äº†è®­ç»ƒé˜¶æ®µã€‚æ­¤æ—¶ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä½¿æŸå¤±å‡½æ•°æœ€å°åŒ–çš„æ¨¡å‹å‚æ•°å€¼ã€‚ç»è¿‡è®­ç»ƒåï¼Œæˆ‘ä»¬å°†éœ€è¦ä½¿ç”¨è¿™äº›å‚æ•°æ¥åšå‡ºæœªæ¥çš„é¢„æµ‹ã€‚æ­¤å¤–ï¼Œæœ‰æ—¶æˆ‘ä»¬å¸Œæœ›æå–å‚æ•°ï¼Œä»¥ä¾¿åœ¨å…¶ä»–ç¯å¢ƒä¸­å¤ç”¨å®ƒä»¬ï¼Œå°†æ¨¡å‹ä¿å­˜ä¸‹æ¥ï¼Œä»¥ä¾¿å®ƒå¯ä»¥åœ¨å…¶ä»–è½¯ä»¶ä¸­æ‰§è¡Œï¼Œæˆ–è€…ä¸ºäº†è·å¾—ç§‘å­¦çš„ç†è§£è€Œè¿›è¡Œæ£€æŸ¥ã€‚

#### å‚æ•°è®¿é—®

```
# æˆ‘ä»¬å…ˆæ„å»ºä¸€ä¸ªå•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœº
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
## å‚æ•°è®¿é—®+ç´¢å¼•è®¿é—®+åˆ©ç”¨state_dict
net[2].state_dict()
```

#### ç›®æ ‡å‚æ•°

```
# æå–åç½®
net[2].bias.data
net[2].bias
#
tensor([-0.1032])
tensor([-0.1032], requires_grad=True)
```

#### ä¸€æ¬¡æ€§è®¿é—®æ‰€æœ‰å‚æ•°

```
# åˆ©ç”¨named_parameters()
print(*[(name,param.shape) for name,param in net[0].named_parameters()])
print(*[(name,param.shape) for name,param in net.named_parameters()])
# å¦ä¸€ç§é‡‡ç”¨state_dictï¼Œè¿™æ˜¯ä¸€ä¸ªOrdereddict
netp[2].state_dict()['2.bias;].data
```

#### ä»åµŒå¥—å—ä¸­æ”¶é›†å‚æ•°

```
def block1():
    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),
                         nn.Linear(8, 4), nn.ReLU())

def block2():
    net = nn.Sequential()
    for i in range(4):
    	net.add_module(f'blcok{i}',block1())
    return net

rgnet = nn.Sequential(block2(),nn.Linear(4,1))
rgnet(X)
```

#### å‚æ•°åˆå§‹åŒ–

##### å†…ç½®åˆå§‹åŒ–

```
def init_normal(m):
    if type(m) == nn.Linear:
    	#ç”¨æ­£æ€åˆ†å¸ƒåˆå§‹åŒ–
    	nn.init.normal(m.weight,mean=0,std=0.01)
    	#å¸¸æ•°
    	nn.init.constant_(m.weight, 1)
    	#xavier
    	nn.init.xavier_uniform_(m.weight)
    	
    	nn.init.zeros(m.bias)
    	
net.apply(init_normal)
net[0].weight.data[0], net[0].bias.data[0]
```

##### è‡ªå®šä¹‰åˆå§‹åŒ–

![image-20240704152743711](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240704152743711.png)

#### å‚æ•°ç»‘å®š

æœ‰æ—¶æˆ‘ä»¬å¸Œæœ›åœ¨å¤šä¸ªå±‚é—´å…±äº«å‚æ•°ï¼š æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç¨ å¯†å±‚ï¼Œç„¶åä½¿ç”¨å®ƒçš„å‚æ•°æ¥è®¾ç½®å¦ä¸€ä¸ªå±‚çš„å‚æ•°ã€‚

```
# æˆ‘ä»¬éœ€è¦ç»™å…±äº«å±‚ä¸€ä¸ªåç§°ï¼Œä»¥ä¾¿å¯ä»¥å¼•ç”¨å®ƒçš„å‚æ•°
shared = nn.Linear(8, 8)
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),
                    shared, nn.ReLU(),
                    shared, nn.ReLU(),
                    nn.Linear(8, 1))
net(X)
# æ£€æŸ¥å‚æ•°æ˜¯å¦ç›¸åŒ
print(net[2].weight.data[0] == net[4].weight.data[0])
net[2].weight.data[0, 0] = 100
# ç¡®ä¿å®ƒä»¬å®é™…ä¸Šæ˜¯åŒä¸€ä¸ªå¯¹è±¡ï¼Œè€Œä¸åªæ˜¯æœ‰ç›¸åŒçš„å€¼
print(net[2].weight.data[0] == net[4].weight.data[0])
```

### å»¶ååˆå§‹åŒ–

æœ‰æ—¶åœ¨å»ºç«‹ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬ä¸ä¼šæŒ‡å®šç½‘ç»œçš„è¾“å…¥è¾“å‡ºç»´åº¦ï¼Œä¹Ÿå°±ä¸èƒ½ç¡®å®šç½‘ç»œçš„å‚æ•°å½¢çŠ¶ï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶æ”¯æŒå»¶ååˆå§‹åŒ–ï¼Œå³å½“ç¬¬ä¸€æ¬¡å°†æ•°æ®ä¼ å…¥æ¨¡å‹æ—¶è‡ªåŠ¨çš„å¾—åˆ°æ‰€æœ‰çš„ç»´åº¦ï¼Œç„¶ååˆå§‹åŒ–æ‰€æœ‰çš„å‚æ•°ã€‚

PyTorchä¹Ÿæ”¯æŒè¿™ä¸€ç‚¹ï¼Œæ¯”å¦‚nn.LazyLinearï¼Œä½†æœ¬é—¨è¯¾ç¨‹ä¸­å¹¶æœªä»‹ç»ã€‚

### è‡ªå®šä¹‰å±‚

æ·±åº¦å­¦ä¹ æˆåŠŸèƒŒåçš„ä¸€ä¸ªå› ç´ æ˜¯ç¥ç»ç½‘ç»œçš„çµæ´»æ€§ï¼šæˆ‘ä»¬å¯ä»¥ç”¨åˆ›é€ æ€§çš„æ–¹å¼ç»„åˆä¸åŒçš„å±‚ï¼Œä»è€Œè®¾è®¡å‡ºé€‚ç”¨äºå„ç§ä»»åŠ¡çš„æ¶æ„ã€‚ä¾‹å¦‚ï¼Œç ”ç©¶äººå‘˜å‘æ˜äº†ä¸“é—¨ç”¨äºå¤„ç†å›¾åƒã€æ–‡æœ¬ã€åºåˆ—æ•°æ®å’Œæ‰§è¡ŒåŠ¨æ€è§„åˆ’çš„å±‚ã€‚åŒæ ·çš„ï¼Œå¯¹äºå±‚è€Œè¨€ï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶å¹¶ä¸èƒ½æ»¡è¶³æˆ‘ä»¬æ‰€æœ‰çš„éœ€æ±‚ï¼Œç„¶è€Œï¼Œå±‚æœ¬èº«ä¹Ÿå…·æœ‰æå¤§çš„çµæ´»æ€§ï¼Œæˆ‘ä»¬å¯ä»¥è‡ªå®šä¹‰æƒ³è¦çš„å±‚ã€‚

### è¯»å†™æ–‡ä»¶

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•å¤„ç†æ•°æ®ï¼Œä»¥åŠå¦‚ä½•æ„å»ºã€è®­ç»ƒå’Œæµ‹è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚ç„¶è€Œï¼Œæœ‰æ—¶æˆ‘ä»¬å¸Œæœ›ä¿å­˜è®­ç»ƒçš„æ¨¡å‹ï¼Œä»¥å¤‡å°†æ¥åœ¨å„ç§ç¯å¢ƒä¸­ä½¿ç”¨ï¼ˆæ¯”å¦‚åœ¨éƒ¨ç½²ä¸­è¿›è¡Œé¢„æµ‹ï¼‰ã€‚æ­¤å¤–ï¼Œå½“è¿è¡Œä¸€ä¸ªè€—æ—¶è¾ƒé•¿çš„è®­ç»ƒè¿‡ç¨‹æ—¶ï¼Œæœ€ä½³çš„åšæ³•æ˜¯å®šæœŸä¿å­˜ä¸­é—´ç»“æœï¼Œä»¥ç¡®ä¿åœ¨æœåŠ¡å™¨ç”µæºè¢«ä¸å°å¿ƒæ–­æ‰æ—¶ï¼Œæˆ‘ä»¬ä¸ä¼šæŸå¤±å‡ å¤©çš„è®¡ç®—ç»“æœã€‚







# å·ç§¯ç¥ç»ç½‘ç»œ

## å·ç§¯å±‚

### å¹³ç§»ä¸å˜æ€§

![image-20240704182222900](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240704182222900.png)

### å±€éƒ¨æ€§

![image-20240704183058348](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240704183058348.png)

### ä»£ç 

äº’ç›¸å…³è¿ç®—

```
import torch
from torch import nn

def corr2d(X,K):    #Xä¸ºè¾“å…¥ï¼ŒKä¸ºæ ¸çŸ©é˜µ
    h,w=K.shape    #hå¾—åˆ°Kçš„è¡Œæ•°ï¼Œwå¾—åˆ°Kçš„åˆ—æ•°
    Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))  #ç”¨0åˆå§‹åŒ–è¾“å‡ºçŸ©é˜µY
    for i in range(Y.shape[0]):   #å·ç§¯è¿ç®—
        for j in range(Y.shape[1]):
          Y[i,j]=(X[i:i+h,j:j+w]*K).sum()
    return Y
```

å®ç°äºŒç»´å·ç§¯å±‚

```
#å®ç°äºŒç»´å·ç§¯å±‚
class Conv2d(nn.Module):
    def _init_(self,kernel_size):
        super()._init_()
        self.weight=nn.Parameter(torch.rand(kerner_size))
        self.bias=nn.Parameter(torch.zeros(1))
    def forward(self,x):
        return corr2d(x,self.weight)+self.bias 
```

å»ºç«‹ä¸€ä¸ªè¾¹ç¼˜æ£€æµ‹

```
X=torch.ones((6,8))
X[:,2:6]=0
X
```

```
>>> tensor([[1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.],
        [1., 1., 0., 0., 0., 0., 1., 1.]])
```

```
K=torch.tensor([[-1,1]])  #è¿™ä¸ªKåªèƒ½æ£€æµ‹å‚ç›´è¾¹ç¼˜
Y=corr2d(X,K)
Y
```

```
>>> tensor([[ 0., -1.,  0.,  0.,  0.,  1.,  0.],
            [ 0., -1.,  0.,  0.,  0.,  1.,  0.],
            [ 0., -1.,  0.,  0.,  0.,  1.,  0.],
            [ 0., -1.,  0.,  0.,  0.,  1.,  0.],
            [ 0., -1.,  0.,  0.,  0.,  1.,  0.],
            [ 0., -1.,  0.,  0.,  0.,  1.,  0.]])
```

æ£€æµ‹å‚ç›´çš„è¾¹ç¼˜

```
corr2d(X.t(),K)
```

```
>>> tensor([[0., 0., 0., 0., 0.],
            [0., 0., 0., 0., 0.],
            [0., 0., 0., 0., 0.],
            [0., 0., 0., 0., 0.],
            [0., 0., 0., 0., 0.],
            [0., 0., 0., 0., 0.],
            [0., 0., 0., 0., 0.],
            [0., 0., 0., 0., 0.]])
```

å­¦ä¹ ç”±Xç”ŸæˆYçš„å·ç§¯æ ¸

```
# è¾“å…¥ï¼Œè¾“å‡ºï¼Œå·ç§¯æ ¸ï¼Œåç½®
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)

# é€šé“æ•°ï¼Œæ‰¹é‡å¤§å°ï¼Œé«˜åº¦ï¼Œå®½åº¦
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))

for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat-Y)**2//2
    conv2d.zero_grad()
    l.sum().backward()
    conv2d.weight.data[:]-=6e-2*conv2d.weight.grad
    if (i+1) % 2 == 0:
    	print(f'batch {i+1} ,loss {l.sum():3f}}
```

```
>>> batch 2, loss 3.852
    batch 4, loss 1.126
    batch 6, loss 0.386
    batch 8, loss 0.145
    batch 10, loss 0.057
```

## å·ç§¯å±‚é‡Œçš„å¡«å……å’Œæ­¥å¹…

###  å¡«å…… 

**å¡«å……**(Padding)æŒ‡çš„æ˜¯åœ¨è¾“å…¥å‘¨å›´æ·»åŠ é¢å¤–çš„è¡Œ/åˆ—

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/20/20-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/20/20-01.png)

**ç»´åº¦å˜åŒ–**ï¼š

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/20/20-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/20/20-02.png)

**ä¸¤ç§ä¸åŒçš„å·ç§¯æ–¹å¼**ï¼š â‘ Valid å·ç§¯ï¼šä¸è¿›è¡Œå¡«å……ï¼Œå·ç§¯è¿ç®—è¿‡åå¾—åˆ°çš„çŸ©é˜µå½¢çŠ¶ä¸º(n-f+1)Ã—(n-f+1)ã€‚

â‘¡Same å·ç§¯ï¼šå…ˆå¯¹çŸ©é˜µè¿›è¡Œå¡«å……ï¼Œç„¶åå†è¿›è¡Œå·ç§¯è¿ç®—ï¼Œä½¿å¾—è¿ç®—å‰åçŸ©é˜µå¤§å°ä¸å˜ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/20/20-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/20/20-03.png)

### æ­¥å¹…  

**æƒ³æ³•æ¥æºï¼šå¦‚æœæŒ‰ç…§åŸæ¥çš„æ“ä½œ(å·ç§¯æ­¥é•¿ä¸º1)ï¼Œé‚£ä¹ˆç»™å®šè¾“å…¥å¤§å°ä¸º224x224ï¼Œåœ¨ä½¿ç”¨5x5å·ç§¯æ ¸çš„æƒ…å†µä¸‹ï¼Œéœ€è¦55å±‚**æ‰èƒ½å°†è¾“å‡ºé™ä½åˆ°4x4ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—æ‰èƒ½å¾—åˆ°ç»´åº¦è¾ƒå°çš„è¾“å‡ºã€‚

**æ­¥å¹…**æ˜¯æŒ‡è¡Œ/åˆ—çš„æ»‘åŠ¨æ­¥é•¿

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/20/20-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/20/20-04.png)

**ç»´åº¦å˜åŒ–**:

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/20/20-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/20/20-05.png)

æ³¨æ„ï¼šç¬¬ä¸‰ç‚¹å¯ä»¥å½“åšç»“è®ºæ¥è®°(Sameå·ç§¯æˆ–Validå·ç§¯(ä¸”sâ‰¥kæ—¶))ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœnæ˜¯å¶æ•°ï¼Œså–2ï¼Œæ± åŒ–å±‚åšValidå·ç§¯(ä¸å¡«å……)ä¸”k=2ï¼Œæ­¤æ—¶è¾“å‡ºç»´åº¦ç›´æ¥å¯ä»¥å†™æˆn/2 x n/2ã€‚å¦‚æœæ€•ææ··ï¼Œç›´æ¥è®°ç¬¬ä¸€ä¸ªå…¬å¼æ¯æ¬¡ç°æ¨ä¹Ÿå¯ã€‚

### æ€»ç»“ 

- å¡«å……å’Œæ­¥å¹…æ˜¯å·ç§¯å±‚çš„**è¶…å‚æ•°**
- **å¡«å……**(padding)åœ¨è¾“å…¥å‘¨å›´æ·»åŠ é¢å¤–çš„è¡Œ/åˆ—ï¼Œæ¥æ§åˆ¶è¾“å‡ºå½¢çŠ¶çš„å‡å°‘é‡
- **æ­¥å¹…**(stride)æ˜¯æ¯æ¬¡æ»‘åŠ¨æ ¸çª—å£æ—¶çš„è¡Œ/åˆ—çš„æ­¥é•¿ï¼Œå¯ä»¥æˆå€åœ°å‡å°‘è¾“å‡ºå½¢çŠ¶

### ä»£ç 

#### å¡«å……å’Œæ­¥å¹…

**å¯¼å…¥åŒ…ï¼Œå®šä¹‰comp_conv2då‡½æ•° (è¿›è¡Œå·ç§¯æ“ä½œ, è¾“å‡ºåä¸¤ç»´ï¼Œä¾¿äºè§‚å¯Ÿé«˜å®½çš„ç»´åº¦å˜åŒ–)**

```
import torch
from torch import nn

def comp_conv2d(conv2d, X):
	# ç»´åº¦çš„å‰é¢åŠ å…¥æ‰¹é‡å¤§å°æ•°(batch_size)å’Œè¾“å…¥é€šé“æ•°(channel_in)
    X = X.reshape((1, 1) + X.shape) 
    Y = conv2d(X)                    
    return Y.reshape(Y.shape[2:])  #å»æ‰å‰é¢çš„ä¸¤ç»´å(åŸæ¥å››ç»´) è¿›è¡Œè¾“å‡º
```

#### padding

**åœ¨æ‰€æœ‰ä¾§è¾¹å¡«å……1ä¸ªåƒç´ (padding=1, å³(1,1))**

```
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) #è¾“å…¥è¾“å‡ºé€šé“æ•°ä¸º1, å·ç§¯æ ¸å¤§å°3x3, å¡«å……ä¸º1(ä¸Šä¸‹å·¦å³å„å¡«å……ä¸€è¡Œ)
X = torch.rand(size=(8, 8))         
comp_conv2d(conv2d, X).shape
```

```
>>> torch.Size([8, 8])
```

**å¡«å……ä¸åŒçš„é«˜åº¦å’Œå®½åº¦(padding=(2,1))**

```
conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))
comp_conv2d(conv2d, X).shape
```

```
>>> torch.Size([8, 8])
```

#### stride

**å°†é«˜åº¦å’Œå®½åº¦çš„æ­¥å¹…è®¾ç½®ä¸º2**

```
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)
comp_conv2d(conv2d, X).shape
```

```
>>> torch.Size([4, 4])
```

**ä¸€ä¸ªç¨å¾®å¤æ‚çš„ä¾‹å­**

```
conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))
comp_conv2d(conv2d, X).shape
```

```
>>> torch.Size([2, 2])
```

## å¤šè¾“å…¥å¤šè¾“å‡ºé€šé“

### å¤šä¸ªè¾“å…¥é€šé“

- å½©è‰²å›¾åƒå¯èƒ½æœ‰RGBä¸‰ä¸ªé€šé“

- è½¬æ¢ä¸ºç°åº¦ä¼šä¸¢å¤±ä¿¡æ¯

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/21/21-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/21/21-01.png)

- æ¯ä¸ªé€šé“éƒ½æœ‰ä¸€ä¸ªå·ç§¯å’Œï¼Œç»“æœæ˜¯æ‰€æœ‰é€šé“å·ç§¯ç»“æœçš„å’Œ

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/21/21-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/21/21-02.png)

- è¾“å…¥**X**:[![c_{i}\times n_{h}\times n_{w}](https://camo.githubusercontent.com/ede4ec360206a8830f9e4238a35c436d5881462fce077e695ae3bfd683ccbe56/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b697d5c74696d65732673706163653b6e5f7b687d5c74696d65732673706163653b6e5f7b777d)](https://camo.githubusercontent.com/ede4ec360206a8830f9e4238a35c436d5881462fce077e695ae3bfd683ccbe56/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b697d5c74696d65732673706163653b6e5f7b687d5c74696d65732673706163653b6e5f7b777d)
- æ ¸**W**ï¼š[![c_{i}\times k_{h}\times k_{w}](https://camo.githubusercontent.com/e4217dc5acd1775e3830925e71415d8059621f1b5616a2ae8e53d9264303f872/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b697d5c74696d65732673706163653b6b5f7b687d5c74696d65732673706163653b6b5f7b777d)](https://camo.githubusercontent.com/e4217dc5acd1775e3830925e71415d8059621f1b5616a2ae8e53d9264303f872/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b697d5c74696d65732673706163653b6b5f7b687d5c74696d65732673706163653b6b5f7b777d)
- è¾“å‡º**Y**:[![m_{h}\times m_{w}](https://camo.githubusercontent.com/0704054ba0d6b123fe7d3508371099665253aecec2c758f3cba4005d24305367/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f6d5f7b687d5c74696d65732673706163653b6d5f7b777d)](https://camo.githubusercontent.com/0704054ba0d6b123fe7d3508371099665253aecec2c758f3cba4005d24305367/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f6d5f7b687d5c74696d65732673706163653b6d5f7b777d)

[![Y=\sum _{i=0}^{c_{i}}X_{i,:,:}\bigstar W_{i,:,:}](https://camo.githubusercontent.com/11eddda729f3b5b08fb8c797e2fe70e66dcd6a4758c676ad943dc41a773fc910/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f593d5c73756d2673706163653b5f7b693d307d5e7b635f7b697d7d585f7b692c3a2c3a7d5c626967737461722673706163653b575f7b692c3a2c3a7d)](https://camo.githubusercontent.com/11eddda729f3b5b08fb8c797e2fe70e66dcd6a4758c676ad943dc41a773fc910/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f593d5c73756d2673706163653b5f7b693d307d5e7b635f7b697d7d585f7b692c3a2c3a7d5c626967737461722673706163653b575f7b692c3a2c3a7d)

å¤šä¸ªè¾“å…¥é€šé“ï¼š

```
import torch
from d2l import torch as d2l

def corr2d_multi_in(X, K):
    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))
```

### å¤šä¸ªè¾“å‡ºé€šé“

- æ— è®ºæœ‰å¤šå°‘è¾“å…¥é€šé“ï¼Œåˆ°ç›®å‰ä½ç½®æˆ‘ä»¬æ¤ç»’åˆ°å•è¾“å‡ºé€šé“
- æˆ‘ä»¬å¯ä»¥æœ‰å¤šä¸ªä¸‰ç»´å·ç§¯æ ¸ï¼Œæ¯ä¸ªæ ¸ç”Ÿæˆä¸€ä¸ªè¾“å‡ºé€šé“
- è¾“å…¥**X**:[![c_{i}\times k_{h}\times k_{w}](https://camo.githubusercontent.com/e4217dc5acd1775e3830925e71415d8059621f1b5616a2ae8e53d9264303f872/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b697d5c74696d65732673706163653b6b5f7b687d5c74696d65732673706163653b6b5f7b777d)](https://camo.githubusercontent.com/e4217dc5acd1775e3830925e71415d8059621f1b5616a2ae8e53d9264303f872/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b697d5c74696d65732673706163653b6b5f7b687d5c74696d65732673706163653b6b5f7b777d)
- æ ¸**W**ï¼š[![c_{o}\times c_{i}\times k_{h}\times k_{w}](https://camo.githubusercontent.com/db922e672cf0c939ff058271b413d0b0c81b0da02a111bf6714bea10c20ea491/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b6f7d5c74696d65732673706163653b635f7b697d5c74696d65732673706163653b6b5f7b687d5c74696d65732673706163653b6b5f7b777d)](https://camo.githubusercontent.com/db922e672cf0c939ff058271b413d0b0c81b0da02a111bf6714bea10c20ea491/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b6f7d5c74696d65732673706163653b635f7b697d5c74696d65732673706163653b6b5f7b687d5c74696d65732673706163653b6b5f7b777d)
- è¾“å‡º**Y**ï¼š[![c_{o}\times m_{h}\times m_{w}](https://camo.githubusercontent.com/d7f7c4abac6c1ae3b751fc15b6f42d2592d0ebe0146a2c088f305eade884b6d2/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b6f7d5c74696d65732673706163653b6d5f7b687d5c74696d65732673706163653b6d5f7b777d)](https://camo.githubusercontent.com/d7f7c4abac6c1ae3b751fc15b6f42d2592d0ebe0146a2c088f305eade884b6d2/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f635f7b6f7d5c74696d65732673706163653b6d5f7b687d5c74696d65732673706163653b6d5f7b777d)

[![Y_{i,:,:}=X\bigstar W_{i,:,:}\qquad for \quad i=1,...,c_{o}](https://camo.githubusercontent.com/ccb530df0e5be9267635cc5817021485ff677fd9b6be34b18bd5a249489a7da1/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f595f7b692c3a2c3a7d3d585c626967737461722673706163653b575f7b692c3a2c3a7d5c71717561642673706163653b666f722673706163653b5c717561642673706163653b693d312c2e2e2e2c635f7b6f7d)](https://camo.githubusercontent.com/ccb530df0e5be9267635cc5817021485ff677fd9b6be34b18bd5a249489a7da1/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f595f7b692c3a2c3a7d3d585c626967737461722673706163653b575f7b692c3a2c3a7d5c71717561642673706163653b666f722673706163653b5c717561642673706163653b693d312c2e2e2e2c635f7b6f7d)

å¤šä¸ªè¾“å‡ºé€šé“ï¼š

```
def corr2d_multi_in_out(X, K):
    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)
```

### å¤šä¸ªè¾“å…¥å’Œè¾“å‡ºé€šé“

- æ¯ä¸ªé€šé“å¯ä»¥è¯†åˆ«ç‰¹å®šçš„æ¨¡å¼

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/21/21-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/21/21-03.png)

- è¾“å…¥é€šé“æ ¸è¯†åˆ«å¹¶ç»„åˆè¾“å…¥ä¸­çš„æ¨¡å¼

### 1X1å·ç§¯å±‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/21/21-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/21/21-04.png)

### äºŒç»´å·ç§¯å±‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/21/21-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/21/21-05.png)

### æ€»ç»“

- è¾“å‡ºé€šé“æ•°æ˜¯å·ç§¯å±‚çš„è¶…å‚æ•°
- æ¯ä¸ªè¾“å…¥é€šé“æœ‰ç‹¬ç«‹çš„äºŒç»´å·ç§¯å’Œï¼Œæ‰€æœ‰é€šé“ç»“æœç›¸åŠ å¾—åˆ°ä¸€ä¸ªè¾“å‡ºé€šé“ç»“æœ
- æ¯ä¸ªè¾“å‡ºé€šé“æœ‰ç‹¬ç«‹çš„ä¸‰ç»´å·ç§¯æ ¸

### ä»£ç 

å¤šè¾“å…¥äº’ç›¸å…³è¿ç®—

```
import torch
from d2l import torch as d2l

def corr2d_multi_in(X,K):
	return sum(cd2l.orr2d(x,k) for x,k in zip(X,K))
```

å¤šé€šé“äº’ç›¸å…³è¿ç®—

 

```
def corr2d_multi_out(X,K):
	return torch.stack([d2l.torch(X,k) for k in K],0)
K = torch.stack((K,K+1,K+2),0)
```

1*1å·ç§¯

```
def corr2d_multi_in_out_1x1(X, K):
    c_i, h, w = X.shape
    c_o = K.shape[0]
    X = X.reshape((c_i, h * w))
    K = K.reshape((c_o, c_i))
    # å…¨è¿æ¥å±‚ä¸­çš„çŸ©é˜µä¹˜æ³•
    Y = torch.matmul(K, X)
    return Y.reshape((c_o, h, w))
```





## æ± åŒ–å±‚

åŒé‡ç›®çš„ï¼šé™ä½å·ç§¯å±‚å¯¹**ä½ç½®**çš„æ•æ„Ÿæ€§ï¼ŒåŒæ—¶é™ä½å¯¹**ç©ºé—´**é™é‡‡æ ·è¡¨ç¤ºçš„æ•æ„Ÿæ€§ã€‚

### æœ€å¤§æ±‡èšå±‚å’Œå¹³å‡æ±‡èšå±‚

#### äºŒç»´æœ€å¤§æ± åŒ–

è¿”å›æ»‘åŠ¨çª—å£ä¸­çš„æœ€å¤§å€¼ï¼šä¿ç•™æœ€å¤§ä¿¡æ¯ç‰¹å¾

#### å¹³å‡æ± åŒ–å±‚

å°†æœ€å¤§æ“ä½œæ›¿æ¢ä¸ºå¹³å‡ï¼Œç£¨å¹³/æŸ”å’Œæ“ä½œ

### å¡«å……å’Œæ­¥å¹…

æ± åŒ–å±‚ä¹Ÿå…·æœ‰å¡«å……å’Œæ­¥å¹…ï¼Œè·Ÿå·ç§¯ç›¸ä¼¼ï¼Œä½†æ˜¯æ²¡æœ‰kernelçš„å¯å­¦ä¹ å‚æ•°

è¾“å‡ºé€šé“æ•°=è¾“å…¥é€šé“æ•°ï¼Œå°†é€šé“èåˆäº¤ç»™äº†å·ç§¯å±‚

### ä»£ç 

å®ç°æ± åŒ–å±‚çš„æ­£å‘ä¼ æ’­

```
import torch
from torch import nn
from d2l import torch as d2l

def pool2d(X, pool_size, mode='max'):
    p_h, p_w = pool_size
    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            if mode == 'max':
                Y[i, j] = X[i: i + p_h, j: j + p_w].max()
            elif mode == 'avg':
                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()
    return Y
```





## ç»å…¸å·ç§¯ç¥ç»ç½‘ç»œLeNet

### LeNetå·ç§¯ç¥ç»ç½‘ç»œ

#### æ‰‹å†™æ•°å­—è¯†åˆ«

- LeNetç½‘ç»œæœ€æ—©æ˜¯ä¸ºäº†åº”ç”¨äºæ‰‹å†™æ•°å­—çš„è¯†åˆ«åº”ç”¨ã€‚
- åº”ç”¨èƒŒæ™¯ï¼š
  - é‚®æ”¿å±€å¸Œæœ›å¯ä»¥è‡ªåŠ¨è¯»å‡ºä¿¡ä»¶ä¸Šçš„é‚®æ”¿ç¼–ç 
  - äººä»¬å¸Œæœ›å¯ä»¥ç”¨æ”¯ç¥¨è‡ªåŠ¨å–é’±
- è¯¥æ¨¡å‹åœ¨80å¹´ä»£æœ«çš„é“¶è¡Œè¢«çœŸæ­£çš„éƒ¨ç½²

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/23/23-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/23/23-01.png)

#### MNIST

- LeNetæ‰€ä½¿ç”¨çš„æ•°æ®é›†
- 50ï¼Œ000ä¸ªè®­ç»ƒæ•°æ®
- 10ï¼Œ000ä¸ªæµ‹è¯•æ•°æ®
- å›¾åƒå¤§å°ä¸º28*28
- 10ç±»

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/23/23-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/23/23-02.png)

#### LeNetçš„å…·ä½“æ¨¡å‹



[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/23/23-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/23/23-03.png)

#### æ€»ç»“

- LeNetæ˜¯æ—©æœŸæˆåŠŸçš„ç¥ç»ç½‘ç»œ
- å…ˆä½¿ç”¨å·ç§¯å±‚æ¥å­¦ä¹ å›¾ç‰‡ç©ºé—´ä¿¡æ¯
- ç„¶åä½¿ç”¨å…¨è¿æ¥å±‚æ¥è½¬æ¢åˆ°ç±»åˆ«ç©ºé—´

### ä»£ç éƒ¨åˆ†

#### å®šä¹‰ç½‘ç»œç»“æ„å’Œå‡†å¤‡å·¥ä½œ

- å¯¼å…¥æ‰€éœ€çš„åº“

```
#å¯¼å…¥æ‰€éœ€çš„åº“
import torch
from torch import nn
from d2l import torch as d2l
```

- å®šä¹‰ç½‘ç»œç»“æ„ï¼ˆå…·ä½“å¯å‚è€ƒä¸Šæ–‡â€œå…·ä½“æ¨¡å‹â€çš„å›¾ï¼‰

```
#å®šä¹‰ç½‘ç»œç»“æ„
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
    nn.AvgPool2d(2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),nn.Flatten(),
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.Sigmoid(),
    nn.Linear(84, 10))
```

- æŸ¥çœ‹æ¯ä¸€å±‚æ•°æ®çš„å˜åŒ–æƒ…å†µ

```
#æŠŠæ¯ä¸€å±‚æ•°æ®çš„shapeç»™æ‰“å°å‡ºæ¥
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)#åˆ›å»ºç¬¦åˆè¦æ±‚çš„å¼ é‡
for layer in net:
    X = layer(X)#é€šè¿‡æ¯ä¸€å±‚
    print(layer.__class__.__name__,'output shape: \t',X.shape)#æ‰“å°
```

#### æ¨¡å‹è®­ç»ƒ

- ä¸‹è½½æ•°æ®é›†

```
batch_size = 256 #æ‰¹é‡å¤§å°
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)#ä¸‹è½½æˆ–åŠ è½½æ•°æ®é›†ï¼Œå¾—åˆ°è®­ç»ƒå’Œæµ‹è¯•é›†çš„è¿­ä»£å¯¹è±¡
```

- ä½¿ç”¨GPUè®¡ç®—æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„ç²¾åº¦

```
def evaluate_accuracy_gpu(net, data_iter, device=None): #@save
    """ä½¿ç”¨GPUè®¡ç®—æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„ç²¾åº¦"""
    if isinstance(net, nn.Module):
        net.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        if not device:
            device = next(iter(net.parameters())).device
    # æ­£ç¡®é¢„æµ‹çš„æ•°é‡ï¼Œæ€»é¢„æµ‹çš„æ•°é‡
    metric = d2l.Accumulator(2)#åˆ›å»ºä¸€ä¸ªç´¯åŠ å™¨ï¼ŒåŒ…å«2ä¸ªè¦ç´¯åŠ çš„å…ƒç´ 
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(X, list):
                # BERTå¾®è°ƒæ‰€éœ€çš„ï¼ˆä¹‹åå°†ä»‹ç»ï¼‰
                X = [x.to(device) for x in X]
            else:
                X = X.to(device)
            y = y.to(device)
            metric.add(d2l.accuracy(net(X), y), y.numel())#æŠŠæ¯ä¸€ç»„æ•°æ®é¢„æµ‹ç»“æœæ­£ç¡®çš„ä¸ªæ•°å’Œé•¿åº¦ç´¯åŠ 
    return metric[0] / metric[1]
```

- è®­ç»ƒå‡½æ•°

```
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device): 
    """ç”¨GPUè®­ç»ƒæ¨¡å‹(åœ¨ç¬¬å…­ç« å®šä¹‰)"""
    def init_weights(m):
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight)#å¯¹linearç±»å‹çš„å±‚ç”¨xavieråˆå§‹åŒ–
    net.apply(init_weights)
    print('training on', device)
    net.to(device)
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    loss = nn.CrossEntropyLoss()
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                            legend=['train loss', 'train acc', 'test acc'])#åŠ¨ç”»éœ€è¦
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        # è®­ç»ƒæŸå¤±ä¹‹å’Œï¼Œè®­ç»ƒå‡†ç¡®ç‡ä¹‹å’Œï¼ŒèŒƒä¾‹æ•°
        metric = d2l.Accumulator(3)
        net.train()
        for i, (X, y) in enumerate(train_iter):
            timer.start()
            optimizer.zero_grad()#æ¢¯åº¦æ¸…é›¶
            X, y = X.to(device), y.to(device)
            y_hat = net(X)#æ­£å‘ä¼ æ’­
            l = loss(y_hat, y)#è®¡ç®—æŸå¤±
            l.backward()#åå‘ä¼ æ’­
            optimizer.step()#æ¢¯åº¦ä¸‹é™
            with torch.no_grad():
                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])#è®­ç»ƒæŸå¤±ä¹‹å’Œï¼Œè®­ç»ƒå‡†ç¡®ç‡ä¹‹å’Œï¼ŒèŒƒä¾‹æ•°
            timer.stop()
            train_l = metric[0] / metric[2]
            train_acc = metric[1] / metric[2]
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (train_l, train_acc, None))
        test_acc = evaluate_accuracy_gpu(net, test_iter)#è¯„ä¼°æµ‹è¯•é›†çš„ç²¾åº¦
        animator.add(epoch + 1, (None, None, test_acc))
    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '
          f'test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '
          f'on {str(device)}')
```

- è¿è¡Œ

```
lr, num_epochs = 0.9, 10
train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```







# ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œ

## AlexNet

### å†å²

#### 2000 æµè¡Œçš„æœºå™¨å­¦ä¹ æ–¹æ³•â€”â€”SVMï¼Œæ ¸æ–¹æ³•

- æ ¸æ–¹æ³•æ›¿ä»£äº†ä¹‹å‰çš„ç¥ç»ç½‘ç»œç½‘ç»œæ–¹æ³•ï¼ŒSVMå¯¹äºè°ƒå‚ä¸æ•æ„Ÿï¼Œç°åœ¨ä¹Ÿæœ‰ä¸€äº›åº”ç”¨
- æœ¬è´¨ä¸Šæ˜¯ç‰¹å¾æå–ï¼Œå…·ä½“çš„æ–¹æ³•æ˜¯é€‰æ‹©æ ¸å‡½æ•°æ¥è®¡ç®—ï¼ŒæŠŠç‰¹å¾æ˜ å°„åˆ°é«˜çº¬ç©ºé—´ï¼Œä½¿å¾—ä»–ä»¬çº¿æ€§å¯åˆ†
- ç»è¿‡æ ¸å‡½æ•°è®¡ç®—ä¹‹åï¼ŒåŸé—®é¢˜å¯ä»¥è½¬åŒ–ä¸ºå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œè¿™æ˜¯2006å¹´å·¦å³çš„ç ”ç©¶çƒ­ç‚¹
- æ ¸æ–¹æ³•æœ‰å¾ˆå¤šæ¼‚äº®çš„å®šç†ï¼Œæœ‰å¾ˆå¥½çš„æ•°å­¦è§£é‡Šæ€§
- 2010å¹´å·¦å³ï¼Œæ·±åº¦å­¦ä¹ æ‰å…´èµ·

#### 2000è®¡ç®—æœºè§†è§‰ä¸»è¦æ–¹æ³•â€”â€”å‡ ä½•å­¦

- é¦–å…ˆè¿˜æ˜¯å¯¹å›¾ç‰‡è¿›è¡Œç‰¹å¾æŠ½å–
- å¸Œæœ›æŠŠè®¡ç®—æœºè§†è§‰é—®é¢˜æè¿°æˆå‡ ä½•é—®é¢˜ï¼Œå»ºç«‹ï¼ˆéï¼‰å‡¸ä¼˜åŒ–æ¨¡å‹ï¼Œå¯ä»¥å¾—åˆ°å¾ˆå¤šæ¼‚äº®çš„å®šç†ã€‚
- å¯ä»¥å‡è®¾è¿™æ˜¯ä¸€ä¸ªå‡ ä½•é—®é¢˜ï¼Œå‡è®¾è¿™ä¸ªå‡è®¾è¢«æ»¡è¶³äº†ï¼Œå¯ä»¥æ¨å‡ºå¾ˆå¥½çš„æ•ˆæœ

#### 2010è®¡ç®—æœºè§†è§‰çš„çƒ­ç‚¹é—®é¢˜â€”â€”ç‰¹å¾å·¥ç¨‹

- ç‰¹å¾å·¥ç¨‹å°±æ˜¯æ€ä¹ˆæŠ½å–ä¸€å¼ å›¾ç‰‡çš„ç‰¹å¾ï¼Œå› ä¸ºç›´æ¥è¾“å…¥ä¸€å¼ å›¾ç‰‡æ•ˆæœéå¸¸çš„å·®
- ç‰¹å¾æè¿°å­ï¼šSIFT,SURF

#### ç¡¬ä»¶çš„å‘å±•å¥ å®šäº†æ·±åº¦å­¦ä¹ çš„å…´èµ·

- æ•°æ®çš„å¢é•¿ï¼Œç¡¬ä»¶çš„è®¡ç®—èƒ½åŠ›å¥ å®šäº†äººä»¬å¯¹äºæ–¹æ³•çš„é€‰æ‹©

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-01.png)

#### ImageNetï¼ˆ2010ï¼‰

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-02.png)

- AlexNetèµ¢å¾—äº†2012å¹´ImageNetç«èµ›å† å†›

- æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåŠ å¼ºç‰ˆçš„LeNetï¼Œæ›´æ·±æ›´å¤§

- AlexNetä¸»è¦æ”¹è¿›æªæ–½ï¼š

  - dropoutï¼ˆæ­£åˆ™ï¼‰
  - ReLuï¼ˆæ¢¯åº¦æ›´å¤§ï¼‰
  - MaxPoolingï¼ˆå–æœ€å¤§å€¼ï¼Œæ¢¯åº¦ç›¸å¯¹å¢å¤§ï¼‰

- å½±å“ï¼šè®¡ç®—æœºè§†è§‰æ–¹æ³•è®ºçš„æ”¹å˜ï¼Œä»äººå·¥æå–ç‰¹å¾è¿‡æ¸¡åˆ°CNNå­¦ä¹ ç‰¹å¾

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-03.png)

### AlexNetæ¶æ„

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-04.png)

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-05.png)

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-06.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-06.png)

- ç½‘ç»œä»£ç 

```
import torch
from torch import nn
from d2l import torch as d2l

 net=nn.Sequential(
 	nn.Conv2d(1,96,kernel_size=11,stride=4,padding=1),
 	nn.ReLu()ï¼Œ
 	nn.MaxPool2d(pool_size=3,stride=2),
 	
 	nn.Conv2d(96,256,kernel_size=5,stride=1,padding=2),
 	nn.ReLu()ï¼Œ
 	nn.MaxPool2d(pool_size=3,stride=2),
 	
 	nn.Conv2d(256,384,kernel_size=3,stride=1,padding=1),
 	nn.ReLu()ï¼Œ
 	nn.Conv2d(384,384,kernel_size=3,stride=1,padding=1),
 	nn.ReLu()ï¼Œ
 	nn.Conv2d(384,384,kernel_size=3,stride=1,padding=1),
 	nn.ReLu()ï¼Œ
 	nn.MaxPool2d(pool_size=3,stride=2),
 	
 	nn.Linear(6400,4096),nn.ReLu(),nn.dropout(p=0.5),
 	nn.Linear(4096,4096),nn.ReLu(),nn.dropout(p=0.5),
 	nn.Linear(4096,1000)
 )
 
 X=torch.rand(1,1,224,224)
```

- æ›´å¤šç»†èŠ‚
  - æ¿€æ´»å‡½æ•°ä»sigmoidå˜æˆReluï¼Œå‡ç¼“æ¢¯åº¦æ¶ˆå¤±
  - éšè—å…¨è¿æ¥å±‚ååŠ å…¥äº†ä¸¢å¼ƒå±‚ï¼ˆ2ä¸ª4096ä¹‹ååŠ å…¥äº†dropoutï¼‰
  - æ•°æ®å¢å¼ºï¼Œå°†ä¸€å¼ å›¾ç‰‡è¿›è¡Œå˜åŒ–ï¼Œé€‰å–å¤šä¸ªä½ç½®ã€å…‰ç…§ä¹‹ç±»çš„ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-07.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-07.png)

- å¤æ‚åº¦å¯¹æ¯”
  - å‚æ•°ä¸ªæ•°å¢åŠ ï¼Œæ¯æ¬¡æ›´æ–°æ•°æ®å¢åŠ 

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/24/24-08.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/24/24-08.png)

### æ€»ç»“

- AlexNet æ˜¯æ›´å¤§æ›´æ·±çš„LeNetï¼Œ10xå‚æ•°ä¸ªæ•°ï¼Œ260xè®¡ç®—å¤æ‚åº¦
- æ–°åŠ å…¥äº†dropoutï¼Œreluï¼Œmaxpoolingï¼Œæ•°æ®å¢å¼º
- æ ‡å¿—ç€æ–°ä¸€è½®ç¥ç»ç½‘ç»œçƒ­æ½®å¼€å§‹äº†

## ä½¿ç”¨å—çš„ç½‘ç»œVGG

### NiNVGGå—

ç›´åˆ°ç°åœ¨æ›´æ·±æ›´å¤§çš„æ¨¡å‹ä¹Ÿæ˜¯æˆ‘ä»¬åŠªåŠ›çš„æ–¹å‘ï¼Œåœ¨å½“æ—¶AlexNetæ¯”LeNetæ›´æ·±æ›´å¤§å¾—åˆ°äº†æ›´å¥½çš„ç²¾åº¦ï¼Œå¤§å®¶ä¹Ÿå¸Œæœ›æŠŠç½‘ç»œåšçš„æ›´æ·±æ›´å¤§ã€‚é€‰æ‹©ä¹‹ä¸€æ˜¯ä½¿ç”¨æ›´å¤šçš„å…¨è¿æ¥å±‚ï¼Œä½†å…¨è¿æ¥å±‚çš„æˆæœ¬å¾ˆé«˜ï¼›ç¬¬äºŒä¸ªé€‰æ‹©æ˜¯ä½¿ç”¨æ›´å¤šçš„å·ç§¯å±‚ï¼Œä½†**ç¼ºä¹å¥½çš„æŒ‡å¯¼æ€æƒ³**æ¥è¯´æ˜åœ¨å“ªåŠ ï¼ŒåŠ å¤šå°‘ã€‚æœ€ç»ˆ**VGGé‡‡å–äº†å°†å·ç§¯å±‚ç»„åˆæˆå—**ï¼Œå†æŠŠ**å·ç§¯å—ç»„åˆåˆ°ä¸€èµ·**çš„æ€è·¯ã€‚

VGGå—å¯ä»¥çœ‹ä½œæ˜¯AlexNetæ€è·¯çš„æ‹“å±•ï¼ŒAlexNetä¸­å°†ä¸‰ä¸ªç›¸åŒçš„å·ç§¯å±‚æ”¾åœ¨ä¸€èµ·å†åŠ ä¸Šä¸€ä¸ªæ± åŒ–å±‚ï¼Œè€ŒVGGå°†å…¶æ‹“å±•æˆå¯ä»¥ä½¿ç”¨ä»»æ„ä¸ª3x3ï¼Œä¸æ”¹å˜è¾“å…¥å¤§å°çš„çš„å·ç§¯å±‚ï¼Œæœ€ååŠ ä¸Šä¸€ä¸ª2x2çš„æœ€å¤§æ± åŒ–å±‚ã€‚

[![25-01](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/25/25-01.PNG)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/25/25-01.PNG)

ä¸ºä»€ä¹ˆé€‰æ‹©3x3å·ç§¯å‘¢ï¼Ÿåœ¨è®¡ç®—é‡ç›¸åŒçš„æƒ…å†µä¸‹é€‰ç”¨æ›´å¤§çš„å·ç§¯æ ¸æ¶‰åŠå¯¹ç½‘ç»œä¼šè¶Šæµ…ï¼ŒVGGä½œè€…ç»è¿‡å®éªŒå‘ç°ç”¨3x3å·ç§¯çš„æ•ˆæœè¦æ¯”5x5å¥½ï¼Œä¹Ÿå°±æ˜¯è¯´ç¥ç»ç½‘ç»œåº“æ·±ä¸”çª„çš„æ•ˆæœä¼šæ›´å¥½ã€‚

### VGGæ¶æ„

å¤šä¸ªVGGå—åæ¥å…¨è¿æ¥å±‚ï¼Œä¸åŒæ¬¡æ•°çš„é‡å¤å—å¾—åˆ°ä¸åŒçš„æ¶æ„ï¼Œå¦‚VGG-16, VGG-19ç­‰ï¼Œåé¢çš„æ•°å­—å–å†³äºç½‘ç»œå±‚æ•°ã€‚

å¯ä»¥è®²VGGçœ‹ä½œæ˜¯å°†AlexNetä¸­è¿ç»­å·ç§¯çš„éƒ¨åˆ†å–å‡ºåŠ ä»¥æ¨å¹¿å’Œå¤åˆ¶ï¼Œå¹¶åˆ å»äº†AlexNetä¸­ä¸é‚£ä¹ˆè§„æ•´çš„å‰å‡ å±‚ã€‚

[![25-02](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/25/25-02.PNG)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/25/25-02.PNG)

VGGè¾ƒAlexNetç›¸æ¯”æ€§èƒ½æœ‰å¾ˆå¤§çš„æå‡ï¼Œè€Œä»£ä»·æ˜¯å¤„ç†æ ·æœ¬é€Ÿåº¦çš„é™ä½å’Œå†…å­˜å ç”¨çš„å¢åŠ ã€‚

### æ€»ç»“

- VGGä½¿ç”¨å¯é‡å¤ä½¿ç”¨çš„å·ç§¯å—æ¥æ„å»ºæ·±åº¦å·ç§¯ç½‘ç»œ
- ä¸åŒå·ç§¯å—ä¸ªæ•°å’Œè¶…å‚æ•°å¯ä»¥å¾—åˆ°ä¸åŒå¤æ‚åº¦çš„å˜ç§

è¿™äº›æ€æƒ³å½±å“äº†åé¢ç¥ç»ç½‘ç»œçš„è®¾è®¡ï¼Œåœ¨ä¹‹åçš„æ¨¡å‹ä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚

### ä»£ç 

VGGå—

```
import torch
from torch import nn
from d2l import torch as d2l

def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(in_channels, out_channels,
                                kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))
    return nn.Sequential(*layers)
    
conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))

def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    # å·ç§¯å±‚éƒ¨åˆ†
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))
        in_channels = out_channels

    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        # å…¨è¿æ¥å±‚éƒ¨åˆ†
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 10))

net = vgg(conv_arch)
```





## NiN-ç½‘ç»œä¸­çš„ç½‘ç»œ

### åŠ¨æœº

**å…¨è¿æ¥å±‚çš„é—®é¢˜**

- **å·ç§¯å±‚**éœ€è¦çš„**å‚æ•°è¾ƒå°‘**
- è€Œå·ç§¯å±‚åçš„ç¬¬ä¸€ä¸ª**å…¨è¿æ¥å±‚**çš„**å‚æ•°è¾ƒå¤š**

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/26/26-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/26/26-01.png)

ä»¥VGGä¸ºä¾‹(å›¾ç¤º)ï¼Œå…¨è¿æ¥å±‚éœ€è¦å…ˆFlattenï¼Œè¾“å…¥ç»´åº¦ä¸º512x7x7ï¼Œè¾“å‡ºç»´åº¦ä¸º4096ï¼Œåˆ™éœ€è¦å‚æ•°ä¸ªæ•°ä¸º512x7x7x4096=102Mã€‚

### NiNå—

- æ ¸å¿ƒæ€æƒ³ï¼šä¸€ä¸ªå·ç§¯å±‚åé¢è·Ÿä¸¤ä¸ª1x1çš„å·ç§¯å±‚ï¼Œåä¸¤å±‚èµ·åˆ°å…¨è¿æ¥å±‚çš„ä½œç”¨ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/26/26-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/26/26-02.png)

### NiNæ¶æ„

- æ— å…¨è¿æ¥å±‚
- äº¤æ›¿ä½¿ç”¨NiNå—å’Œæ­¥å¹…ä¸º2çš„æœ€å¤§æ± åŒ–å±‚
  - é€æ­¥å‡å°é«˜å®½å’Œå¢å¤§é€šé“æ•°
- æœ€åä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–å¾—åˆ°è¾“å‡º
  - å…¶è¾“å…¥é€šé“æ˜¯ç±»åˆ«æ•°

### NiN Networks

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/26/26-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/26/26-03.png)

NiNæ¶æ„å¦‚ä¸Šå›¾å³è¾¹æ‰€ç¤ºï¼Œè‹¥å¹²ä¸ªNiNå—(å›¾ç¤ºä¸­ä¸º4ä¸ªå—)+æ± åŒ–å±‚ï¼›å‰3ä¸ªå—åæ¥æœ€å¤§æ± åŒ–å±‚ï¼Œæœ€åä¸€å—è¿æ¥ä¸€ä¸ªå…¨å±€å¹³å‡æ± åŒ–å±‚ã€‚

### æ€»ç»“

- NiNå—ç»“æ„ï¼šä½¿ç”¨å·ç§¯å±‚åŠ ä¸¤ä¸ª1x1å·ç§¯å±‚
  - åè€…å¯¹æ¯ä¸ªåƒç´ å¢åŠ äº†éçº¿æ€§æ€§
- NiNä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–å±‚æ¥æ›¿ä»£VGGå’ŒAlexNetä¸­çš„å…¨è¿æ¥å±‚
  - ä¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œæ›´å°‘çš„å‚æ•°ä¸ªæ•°

### ä»£ç 

```
# å¦‚æœåœ¨Colabä¸Šè·‘, æˆ–æ²¡æœ‰å®‰è£…è¿‡d2låŒ…, éœ€è¦æœ€å¼€å§‹pip install d2l
!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l
```

**NiNå—**

```
import torch
from torch import nn
from d2l import torch as d2l

# å®šä¹‰NiNå—
def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),
        nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1),
        nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1),
        nn.ReLU())
```

**NiNæ¨¡å‹**

```
net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2), nn.Dropout(0.5),
    # æ ‡ç­¾ç±»åˆ«æ•°æ˜¯10
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),          #å…¨å±€å¹³å‡æ± åŒ–ï¼Œé«˜å®½éƒ½å˜æˆ1
    nn.Flatten())             #æ¶ˆæ‰æœ€åä¸¤ä¸ªç»´åº¦, å˜æˆ(batch_size, 10)
```

**demoæµ‹è¯•ï¼ŒæŸ¥çœ‹æ¯ä¸ªå—çš„è¾“å‡ºæƒ…å†µ**

```
X = torch.rand(size=(1, 1, 224, 224))
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__, 'output shape:\t', X.shape)
```

```
>>>
Sequential output shape:	 torch.Size([1, 96, 54, 54])
MaxPool2d output shape:		 torch.Size([1, 96, 26, 26])
Sequential output shape:	 torch.Size([1, 256, 26, 26])
MaxPool2d output shape:		 torch.Size([1, 256, 12, 12])
Sequential output shape:	 torch.Size([1, 384, 12, 12])
MaxPool2d output shape:		 torch.Size([1, 384, 5, 5])
Dropout output shape:		 torch.Size([1, 384, 5, 5])
Sequential output shape:	 torch.Size([1, 10, 5, 5])
AdaptiveAvgPool2d output shape:	 torch.Size([1, 10, 1, 1])
Flatten output shape:		 torch.Size([1, 10])
```

**è®­ç»ƒæ¨¡å‹**

```
lr, num_epochs, batch_size = 0.1, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

```
>>> <Figure size 252x180 with 1 Axes>
```





## GoogLeNet

### å«å¹¶è¡Œè¿ç»“çš„ç½‘ç»œ

- GoogLeNetå¸æ”¶äº†NiNä¸­ä¸²è”ç½‘ç»œçš„æ€æƒ³ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šåšäº†æ”¹è¿›ã€‚æˆ‘ä»¬å¾€å¾€ä¸ç¡®å®šåˆ°åº•é€‰å–ä»€ä¹ˆæ ·çš„å±‚æ•ˆæœæ›´å¥½ï¼Œåˆ°åº•æ˜¯3X3å·ç§¯å±‚è¿˜æ˜¯5X5çš„å·ç§¯å±‚ï¼Œè¯¸å¦‚æ­¤ç±»çš„é—®é¢˜æ˜¯GooLeNeté€‰æ‹©äº†å¦ä¸€ç§æ€è·¯â€œå°å­¦ç”Ÿæ‰åšé€‰æ‹©ï¼Œæˆ‘å…¨éƒ½è¦â€ï¼Œè¿™ä¹Ÿä½¿å¾—GooLeNetæˆä¸ºäº†ç¬¬ä¸€ä¸ªæ¨¡å‹ä¸­è¶…è¿‡1000ä¸ªå±‚çš„æ¨¡å‹ã€‚
- é€‰æ‹©å„ç§å·ç§¯å±‚çš„é€šé“æ•°é‡ï¼ˆè¾“å‡ºå›¾ç‰‡çš„é«˜å®½æ˜¯ä¸ä¼šæ”¹å˜çš„ï¼‰

### Inceptionå—

- åœ¨GoogLeNetä¸­ï¼ŒåŸºæœ¬çš„å·ç§¯å—è¢«ç§°ä¸º*Inceptionå—*ï¼ˆInception blockï¼‰

  [![æˆªå±2022-01-23 ä¸Šåˆ10.11.18](https://github.com/kinza99/DeepLearning-MuLi-Notes/raw/main/imgs/27/27-1.png)](https://github.com/kinza99/DeepLearning-MuLi-Notes/blob/main/imgs/27/27-1.png)

- Inceptionå—ç”±å››æ¡å¹¶è¡Œè·¯å¾„ç»„æˆã€‚ å‰ä¸‰æ¡è·¯å¾„ä½¿ç”¨çª—å£å¤§å°ä¸º1Ã—1ã€3Ã—3å’Œ5Ã—5çš„å·ç§¯å±‚ï¼Œä»ä¸åŒç©ºé—´å¤§å°ä¸­æå–ä¿¡æ¯ã€‚ ä¸­é—´çš„ä¸¤æ¡è·¯å¾„åœ¨è¾“å…¥ä¸Šæ‰§è¡Œ1Ã—1å·ç§¯ï¼Œä»¥å‡å°‘é€šé“æ•°ï¼Œä»è€Œé™ä½æ¨¡å‹çš„å¤æ‚æ€§ã€‚ ç¬¬å››æ¡è·¯å¾„ä½¿ç”¨3Ã—3æœ€å¤§æ±‡èšå±‚ï¼Œç„¶åä½¿ç”¨1Ã—1å·ç§¯å±‚æ¥æ”¹å˜é€šé“æ•°ã€‚ è¿™å››æ¡è·¯å¾„éƒ½ä½¿ç”¨åˆé€‚çš„å¡«å……æ¥ä½¿è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œæœ€åæˆ‘ä»¬å°†æ¯æ¡çº¿è·¯çš„è¾“å‡ºåœ¨é€šé“ç»´åº¦ä¸Šè¿ç»“ï¼Œå¹¶æ„æˆInceptionå—çš„è¾“å‡ºã€‚åœ¨Inceptionå—ä¸­ï¼Œé€šå¸¸è°ƒæ•´çš„è¶…å‚æ•°æ˜¯æ¯å±‚è¾“å‡ºé€šé“æ•°ã€‚

- æˆ‘ä»¬å‘ç°è·¯å¾„çš„ä¸åŒç»„åˆæ–¹å¼ã€‚å•çº¯çš„å·ç§¯å±‚ï¼›é€šé“å°çš„å·ç§¯+é€šé“å¤§çš„å·ç§¯ï¼›æ± åŒ–å±‚+å·ç§¯å±‚ã€‚

### GoogleNetæ¨¡å‹

- GoogLeNetä¸€å…±ä½¿ç”¨9ä¸ªInceptionå—å’Œå…¨å±€å¹³å‡æ±‡èšå±‚çš„å †å æ¥ç”Ÿæˆå…¶ä¼°è®¡å€¼ã€‚Inceptionå—ä¹‹é—´çš„æœ€å¤§æ±‡èšå±‚å¯é™ä½ç»´åº¦ã€‚ ç¬¬ä¸€ä¸ªæ¨¡å—ç±»ä¼¼äºAlexNetå’ŒLeNetï¼ŒInceptionå—çš„ç»„åˆä»VGGç»§æ‰¿ï¼Œå…¨å±€å¹³å‡æ±‡èšå±‚é¿å…äº†åœ¨æœ€åä½¿ç”¨å…¨è¿æ¥å±‚ã€‚[![æˆªå±2022-01-23 ä¸Šåˆ10.17.11](https://github.com/kinza99/DeepLearning-MuLi-Notes/raw/main/imgs/27/27-2.png)](https://github.com/kinza99/DeepLearning-MuLi-Notes/blob/main/imgs/27/27-2.png)
- ç¬¬ä¸€ä¸ªæ¨¡å—æ˜¯7Ã—7å·ç§¯å±‚+æ± åŒ–ã€‚

![image-20240713230335077](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240713230335077.png)

- ç¬¬äºŒä¸ªæ¨¡å—ä½¿ç”¨ä¸¤ä¸ªå·ç§¯å±‚ï¼šç¬¬ä¸€ä¸ªå·ç§¯å±‚æ˜¯1Ã—1å·ç§¯å±‚ï¼›ç¬¬äºŒä¸ªå·ç§¯å±‚ä½¿ç”¨så°†é€šé“æ•°é‡å¢åŠ ä¸‰å€çš„3Ã—3å·ç§¯å±‚ã€‚ è¿™å¯¹åº”äºInceptionå—ä¸­çš„ç¬¬äºŒæ¡è·¯å¾„ã€‚

![image-20240713230408146](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240713230408146.png)

- ç¬¬ä¸‰ä¸ªæ¨¡å—ä¸²è”ä¸¤ä¸ªå®Œæ•´çš„Inceptionå—ã€‚ ç¬¬ä¸€ä¸ªInceptionå—çš„è¾“å‡ºé€šé“æ•°ä¸º64+128+32+32=25664+128+32+32=256ï¼Œå››ä¸ªè·¯å¾„ä¹‹é—´çš„è¾“å‡ºé€šé“æ•°é‡æ¯”ä¸º64:128:32:32=2:4:1:1ã€‚ ç¬¬äºŒä¸ªå’Œç¬¬ä¸‰ä¸ªè·¯å¾„é¦–å…ˆå°†è¾“å…¥é€šé“çš„æ•°é‡åˆ†åˆ«å‡å°‘åˆ°96/192=1/296/192=1/2å’Œ16/192=1/1216/192=1/12ï¼Œç„¶åè¿æ¥ç¬¬äºŒä¸ªå·ç§¯å±‚ã€‚ç¬¬äºŒä¸ªInceptionå—çš„è¾“å‡ºé€šé“æ•°å¢åŠ åˆ°128+192+96+64=480ï¼Œå››ä¸ªè·¯å¾„ä¹‹é—´çš„è¾“å‡ºé€šé“æ•°é‡æ¯”ä¸º128:192:96:64=4:6:3:2ã€‚ ç¬¬äºŒæ¡å’Œç¬¬ä¸‰æ¡è·¯å¾„é¦–å…ˆå°†è¾“å…¥é€šé“çš„æ•°é‡åˆ†åˆ«å‡å°‘åˆ°128/256=1/2128/256=1/2å’Œ32/256=1/832/256=1/8ã€‚

![image-20240713230710702](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240713230710702.png)

- ç¬¬å››æ¨¡å—æ›´åŠ å¤æ‚ï¼Œ å®ƒä¸²è”äº†5ä¸ªInceptionå—ï¼Œå…¶è¾“å‡ºé€šé“æ•°åˆ†åˆ«æ˜¯192+208+48+64=512ã€160+224+64+64=512ã€128+256+64+64=512ã€112+288+64+64=528å’Œ256+320+128+128=832256+320+128+128=832ã€‚ è¿™äº›è·¯å¾„çš„é€šé“æ•°åˆ†é…å’Œç¬¬ä¸‰æ¨¡å—ä¸­çš„ç±»ä¼¼ï¼Œé¦–å…ˆæ˜¯å«3Ã—3å·ç§¯å±‚çš„ç¬¬äºŒæ¡è·¯å¾„è¾“å‡ºæœ€å¤šé€šé“ï¼Œå…¶æ¬¡æ˜¯ä»…å«1Ã—1å·ç§¯å±‚çš„ç¬¬ä¸€æ¡è·¯å¾„ï¼Œä¹‹åæ˜¯å«5Ã—5å·ç§¯å±‚çš„ç¬¬ä¸‰æ¡è·¯å¾„å’Œå«3Ã—3æœ€å¤§æ±‡èšå±‚çš„ç¬¬å››æ¡è·¯å¾„ã€‚ å…¶ä¸­ç¬¬äºŒã€ç¬¬ä¸‰æ¡è·¯å¾„éƒ½ä¼šå…ˆæŒ‰æ¯”ä¾‹å‡å°é€šé“æ•°ã€‚ è¿™äº›æ¯”ä¾‹åœ¨å„ä¸ªInceptionå—ä¸­éƒ½ç•¥æœ‰ä¸åŒã€‚

### æ€»ç»“

- Inceptionå—ç›¸å½“äºä¸€ä¸ªæœ‰4æ¡è·¯å¾„çš„å­ç½‘ç»œã€‚å®ƒé€šè¿‡ä¸åŒçª—å£å½¢çŠ¶çš„å·ç§¯å±‚å’Œæœ€å¤§æ±‡èšå±‚æ¥å¹¶è¡ŒæŠ½å–ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨1Ã—1å·ç§¯å±‚å‡å°‘æ¯åƒç´ çº§åˆ«ä¸Šçš„é€šé“ç»´æ•°ä»è€Œé™ä½æ¨¡å‹å¤æ‚åº¦ã€‚
- GoogLeNetå°†å¤šä¸ªè®¾è®¡ç²¾ç»†çš„Inceptionå—ä¸å…¶ä»–å±‚ï¼ˆå·ç§¯å±‚ã€å…¨è¿æ¥å±‚ï¼‰ä¸²è”èµ·æ¥ã€‚å…¶ä¸­Inceptionå—çš„é€šé“æ•°åˆ†é…ä¹‹æ¯”æ˜¯åœ¨ImageNetæ•°æ®é›†ä¸Šé€šè¿‡å¤§é‡çš„å®éªŒå¾—æ¥çš„ã€‚
- GoogLeNetå’Œå®ƒçš„åç»§è€…ä»¬ä¸€åº¦æ˜¯ImageNetä¸Šæœ€æœ‰æ•ˆçš„æ¨¡å‹ä¹‹ä¸€ï¼šå®ƒä»¥è¾ƒä½çš„è®¡ç®—å¤æ‚åº¦æä¾›äº†ç±»ä¼¼çš„æµ‹è¯•ç²¾åº¦ã€‚





## æ‰¹é‡å½’ä¸€åŒ–

æ·±å±‚ç¥ç»ç½‘ç»œçš„è®­ç»ƒï¼Œå°¤å…¶æ˜¯ä½¿ç½‘ç»œåœ¨è¾ƒçŸ­æ—¶é—´å†…æ”¶æ•›æ˜¯ååˆ†å›°éš¾çš„ï¼Œ**æ‰¹é‡å½’ä¸€åŒ–[batch normalization]**æ˜¯ä¸€ç§æµè¡Œä¸”æœ‰æ•ˆçš„æŠ€æœ¯ï¼Œèƒ½åŠ é€Ÿæ·±å±‚ç½‘ç»œçš„æ”¶æ•›é€Ÿåº¦ï¼Œç›®å‰ä»è¢«å¹¿æ³›ä½¿ç”¨ã€‚

### è®­ç»ƒæ·±å±‚ç½‘ç»œæ—¶çš„é—®é¢˜-æ”¶æ•›å›°éš¾



[![deep-model](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/28/deep_model.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/28/deep_model.png)

æ·±åº¦ç¥ç»ç½‘ç»œåœ¨è®­ç»ƒæ—¶ä¼šé‡åˆ°ä¸€äº›é—®é¢˜ï¼š

- æ”¶æ•›é€Ÿåº¦æ…¢ï¼š
  - ç”±äºè®­ç»ƒæ—¶å…ˆæ­£å‘ä¼ æ’­ååå‘ä¼ æ’­ï¼Œä¸”æ¯å±‚çš„æ¢¯åº¦ä¸€èˆ¬è¾ƒå°ï¼Œè‹¥ç½‘ç»œè¾ƒæ·±ï¼Œåˆ™åå‘ä¼ æ’­æ—¶ä¼šå‡ºç°ç±»ä¼¼äºæ¢¯åº¦æ¶ˆå¤±çš„ç°è±¡ï¼Œå¯¼è‡´è·ç¦»æ•°æ®æ›´è¿‘çš„å±‚æ¢¯åº¦è¾ƒå°ï¼Œæ”¶æ•›æ…¢ï¼Œè€Œè·ç¦»è¾“å‡ºæ›´è¿‘çš„å±‚æ¢¯åº¦è¾ƒå¤§ï¼Œæ”¶æ•›å¿«ã€‚ç„¶è€Œåº•éƒ¨çš„å±‚ä¸€èˆ¬éƒ½ç”¨äºæå–è¾ƒåŸºç¡€çš„ç‰¹å¾ä¿¡æ¯ï¼Œä¸Šæ–¹çš„å±‚æ”¶æ•›åï¼Œç”±äºåº•éƒ¨æå–åŸºç¡€ç‰¹å¾çš„å±‚ä»åœ¨å˜åŒ–ï¼ˆç”±äºå‚æ•°ä¸€ç›´åœ¨éšç€æ¯å±‚æ¢¯åº¦è€Œä¸æ–­æ›´æ–°ï¼Œæ‰€ä»¥åº•éƒ¨æå–ä¹Ÿåœ¨ä¸æ–­å‘ç”Ÿå˜åŒ–ï¼‰ï¼Œä¸Šæ–¹çš„å±‚ä¸€ç›´åœ¨ä¸åœçš„é‡æ–°è®­ç»ƒï¼Œå¯¼è‡´æ•´ä¸ªç½‘ç»œéš¾ä»¥æ”¶æ•›ï¼Œè®­ç»ƒè¾ƒæ…¢ã€‚
- å†…éƒ¨åå˜é‡è½¬ç§»ï¼š
  - åˆ†å¸ƒåç§»ï¼šåç§»åœ¨è§†é¢‘è¯¾ç¨‹ä¸­å¹¶æœªå‡ºç°ï¼Œä½†åœ¨ã€ŠåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‹è¿™æœ¬ä¹¦ä¸­æœ‰æåˆ°è¿‡ï¼Œåœ¨[4.9. ç¯å¢ƒå’Œåˆ†å¸ƒåç§»](https://zh-v2.d2l.ai/chapter_multilayer-perceptrons/environment.html)éƒ¨åˆ†ã€‚åç§»æŒ‡çš„æ˜¯è®­ç»ƒæ•°æ®å¯èƒ½å’Œæµ‹è¯•æ•°æ®çš„åˆ†å¸ƒä¸åŒï¼Œæ¯”å¦‚åˆ©ç”¨æ¥è‡ªçœŸå®çš„çŒ«å’Œç‹—çš„ç…§ç‰‡çš„è®­ç»ƒæ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œç„¶åè®©æ¨¡å‹å»é¢„æµ‹åŠ¨ç”»ä¸­çš„çŒ«å’Œç‹—çš„å›¾ç‰‡ã€‚[![cat-dog-train](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/28/cat-dog-train.svg)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/28/cat-dog-train.svg)[![cat-dog-test](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/28/cat-dog-test.svg)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/28/cat-dog-test.svg)è¿™æ˜¾ç„¶ä¼šé™ä½æ­£ç¡®ç‡ä¹Ÿä¼šå¯¹æ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–å¸¦æ¥å¹²æ‰°ã€‚ä¸€èˆ¬æƒ…å†µä¸‹å¯¹äºåˆ†å¸ƒåç§»æˆ‘ä»¬æ¯«æ— åŠæ³•ï¼Œç„¶è€Œï¼Œåœ¨ä¸€äº›ç‰¹å®šåœºæ™¯ä¸­ï¼Œå¦‚æœå‡å®šä¸€äº›è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®åˆ†å¸ƒçš„å‰ææ¡ä»¶ï¼Œå°±èƒ½å¯¹åˆ†å¸ƒåç§»è¿›è¡Œå¤„ç†ï¼Œå…¶ä¸­ä¹‹ä¸€å°±æ˜¯åå˜é‡åç§»ã€‚
  - åå˜é‡åç§»ï¼šåå˜é‡åç§»å‡è®¾è¾“å…¥çš„åˆ†å¸ƒå¯èƒ½éšæ—¶é—´å˜åŒ–ï¼Œä½†æ ‡ç­¾å‡½æ•°ï¼ˆæ¡ä»¶åˆ†å¸ƒ$P(y|\bold x)$ï¼‰æ²¡æœ‰æ”¹å˜ã€‚ç»Ÿè®¡å­¦å®¶ç§°è¿™ä¸º*åå˜é‡åç§»*ï¼ˆcovariate shiftï¼‰å¹¶ç»™å‡ºäº†ä¸€äº›è§£å†³æ–¹æ¡ˆ
  - **å†…éƒ¨åå˜é‡åç§»(Internal Covariate Shift)**ï¼šæ¯ä¸€å±‚çš„å‚æ•°åœ¨æ›´æ–°è¿‡ç¨‹ä¸­ï¼Œä¼šæ”¹å˜ä¸‹ä¸€å±‚è¾“å…¥çš„åˆ†å¸ƒï¼Œå¯¼è‡´ç½‘ç»œå‚æ•°å˜å¹»è«æµ‹ï¼Œéš¾ä»¥æ”¶æ•›ï¼Œç¥ç»ç½‘ç»œå±‚æ•°è¶Šå¤šï¼Œè¡¨ç°å¾—è¶Šæ˜æ˜¾ã€‚
  - æ³¨æ„ï¼š
    - 1ï¼šå†…éƒ¨åå˜é‡åç§»è¿™ä¸ªè¯ä¸æ ‡å‡†çš„åå˜é‡åç§»æ‰€æœ‰åŒºåˆ«ã€‚
    - 2ï¼šèƒ½ç¼“è§£å†…éƒ¨åå˜é‡åç§»ä»…ä»…æ˜¯æ‰¹é‡å½’ä¸€åŒ–çš„ä½œè€…æå‡ºçš„å‡æƒ³ï¼Œåç»­è®ºæ–‡è¯å®æ‰¹é‡å½’ä¸€åŒ–å®é™…å¯¹å†…éƒ¨åå˜é‡åç§»çš„ç¼“è§£å¸®åŠ©ä¸å¤§
    - 3ï¼šæ‰¹é‡å½’ä¸€åŒ–ä¸€èˆ¬åªå½±å“æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦ï¼Œä¸å½±å“ç²¾åº¦
- è¿‡æ‹Ÿåˆï¼š
  - ç”±äºç½‘ç»œæ·±åº¦åŠ æ·±ï¼Œå˜å¾—æ›´ä¸ºå¤æ‚ï¼Œä½¿å¾—ç½‘ç»œå®¹æ˜“è¿‡æ‹Ÿåˆã€‚

### æ‰¹é‡å½’ä¸€åŒ–

**æ‰¹é‡å½’ä¸€åŒ–(batch normalization)**åœ¨ [[Ioffe & Szegedy, 2015\]](https://zh-v2.d2l.ai/chapter_references/zreferences.html#ioffe-szegedy-2015)ä¸­è¢«æå‡ºï¼Œç”¨äºè§£å†³ä¸Šè¿°è®­ç»ƒæ·±åº¦ç½‘ç»œæ—¶çš„è¿™äº›é—®é¢˜ï¼Œç„¶è€Œè¿™åªæ˜¯äººä»¬çš„æ„Ÿæ€§ç†è§£ï¼Œå…³äºæ‰¹é‡å½’ä¸€åŒ–å…·ä½“æ˜¯æ€æ ·å¸®åŠ©è®­ç»ƒè¿™ä¸ªé—®é¢˜ç›®å‰ä»å¾…è¿›ä¸€æ­¥ç ”ç©¶ã€‚

æ‰¹é‡å½’ä¸€åŒ–å°è¯•å°†æ¯ä¸ªè®­ç»ƒä¸­çš„mini-batchå°æ‰¹é‡æ•°æ®ï¼ˆå³ä¼šå¯¼è‡´å‚æ•°æ›´æ–°çš„æ•°æ®ï¼‰åœ¨æ¯ä¸€å±‚çš„ç»“æœè¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å…¶æ›´ç¨³å®šï¼Œå½’ä¸€åŒ–æŒ‡çš„æ˜¯å¯¹äºå½“å‰å°æ‰¹é‡ä¸­çš„æ‰€æœ‰æ ·æœ¬ï¼Œæ±‚å‡ºæœŸæœ›å’Œæ–¹å·®ï¼Œç„¶åå°†æ¯ä¸ªæ ·æœ¬å‡å»æœŸæœ›å†é™¤ä»¥æ ‡å‡†å·®ã€‚

#### å½¢å¼åŒ–è¡¨è¾¾-ç†è®º

ä¸‹é¢çš„è¿ç®—å‡ä¸ºå‘é‡è¿ç®—ï¼Œå‘é‡ä¸­çš„æ¯ä¸ªç»´åº¦ä»£è¡¨ä¸€ä¸ªç‰¹å¾ï¼Œå¯¹äºæ¯ä¸ªç‰¹å¾åˆ†åˆ«è¿›è¡Œè®¡ç®—å†æ‹¼æ¥åœ¨ä¸€èµ·å³ä¸ºå‘é‡è¿ç®—ã€‚

è®¾$ \bold x \in \mathcal{B}$ä¸ºæ¥è‡ªä¸€ä¸ªå°æ‰¹é‡$\mathcal{B}$çš„è¾“å…¥ï¼Œæ‰¹é‡è§„èŒƒåŒ–æ ¹æ®ä¸‹å¼è¿›è¡Œè½¬æ¢ $$ \mathrm{BN}(\mathbf{x}) = \boldsymbol{\gamma} \odot \frac{\mathbf{x} - \hat{\boldsymbol{\mu}}*\mathcal{B}}{\hat{\boldsymbol{\sigma}}*\mathcal{B}} + \boldsymbol{\beta}. $$ å¼ä¸­$\hat{\boldsymbol{\mu}}*\mathcal{B}$ä¸ºå°æ‰¹é‡$\mathcal{B}$æ ·æœ¬å‡å€¼ï¼Œ$\hat{\boldsymbol{\sigma}}*\mathcal{B}$ä¸ºæ ·æœ¬æ ‡å‡†å·®ï¼š $$ \begin{split}\begin{aligned} \hat{\boldsymbol{\mu}}*\mathcal{B} &= \frac{1}{|\mathcal{B}|} \sum*{\mathbf{x} \in \mathcal{B}} \mathbf{x},\ \hat{\boldsymbol{\sigma}}*\mathcal{B}^2 &= \frac{1}{|\mathcal{B}|} \sum*{\mathbf{x} \in \mathcal{B}} (\mathbf{x} - \hat{\boldsymbol{\mu}}_{\mathcal{B}})^2 + \epsilon\end{aligned}\end{split} $$ å…¶ä¸­$\epsilon$ç”¨äºé˜²æ­¢åˆ†æ¯ä¸º0ï¼Œç»è¿‡å‡æœŸæœ›ä¸é™¤ä»¥æ ‡å‡†å·®åå¾—åˆ°æœŸæœ›ä¸º1æ–¹å·®ä¸º0çš„å°æ‰¹é‡æ•°æ®ã€‚ç„¶è€Œï¼ŒæœŸæœ›å’Œæ–¹å·®ä¸ºäº†ä½¿å°æ‰¹é‡æœ‰æ›´è‡ªç”±çš„é€‰æ‹©ï¼Œå†å°†å…¶ä¹˜æ‹‰ä¼¸å‚æ•°$\boldsymbol {\gamma}$ï¼ŒåŠ åç§»å‚æ•°$\boldsymbol \beta$ï¼Œè¿™ä¸¤ä¸ªå‚æ•°ä¸$\bold x$åŒæ ·å¤§å°ï¼Œæ˜¯æ¨¡å‹ä¸­çš„å¯å­¦ä¹ å‚æ•°ï¼Œä¸å…¶ä»–å‚æ•°ä¸€åŒæ›´æ–°ã€‚

ç”±äº$\hat{\boldsymbol{\mu}}*\mathcal{B}$å’Œ$\hat{\boldsymbol{\sigma}}*\mathcal{B}$ä¸ºç”±å½“å‰å°æ‰¹é‡è®¡ç®—çš„å€¼ï¼Œå®é™…ä¸Šæ˜¯æ•´ä¸ªåˆ†å¸ƒå¯¹åº”çš„æœŸæœ›ä¸æ ‡å‡†å·®çš„ä¼°è®¡å€¼ï¼Œç”±äºå°æ‰¹é‡çš„éšæœºé€‰æ‹©ï¼Œ$\hat{\boldsymbol{\mu}}*\mathcal{B}$å’Œ$\hat{\boldsymbol{\sigma}}*\mathcal{B}$ä¼šç»™æ¨¡å‹å¸¦æ¥ä¸€å®šçš„ä¸è¾“å…¥æ•°æ®æœ‰å…³çš„å™ªéŸ³ï¼Œè€Œè¿™äº›å™ªéŸ³ä¹Ÿèƒ½å¯¹æ¨¡å‹è¿›è¡Œæ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚ä¸ºä½•è¿™ç§å™ªéŸ³èƒ½åŠ å¿«è®­ç»ƒå¹¶å¸¦æ¥æ­£åˆ™åŒ–è¿˜æœ‰å¾…ç ”ç©¶ï¼Œä¸è¿‡å·²æœ‰ç†è®ºè¯´æ˜äº†ä¸ºä»€ä¹ˆæ‰¹é‡è§„èŒƒåŒ–æœ€é€‚åº”$50âˆ¼100$èŒƒå›´ä¸­çš„ä¸­ç­‰æ‰¹é‡å¤§å°çš„é—®é¢˜ã€‚

è®­ç»ƒæ—¶ä¸èƒ½ä½¿ç”¨æ•´ä¸ªæ•°æ®é›†ï¼Œåªèƒ½ä¸€æ­¥æ­¥çš„è®­ç»ƒå’Œæ›´æ–°ï¼›è€Œé¢„æµ‹æ—¶æ¨¡å‹å·²ç„¶å›ºå®šï¼Œå¯ä»¥æ ¹æ®æ•´ä¸ªæ•°æ®é›†ç²¾ç¡®è®¡ç®—å‡å€¼å’Œæ–¹å·®ã€‚å› æ­¤ï¼Œæ‰¹é‡å½’ä¸€åŒ–å¯¹äºè®­ç»ƒå’Œé¢„æµ‹æ—¶æœ‰ä¸¤ç§ä¸åŒæ¨¡å¼ã€‚

#### æ‰¹é‡å½’ä¸€åŒ–å±‚

æ‰¹é‡å½’ä¸€åŒ–ä¸å†å•ç‹¬çš„è€ƒè™‘å•ä¸ªæ ·æœ¬ï¼Œéœ€è¦å¯¹æ•´ä¸ªmini-batchè¿›è¡Œï¼Œå› æ­¤éœ€è¦è€ƒè™‘å¤šç§æƒ…å†µã€‚

##### å…¨è¿æ¥å±‚

é€šå¸¸ï¼Œæˆ‘ä»¬å°†æ‰¹é‡è§„èŒƒåŒ–å±‚ç½®äºå…¨è¿æ¥å±‚ä¸­çš„ä»¿å°„å˜æ¢å’Œæ¿€æ´»å‡½æ•°ä¹‹é—´ã€‚å¦‚ä¸‹ï¼š $$ \mathbf{h} = \phi(\mathrm{BN}(\mathbf{W}\mathbf{x} + \mathbf{b})) $$

##### å·ç§¯å±‚

åœ¨å·ç§¯å±‚ä¸­ï¼Œæˆ‘ä»¬å°†é€šé“è§†ä½œæ¯ä¸ªä½ç½®çš„ç‰¹å¾ï¼Œå°†æ¯ä¸ªæ ·æœ¬ä¸­çš„æ¯ä¸ªä½ç½®è§†ä½œä¸€ä¸ªæ ·æœ¬è¿›è¡Œè®¡ç®—ã€‚æ¯ä¸ªé€šé“éƒ½æœ‰ç€è‡ªå·±çš„æ‹‰ä¼¸å‚æ•°${\gamma}$å’Œåç§»å‚æ•°$\beta$ï¼Œæ‰€æœ‰é€šé“åŠ åœ¨ä¸€èµ·ç»„æˆäº†æ‹‰ä¼¸å‚æ•°å‘é‡$\boldsymbol {\gamma}$å’Œåç§»å‚æ•°å‘é‡$\boldsymbol \beta$ï¼Œè‹¥æ ·æœ¬æ•°ä¸ºmï¼Œå·ç§¯è¾“å‡ºä¸ºp*qï¼Œè®¡ç®—æ—¶å¯¹m*p*qä¸ªå‘é‡è¿›è¡Œæ‰¹é‡å½’ä¸€åŒ–è¿ç®—ï¼ˆå³è§†ä½œæœ‰m*p*qä¸ªæ ·æœ¬ï¼‰

##### é¢„æµ‹è¿‡ç¨‹ä¸­çš„æ‰¹é‡å½’ä¸€åŒ–

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä¸æ–­åœ°æ›´æ–°æ¨¡å‹ï¼Œæ–¹å·®å’Œå‡å€¼ä¹Ÿå°±åœ¨ä¸æ–­åœ°å˜åŒ–ï¼Œå°±å¿…é¡»è®¡ç®—å½“å‰å°æ‰¹é‡æ•°æ®å¯¹åº”çš„æ–¹å·®å’Œå‡å€¼ï¼Œç„¶è€Œé¢„æµ‹æ—¶æˆ‘ä»¬çš„æ¨¡å‹å·²ç»ç¡®å®šä¸‹æ¥ï¼Œå¯ä»¥ç”¨åœ¨æ•´ä¸ªè®­ç»ƒæ•°æ®é›†ä¸Šå¾—åˆ°çš„å‡å€¼å’Œæ–¹å·®æ¥å¯¹é¢„æµ‹æ—¶çš„ç»“æœè¿›è¡Œå½’ä¸€åŒ–ã€‚

### ä»£ç å®ç°

#### å®ç°ç»†èŠ‚-ä»é›¶å®ç°

- åœ¨å®é™…å®ç°æ—¶ï¼Œä¸€èˆ¬ä½¿ç”¨æŒ‡æ•°åŠ æƒå¹³å‡æ¥æ›´æ–°å°æ‰¹é‡çš„å‡å€¼å’Œæ–¹å·®ï¼ŒæŒ‡æ•°åŠ æƒå¹³å‡å°†æ—§å€¼å’Œå½“å‰è®¡ç®—ç»“æœä¸æ–­è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œæœ€ç»ˆåšåˆ°å¹³æ»‘çš„å‘æ›´æ–°å€¼é æ‹¢ï¼Œå…¬å¼å¦‚ä¸‹ï¼š
- ğ‘†ğ‘¡={ğ‘Œ1,ğ‘¡=1 ğ›½ğ‘†ğ‘¡âˆ’1+(1âˆ’ğ›½)ğ‘Œğ‘¡,ğ‘¡>1
- æ‰¹é‡å½’ä¸€åŒ–çš„å‚æ•°å¯ä»¥é€šè¿‡åŠ¨é‡æ¢¯åº¦ä¸‹é™ï¼ŒRMSPropï¼ŒAdamç­‰å¤šç§ä¼˜åŒ–æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚

```
import torch
from torch import nn
from d2l import torch as d2l

# è¾“å…¥ å¯å­¦ä¹ çš„ä¸¤ä¸ªå‚æ•° å…¨å±€çš„å‡å€¼ å…¨å±€çš„æ–¹å·®ï¼ˆæ•´ä¸ªæ•°æ®é›†çš„è€Œéå°æ‰¹é‡çš„ï¼‰ epsé˜²æ­¢é™¤é›¶ momentumæ›´æ–°å‡å€¼å’Œæ–¹å·®
def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):
    # é€šè¿‡is_grad_enabledæ¥åˆ¤æ–­å½“å‰æ¨¡å¼æ˜¯è®­ç»ƒæ¨¡å¼è¿˜æ˜¯é¢„æµ‹æ¨¡å¼
    if not torch.is_grad_enabled():
        # å¦‚æœæ˜¯åœ¨é¢„æµ‹æ¨¡å¼ä¸‹ï¼Œç›´æ¥ä½¿ç”¨ä¼ å…¥çš„ç§»åŠ¨å¹³å‡æ‰€å¾—çš„å‡å€¼å’Œæ–¹å·®
        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)
    else:
        assert len(X.shape) in (2, 4)
        if len(X.shape) == 2:
            # ä½¿ç”¨å…¨è¿æ¥å±‚çš„æƒ…å†µï¼Œè®¡ç®—ç‰¹å¾ç»´ä¸Šçš„å‡å€¼å’Œæ–¹å·®
            mean = X.mean(dim=0)
            var = ((X - mean) ** 2).mean(dim=0)
        else:
            # ä½¿ç”¨äºŒç»´å·ç§¯å±‚çš„æƒ…å†µï¼Œè®¡ç®—é€šé“ç»´ä¸Šï¼ˆaxis=1ï¼‰çš„å‡å€¼å’Œæ–¹å·®ã€‚
            # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿æŒXçš„å½¢çŠ¶ä»¥ä¾¿åé¢å¯ä»¥åšå¹¿æ’­è¿ç®—
            mean = X.mean(dim=(0, 2, 3), keepdim=True)
            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)
        # è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œç”¨å½“å‰çš„å‡å€¼å’Œæ–¹å·®åšæ ‡å‡†åŒ–
        X_hat = (X - mean) / torch.sqrt(var + eps)
        # æ›´æ–°ç§»åŠ¨å¹³å‡çš„å‡å€¼å’Œæ–¹å·®
        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean
        moving_var = momentum * moving_var + (1.0 - momentum) * var
    Y = gamma * X_hat + beta  # ç¼©æ”¾å’Œç§»ä½
    return Y, moving_mean.data, moving_var.data
```

åˆ›å»ºä¸€ä¸ªæ­£ç¡®çš„BatchNormçš„å›¾å±‚

```
class BatchNorm(nn.Module):
    # num_featuresï¼šå®Œå…¨è¿æ¥å±‚çš„è¾“å‡ºæ•°é‡æˆ–å·ç§¯å±‚çš„è¾“å‡ºé€šé“æ•°ã€‚
    # num_dimsï¼š2è¡¨ç¤ºå®Œå…¨è¿æ¥å±‚ï¼Œ4è¡¨ç¤ºå·ç§¯å±‚
    def __init__(self, num_features, num_dims):
        super().__init__()
        if num_dims == 2:
            shape = (1, num_features)
        else:
            shape = (1, num_features, 1, 1)
        # å‚ä¸æ±‚æ¢¯åº¦å’Œè¿­ä»£çš„æ‹‰ä¼¸å’Œåç§»å‚æ•°ï¼Œåˆ†åˆ«åˆå§‹åŒ–æˆ1å’Œ0
        self.gamma = nn.Parameter(torch.ones(shape))
        self.beta = nn.Parameter(torch.zeros(shape))
        # éæ¨¡å‹å‚æ•°çš„å˜é‡åˆå§‹åŒ–ä¸º0å’Œ1
        self.moving_mean = torch.zeros(shape)
        self.moving_var = torch.ones(shape)
        
    def forward(self, X):
        # å¦‚æœXä¸åœ¨å†…å­˜ä¸Šï¼Œå°†moving_meanå’Œmoving_var
        # å¤åˆ¶åˆ°Xæ‰€åœ¨æ˜¾å­˜ä¸Š
        if self.moving_mean.device != X.device:
            self.moving_mean = self.moving_mean.to(X.device)
            self.moving_var = self.moving_var.to(X.device)
        # ä¿å­˜æ›´æ–°è¿‡çš„moving_meanå’Œmoving_var
        Y, self.moving_mean, self.moving_var = batch_norm(
            X, self.gamma, self.beta, self.moving_mean,
            self.moving_var, eps=1e-5, momentum=0.9)
        return Y
```

åº”ç”¨ï¼šåº”ç”¨åˆ°LeNetæ¨¡å‹ä¸Š

æ‰¹é‡è§„èŒƒåŒ–æ˜¯åœ¨å·ç§¯å±‚æˆ–å…¨è¿æ¥å±‚ä¹‹åã€ç›¸åº”çš„æ¿€æ´»å‡½æ•°ä¹‹å‰åº”ç”¨çš„

```
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), 
    BatchNorm(6, num_dims=4), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    
    nn.Conv2d(6, 16, kernel_size=5), 
    BatchNorm(16, num_dims=4), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2), 
    
    nn.Flatten(),
    nn.Linear(16*4*4, 120), 
    BatchNorm(120, num_dims=2), nn.Sigmoid(),
    
    nn.Linear(120, 84), 
    BatchNorm(84, num_dims=2), nn.Sigmoid(),
    
    nn.Linear(84, 10))
```

#### å®ç°ç»†èŠ‚-è°ƒåŒ…

```
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),
    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),
    nn.Linear(84, 10))
```

### å´æ©è¾¾è€å¸ˆæ·±åº¦å­¦ä¹ è¯¾ç¨‹ä¸­çš„æ‰¹é‡å½’ä¸€åŒ–

å´æ©è¾¾è€å¸ˆæ·±åº¦å­¦ä¹ è¯¾ç¨‹ä¸­çš„æ‰¹é‡å½’ä¸€åŒ–ä¸­çš„éƒ¨åˆ†å†…å®¹ä¸æœ¬è¯¾ç¨‹æœ‰æ‰€å‡ºå…¥ï¼Œè€ƒè™‘åˆ°æ‰¹é‡å½’ä¸€åŒ–è¿™éƒ¨åˆ†å†…å®¹è¿˜æ²¡æœ‰ç²¾ç¡®çš„ç†è®ºè§£é‡Šï¼Œç›®å‰çš„è®¤è¯†ä»…é™äºç›´è§‰ï¼Œæ•…å°†ä¸¤è¯¾ç¨‹ä¸­çš„åŒºåˆ«å³è¡¥å……ç½—åˆ—åœ¨æ­¤ä½œä¸ºå‚è€ƒï¼š

- å…³äºdropoutï¼š
  - æœ¬è¯¾ä¸­æåˆ°æ‰¹é‡å½’ä¸€åŒ–æœ‰æ­£åˆ™åŒ–æ•ˆæœï¼Œæ— éœ€å†è¿›è¡Œdropout
  - å´æ©è¾¾è€å¸ˆè¯¾ç¨‹ä¸­æåˆ°æ‰¹é‡å½’ä¸€åŒ–æ­£åˆ™åŒ–æ•ˆæœè¾ƒå·®ï¼Œä¸èƒ½ä½œä¸ºæ­£åˆ™åŒ–çš„æ‰‹æ®µï¼Œå¿…è¦æ—¶éœ€è¦dropout
- å¯¹äºçº¿æ€§å±‚ï¼ˆåŒ…æ‹¬å…¶ä»–å¸¦æœ‰åç½®é¡¹çš„å±‚ï¼‰åçš„æ‰¹é‡å½’ä¸€åŒ–ï¼Œç”±äºå½’ä¸€åŒ–æ—¶å‡å»äº†å‡å€¼ï¼Œåç½®é¡¹è¢«æ¶ˆæ‰ï¼Œå¯ä»¥çœç•¥å½’ä¸€åŒ–å±‚ä¹‹å‰çš„åç½®é¡¹
- æ ‡å‡†åŒ–çš„è¾“å…¥èƒ½ä½¿æ¢¯åº¦ä¸‹é™åŠ å¿«ï¼Œæ‰¹å½’ä¸€åŒ–èƒ½ä½¿å¾—æ¯å±‚çš„è¾“å…¥éƒ½è¢«å½’ä¸€åŒ–ï¼Œè¿™ä¹Ÿæ˜¯è®­ç»ƒæ›´å¿«çš„åŸå› ä¹‹ä¸€
- æ‰¹é‡å½’ä¸€åŒ–å¯ä»¥ä½¿å¾—ä¸åŒå±‚ä¹‹é—´äº’ç›¸çš„å½±å“å‡å°‘ï¼Œä»è€Œåº”å¯¹æ•°æ®åç§»ï¼Œå¢å¼ºé²æ£’æ€§ã€‚







## æ®‹å·®ç½‘ç»œResNet

éšç€æˆ‘ä»¬è®¾è®¡è¶Šæ¥è¶Šæ·±çš„ç½‘ç»œï¼Œæ·±åˆ»ç†è§£â€œæ–°æ·»åŠ çš„å±‚å¦‚ä½•æå‡ç¥ç»ç½‘ç»œçš„æ€§èƒ½â€å˜å¾—è‡³å…³é‡è¦ã€‚æ›´é‡è¦çš„æ˜¯è®¾è®¡ç½‘ç»œçš„èƒ½åŠ›ï¼Œåœ¨ResNetè¿™ç§ç½‘ç»œä¸­ï¼Œæ·»åŠ å±‚ä¼šä½¿ç½‘ç»œæ›´å…·è¡¨ç°åŠ›

#### å‡½æ•°ç±»

- å‡è®¾æœ‰ä¸€ç±»ç‰¹å®šçš„ç¥ç»ç½‘ç»œæ¶æ„Fï¼Œå®ƒåŒ…æ‹¬å­¦ä¹ é€Ÿç‡å’Œå…¶ä»–è¶…å‚æ•°è®¾ç½®ã€‚ å¯¹äºæ‰€æœ‰*f*âˆˆFï¼Œå­˜åœ¨ä¸€äº›å‚æ•°é›†ï¼ˆä¾‹å¦‚æƒé‡å’Œåç½®ï¼‰ï¼Œè¿™äº›å‚æ•°å¯ä»¥é€šè¿‡åœ¨åˆé€‚çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒè€Œè·å¾—ã€‚ ç°åœ¨å‡è®¾*f*âˆ—æ˜¯æˆ‘ä»¬çœŸæ­£æƒ³è¦æ‰¾åˆ°çš„å‡½æ•°ï¼Œå¦‚æœæ˜¯*f*âˆ—âˆˆFï¼Œé‚£æˆ‘ä»¬å¯ä»¥è½»è€Œæ˜“ä¸¾çš„è®­ç»ƒå¾—åˆ°å®ƒï¼Œä½†é€šå¸¸æˆ‘ä»¬ä¸ä¼šé‚£ä¹ˆå¹¸è¿ã€‚ ç›¸åï¼Œæˆ‘ä»¬å°†å°è¯•æ‰¾åˆ°ä¸€ä¸ªå‡½æ•°*f*âˆ—ï¼Œè¿™æ˜¯æˆ‘ä»¬åœ¨Fä¸­çš„æœ€ä½³é€‰æ‹©ã€‚
- ä¸ºäº†å¾—åˆ°æ›´è¿‘ä¼¼çœŸæ­£*f*âˆ—çš„å‡½æ•°æˆ‘ä»¬éœ€è¦è®¾è®¡ä¸€ä¸ªæ›´å¼ºå¤§çš„æ¶æ„F'ï¼Œä½†æ˜¯å¦‚æœå…ˆå‰çš„æ¡†æ¶Fä¸åŒ…å«äºæ–°æ¡†æ¶Fâ€˜ä¸­å°±å¯èƒ½å¯¼è‡´å¦‚ä¸‹å›¾ä¸­å·¦ä¾§çš„æœ€ä¼˜å‡½æ•°ç¦»å®é™…é¢„æµ‹å‡½æ•°è¯¯å·®åè€Œéšæ¡†æ¶è¾¹å¼ºè€Œå¢å¤§ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬æœŸæœ›çš„ç»“æœï¼Œæ‰€ä»¥æˆ‘ä»¬é€‰æ‹©ä½¿ç”¨ä¸‹å›¾ä¸­å³ä¾§çš„åµŒå¥—å‡½æ•°ç±»ä»¥è§£å†³è¿™ä¸ªé—®é¢˜
- å¼•å…¥æ–¹æ³•ï¼šå¯¹äºæ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¦‚æœæˆ‘ä»¬èƒ½å°†æ–°æ·»åŠ çš„å±‚è®­ç»ƒæˆ*æ’ç­‰æ˜ å°„*ï¼ˆidentity functionï¼‰*f*(**x**)=**x**ï¼Œæ–°æ¨¡å‹å’ŒåŸæ¨¡å‹å°†åŒæ ·æœ‰æ•ˆã€‚ åŒæ—¶ï¼Œç”±äºæ–°æ¨¡å‹å¯èƒ½å¾—å‡ºæ›´ä¼˜çš„è§£æ¥æ‹Ÿåˆè®­ç»ƒæ•°æ®é›†ï¼Œå› æ­¤æ·»åŠ å±‚ä¼¼ä¹æ›´å®¹æ˜“é™ä½è®­ç»ƒè¯¯å·®ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/29/29-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/29/29-01.png)

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/29/29-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/29/29-02.png)

#### æ®‹å·®å—

- ç¥ç»ç½‘ç»œä¸­çš„å…·ä½“å®ç°ï¼šå‡è®¾æˆ‘ä»¬çš„åŸå§‹è¾“å…¥ä¸º*x*ï¼Œè€Œå¸Œæœ›å­¦å‡ºçš„ç†æƒ³æ˜ å°„ä¸º*f*(**x**)ï¼Œå·¦å›¾è™šçº¿æ¡†ä¸­çš„éƒ¨åˆ†éœ€è¦ç›´æ¥æ‹Ÿåˆå‡ºè¯¥æ˜ å°„*f*(**x**)ï¼Œè€Œå³å›¾è™šçº¿æ¡†ä¸­çš„éƒ¨åˆ†åˆ™éœ€è¦æ‹Ÿåˆå‡ºæ®‹å·®æ˜ å°„*f*(**x**)âˆ’**x**ã€‚è€Œå³å›¾æ­£æ˜¯ResNetçš„åŸºç¡€æ¶æ„â€“*æ®‹å·®å—*ï¼ˆresidual blockï¼‰
- æ®‹å·®å—çš„ä»£ç å®ç°ï¼š

```
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


class Residual(nn.Module):
    def __init__(self, input_channels, num_channels,
                 use_1x1conv=False, strides=1):
        super().__init__()
        # ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        self.conv1 = nn.Conv2d(input_channels, num_channels,
                               kernel_size=3, padding=1, stride=strides)
        # ç¬¬äºŒä¸ªå·ç§¯å±‚
        self.conv2 = nn.Conv2d(num_channels, num_channels,
                               kernel_size=3, padding=1)
        # å¦‚æœä½¿ç”¨1 x 1å·ç§¯ä»¥ä½¿å¾—è¾“å…¥å˜æ¢æˆéœ€è¦çš„å½¢çŠ¶
        if use_1x1conv:
            self.conv3 = nn.Conv2d(input_channels, num_channels,
                                   kernel_size=1, stride=strides)
        else:
            self.conv3 = None
        # å¯¹åº”ç¬¬ä¸€ä¸ªå·ç§¯å±‚çš„æ‰¹é‡è§„èŒƒåŒ–å±‚
        self.bn1 = nn.BatchNorm2d(num_channels)
        # å¯¹åº”ç¬¬äºŒä¸ªå·ç§¯å±‚çš„æ‰¹é‡è§„èŒƒåŒ–å±‚
        self.bn2 = nn.BatchNorm2d(num_channels)

    def forward(self, X):
        # ç¬¬ä¸€å±‚ï¼šå·ç§¯ -> è§„èŒƒåŒ– -> reluæ¿€æ´»
        Y = F.relu(self.bn1(self.conv1(X)))
        # ç¬¬äºŒå±‚ï¼šå·ç§¯ -> è§„èŒƒåŒ–
        Y = self.bn2(self.conv2(Y))
        # å¦‚æœè¦è®©è¾“å…¥å˜æ¢æˆéœ€è¦çš„å½¢çŠ¶
        if self.conv3:
            # å¯¹Xä½¿ç”¨1 x 1å·ç§¯ï¼Œä»¥ä½¿è¾“å‡ºæˆä¸ºéœ€è¦çš„å½¢çŠ¶
            X = self.conv3(X)
        # åµŒå¥—æ¨¡å‹çš„å®ç°ï¼Œå³å¯¹ä¸Šä¸€æ¬¡è®­ç»ƒåçš„æ¨¡å‹è¿›è¡ŒåµŒå¥—
        Y += X
        # reluæ¿€æ´»å¹¶è¾“å‡º
        return F.relu(Y)
```



[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/29/29-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/29/29-03.png)

#### ResNetæ¨¡å‹

- ResNetçš„å‰ä¸¤å±‚è·Ÿä¹‹å‰ä»‹ç»çš„GoogLeNetä¸­çš„ä¸€æ ·ï¼š åœ¨è¾“å‡ºé€šé“æ•°ä¸º64ã€æ­¥å¹…ä¸º2çš„7Ã—7å·ç§¯å±‚åï¼Œæ¥æ­¥å¹…ä¸º2çš„3Ã—3çš„æœ€å¤§æ±‡èšå±‚ã€‚ ä¸åŒä¹‹å¤„åœ¨äºResNetæ¯ä¸ªå·ç§¯å±‚åå¢åŠ äº†æ‰¹é‡è§„èŒƒåŒ–å±‚ã€‚

```
b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.BatchNorm2d(64), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```

- GoogLeNetåœ¨åé¢æ¥äº†4ä¸ªç”±Inceptionå—ç»„æˆçš„æ¨¡å—ã€‚ ResNetåˆ™ä½¿ç”¨4ä¸ªç”±æ®‹å·®å—ç»„æˆçš„æ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—ä½¿ç”¨è‹¥å¹²ä¸ªåŒæ ·è¾“å‡ºé€šé“æ•°çš„æ®‹å·®å—ã€‚ ç¬¬ä¸€ä¸ªæ¨¡å—çš„é€šé“æ•°åŒè¾“å…¥é€šé“æ•°ä¸€è‡´ã€‚ ç”±äºä¹‹å‰å·²ç»ä½¿ç”¨äº†æ­¥å¹…ä¸º2çš„æœ€å¤§æ±‡èšå±‚ï¼Œæ‰€ä»¥æ— é¡»å‡å°é«˜å’Œå®½ã€‚ ä¹‹åçš„æ¯ä¸ªæ¨¡å—åœ¨ç¬¬ä¸€ä¸ªæ®‹å·®å—é‡Œå°†ä¸Šä¸€ä¸ªæ¨¡å—çš„é€šé“æ•°ç¿»å€ï¼Œå¹¶å°†é«˜å’Œå®½å‡åŠã€‚

```
def resnet_block(input_channels, num_channels, num_residuals,
                 first_block=False):
    blk = []
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.append(Residual(input_channels, num_channels,
                                use_1x1conv=True, strides=2))
        else:
            blk.append(Residual(num_channels, num_channels))
    return blk
```



- æ¥ç€åœ¨ResNetåŠ å…¥æ‰€æœ‰æ®‹å·®å—ï¼Œè¿™é‡Œæ¯ä¸ªæ¨¡å—ä½¿ç”¨2ä¸ªæ®‹å·®å—ã€‚

```
b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))
b3 = nn.Sequential(*resnet_block(64, 128, 2))
b4 = nn.Sequential(*resnet_block(128, 256, 2))
b5 = nn.Sequential(*resnet_block(256, 512, 2))
```

- æœ€åï¼Œä¸GoogLeNetä¸€æ ·ï¼Œåœ¨ResNetä¸­åŠ å…¥å…¨å±€å¹³å‡æ±‡èšå±‚ï¼Œä»¥åŠå…¨è¿æ¥å±‚è¾“å‡ºã€‚

```
net = nn.Sequential(b1, b2, b3, b4, b5,
                    nn.AdaptiveAvgPool2d((1,1)),
                    nn.Flatten(), nn.Linear(512, 10))
```



- æ¯ä¸ªæ¨¡å—æœ‰4ä¸ªå·ç§¯å±‚ï¼ˆä¸åŒ…æ‹¬æ’ç­‰æ˜ å°„çš„1Ã—1å·ç§¯å±‚ï¼‰ã€‚ åŠ ä¸Šç¬¬ä¸€ä¸ª7Ã—7å·ç§¯å±‚å’Œæœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œå…±æœ‰18å±‚ã€‚ å› æ­¤ï¼Œè¿™ç§æ¨¡å‹é€šå¸¸è¢«ç§°ä¸ºResNet-18ã€‚ é€šè¿‡é…ç½®ä¸åŒçš„é€šé“æ•°å’Œæ¨¡å—é‡Œçš„æ®‹å·®å—æ•°å¯ä»¥å¾—åˆ°ä¸åŒçš„ResNetæ¨¡å‹ï¼Œä¾‹å¦‚æ›´æ·±çš„å«152å±‚çš„ResNet-152ã€‚ è™½ç„¶ResNetçš„ä¸»ä½“æ¶æ„è·ŸGoogLeNetç±»ä¼¼ï¼Œä½†ResNetæ¶æ„æ›´ç®€å•ï¼Œä¿®æ”¹ä¹Ÿæ›´æ–¹ä¾¿ã€‚è¿™äº›å› ç´ éƒ½å¯¼è‡´äº†ResNetè¿…é€Ÿè¢«å¹¿æ³›ä½¿ç”¨ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/29/29-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/29/29-04.png)



#### æ€»ç»“

- å­¦ä¹ åµŒå¥—å‡½æ•°ï¼ˆnested functionï¼‰æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œçš„ç†æƒ³æƒ…å†µã€‚åœ¨æ·±å±‚ç¥ç»ç½‘ç»œä¸­ï¼Œå­¦ä¹ å¦ä¸€å±‚ä½œä¸ºæ’ç­‰æ˜ å°„ï¼ˆidentity functionï¼‰è¾ƒå®¹æ˜“ï¼ˆå°½ç®¡è¿™æ˜¯ä¸€ä¸ªæç«¯æƒ…å†µï¼‰ã€‚
- æ®‹å·®æ˜ å°„å¯ä»¥æ›´å®¹æ˜“åœ°å­¦ä¹ åŒä¸€å‡½æ•°ï¼Œä¾‹å¦‚å°†æƒé‡å±‚ä¸­çš„å‚æ•°è¿‘ä¼¼ä¸ºé›¶ã€‚
- åˆ©ç”¨æ®‹å·®å—ï¼ˆresidual blocksï¼‰å¯ä»¥è®­ç»ƒå‡ºä¸€ä¸ªæœ‰æ•ˆçš„æ·±å±‚ç¥ç»ç½‘ç»œï¼šè¾“å…¥å¯ä»¥é€šè¿‡å±‚é—´çš„æ®‹ä½™è¿æ¥æ›´å¿«åœ°å‘å‰ä¼ æ’­ã€‚
- æ®‹å·®ç½‘ç»œï¼ˆResNetï¼‰å¯¹éšåçš„æ·±å±‚ç¥ç»ç½‘ç»œè®¾è®¡äº§ç”Ÿäº†æ·±è¿œå½±å“ã€‚







# ç¡¬ä»¶å¤„ç†

## CPUå’ŒGPU

### CPUï¼š

#### æå‡CPUåˆ©ç”¨ç‡ä¸€

- åœ¨è®¡ç®—a+bä¹‹å‰ï¼Œéœ€è¦å‡†å¤‡æ•°æ®
- ä¸»å†…å­˜->L3->L2->L1->å¯„å­˜å™¨
  - L1è®¿é—®å»¶æ—¶ï¼š0.5ms
  - L2è®¿é—®å»¶æ—¶ï¼š7nsï¼ˆ14XL1ï¼‰
  - ä¸»å†…å­˜è®¿é—®å»¶æ—¶ï¼š100ns(200XL1)
- æå‡ç©ºé—´å’Œæ—¶é—´çš„å†…å­˜æœ¬åœ°æ€§
  - æ—¶é—´ï¼šé‡ç”¨æ•°æ®ä½¿å®ƒä»¬åœ¨ç¼“å­˜é‡Œ
  - ç©ºé—´ï¼šæŒ‰åºè¯»å†™æ•°æ®æ˜¯çš„å¯ä»¥é¢„è¯»å–

![image-20240719144709106](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240719144709106.png)

##### æ ·ä¾‹åˆ†æ

- å¦‚æœä¸€ä¸ªçŸ©é˜µæ˜¯æŒ‰è¡Œå­˜å‚¨ï¼Œè®¿é—®ä¸€è¡Œæ¯”è®¿é—®ä¸€åˆ—è¦å¿«
  - CPUä¸€æ¬¡è¯»å–64å­—èŠ‚ï¼ˆç¼“å­˜çº¿ï¼‰
  - CPUä¼šâ€œèªæ˜çš„â€æå‰è¯»å–ä¸‹ä¸€ä¸ªï¼ˆç¼“å­˜çº¿ï¼‰

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/31/31-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/31/31-01.png)

#### æå‡CPUåˆ©ç”¨ç‡äºŒï¼š

- é«˜ç«¯CPUæœ‰å‡ åä¸ªæ ¸
  - EC2 P3.16xlarge:2 Intel Xeon CPUs,32ç‰©ç†æ ¸
- å¹¶è¡Œæ¥åˆ©ç”¨æ‰€ç”¨æ ¸
  - è¶…çº¿ç¨‹ä¸ä¸€å®šæå‡æ€§èƒ½ï¼Œå› ä¸ºä»–ä»¬å…±äº«å¯„å­˜å™¨

##### æ ·ä¾‹åˆ†æï¼š

- å·¦è¾¹æ¯”å³è¾¹æ…¢ï¼ˆpythonï¼‰

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/31/31-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/31/31-02.png)

- å·¦è¾¹è°ƒç”¨næ¬¡å‡½æ•°ï¼Œæ¯æ¬¡è°ƒç”¨æœ‰å¼€é”€
- å³è¾¹å¾ˆå®¹æ˜“è¢«å¹¶è¡Œï¼ˆä¾‹å¦‚ä¸‹é¢çš„C++å®ç°ï¼‰

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/31/31-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/31/31-03.png)

### CPU vs GPU:

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/31/31-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/31/31-04.png)

#### æå‡GPUåˆ©ç”¨ç‡

- å¹¶è¡Œ
  - ä½¿ç”¨æ•°åƒä¸ªçº¿ç¨‹
- å†…å­˜æœ¬åœ°æ€§
  - ç¼“å­˜æ›´å°ï¼Œæ¶æ„æ›´ç®€å•
- å°‘ç”¨æ§åˆ¶è¯­å¥
  - æ”¯æŒæœ‰é™
  - åŒæ­¥å¼€é”€å¤§

#### CPU/GPU å¸¦å®½

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/31/31-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/31/31-05.png)

#### æ›´å¤šçš„CPUså’ŒGPUs

- CPU:AMD,ARM
- GPU:AMD,Intel,ARM,Qualcomm...

#### CPU/GPUé«˜æ€§èƒ½è®¡ç®—ç¼–ç¨‹

- CPUï¼šC++æˆ–è€…ä»»ä½•é«˜æ€§èƒ½è¯­è¨€
  - ç¼–è¯‘å™¨æˆç†Ÿ
- GPU
  - Nvidaä¸Šç”¨CUDA
    - ç¼–è¯‘å™¨å’Œé©±åŠ¨æˆç†Ÿ
  - å…¶ä»–ç”¨OpenCL
    - è´¨é‡å–å†³äºç¡¬ä»¶å‚å•†

### æ€»ç»“

- CPU:å¯ä»¥å¤„ç†é€šç”¨è®¡ç®—ã€‚æ€§èƒ½ä¼˜åŒ–è€ƒè™‘æ•°æ®è¯»å†™æ•ˆç‡å’Œå¤šçº¿ç¨‹
- GPUï¼šä½¿ç”¨æ›´å¤šçš„å°æ ¸å’Œæ›´å¥½çš„å†…å­˜å¸¦å®½ï¼Œé€‚åˆèƒ½å¤§è§„æ¨¡å¹¶è¡Œçš„è®¡ç®—ä»»åŠ¡

## æ·±åº¦å­¦ä¹ ç¡¬ä»¶

![image-20240719145059087](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240719145059087.png)

### DSP:æ•°å­—ä¿¡å·å¤„ç†ï¼ˆDigital Signal Processï¼‰

- ä¸ºæ•°å­—ä¿¡å·å¤„ç†ç®—æ³•è®¾è®¡ï¼šç‚¹ç§¯ã€å·ç§¯ã€FFT
- ä½åŠŸè€—ï¼Œé«˜æ€§èƒ½
  - æ¯”ç§»åŠ¨GPUå¿«5å€ï¼ŒåŠŸè€—æ›´ä½
- VLIWï¼švery long instruction word
  - é¢‘ç‡ä½ï¼Œæ ¸å°‘ï¼Œä½†æ˜¯ä¸€æ¡æŒ‡ä»¤å¯ä»¥è¿›è¡Œä¸Šç™¾æ¬¡çš„ç´¯åŠ ï¼Œä¾¿äºé‡å¤
- ç¼ºç‚¹ï¼šç¼–ç¨‹å’Œè°ƒè¯•å›°éš¾ï¼Œç¼–è¯‘å™¨è‰¯è ä¸é½ï¼ˆåšçš„äººå°‘ï¼Œå·¥å…·ä¸æ˜¯å¾ˆå¥½ç”¨ï¼‰

### å¯ç¼–ç¨‹é˜µåˆ—ï¼ˆFPGAï¼‰

- æœ‰å¤§é‡çš„å¯ä»¥ç”¨æ¥ç¼–ç¨‹çš„é€»è¾‘å•å…ƒå’Œå¯é…ç½®é“¾æ¥
- å¯ä»¥é…ç½®æˆè®¡ç®—å¤æ‚å‡½æ•°
  - ç¼–ç¨‹è¯­è¨€ï¼šVHDL Verilog
- é€šå¸¸æ¯”é€šç”¨ç¡¬ä»¶æ›´é«˜æ•ˆï¼Œä½†æ˜¯ä½“ç§¯æ›´å¤§ä¸æ–¹ä¾¿
- ç¼ºç‚¹ï¼šå·¥å…·é“¾è´¨é‡è‰¯è ä¸é½ï¼Œä¸€æ¬¡ç¼–è¯‘éœ€è¦æ•°ä¸ªå°æ—¶ï¼ˆçƒ§ä¸€æ¬¡æ¿å­ï¼Œç‰©ç†ä¸Šçš„æ”¹å˜ï¼‰
- ç”¨é€”ï¼šä¸»è¦ç”¨æ¥æ¨¡æ‹Ÿï¼Œçœ‹çœ‹æ•ˆæœå¥½ä¸å¥½ï¼Œå¦‚æœå¥½å¯ä»¥è¿›ä¸€æ­¥é€ èŠ¯ç‰‡

### AI ASIC

- æ·±åº¦å­¦ä¹ çƒ­é—¨é¢†åŸŸï¼ˆé’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼‰
  
  - å¤§å…¬å¸éƒ½åœ¨é€ è‡ªå·±çš„èŠ¯ç‰‡ï¼ˆIntel Qualcomm Google Amazon Facebookï¼‰
- Google TPU æ˜¯æ ‡sså¿—æ€§èŠ¯ç‰‡ï¼ˆå¬è¯´åœ¨Googleå†…éƒ¨å·²ç»ç››è¡Œ å–ä»£GPUäº†ï¼‰
  - èƒ½å¤Ÿåª²ç¾ Nvidia GPUæ€§èƒ½
  - åœ¨Google å¤§é‡éƒ¨ç½²
  - æ ¸å¿ƒæ˜¯ systolic arrayï¼ˆæ—¶é—´å¿« ä¾¿å®œï¼‰ï¼ˆä¸“é—¨ç”¨æ¥é’ˆå¯¹å¤§çŸ©é˜µè¿ç®—ï¼‰
- systolic array
  - è®¡ç®—å•å…ƒï¼ˆPEï¼‰é˜µåˆ—
  - ç‰¹åˆ«é€‚åˆåšçŸ©é˜µä¹˜æ³•
  - è®¾è®¡å’Œåˆ¶é€ ç›¸å¯¹ç®€å•ï¼ˆæ ¸å°‘ï¼‰

  ![image-20240719150440300](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240719150440300.png)
- çŸ©é˜µä¹˜æ³•ä¾‹å­ï¼š
  - å¯¹äºä¸€èˆ¬çš„çŸ©é˜µä¹˜æ³•ï¼šé€šè¿‡åˆ‡å¼€ã€å¡«å……æ¥åŒ¹é…SAå¤§å°
  - æ‰¹é‡è¾“å…¥æ¥é™ä½å»¶è¿Ÿï¼ˆé¿å…ç©ºç­‰ï¼Œå…ˆå‡ºçš„ç¡¬ä»¶ç©ºé—²ï¼‰
  - é€šå¸¸æœ‰å…¶ä»–ç¡¬ä»¶å•å…ƒæ¥å¤„ç†åˆ«çš„NNæ“ä½œå­ï¼Œä¾‹å¦‚æ¿€æ´»å±‚
- ç¼ºç‚¹ï¼šåªé’ˆå¯¹æ·±åº¦å­¦ä¹ è¿™æ–¹é¢æœ‰ç”¨ï¼Œåˆ«çš„æ–¹é¢æ•ˆæœä¸å¤§ 





## å•æœºå¤šå¡å¹¶è¡Œ



ä¸€å°æœºå™¨å¯ä»¥å®‰è£…å¤šä¸ªGPUï¼ˆä¸€èˆ¬ä¸º1-16ä¸ªï¼‰ï¼Œåœ¨è®­ç»ƒå’Œé¢„æµ‹æ—¶å¯ä»¥å°†ä¸€ä¸ªå°æ‰¹é‡è®¡ç®—åˆ‡åˆ†åˆ°å¤šä¸ªGPUä¸Šæ¥è¾¾åˆ°åŠ é€Ÿç›®çš„ï¼Œå¸¸ç”¨çš„åˆ‡åˆ†æ–¹æ¡ˆæœ‰æ•°æ®å¹¶è¡Œï¼Œæ¨¡å‹å¹¶è¡Œï¼Œé€šé“å¹¶è¡Œã€‚

### æ•°æ®å¹¶è¡Œ

å°†å°æ‰¹é‡çš„æ•°æ®åˆ†ä¸ºnå—ï¼Œæ¯ä¸ªGPUæ‹¿åˆ°å®Œæ•´çš„å‚æ•°ï¼Œå¯¹è¿™ä¸€å—çš„æ•°æ®è¿›è¡Œå‰å‘ä¼ æ’­ä¸åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ã€‚

æ•°æ®å¹¶è¡Œé€šå¸¸æ€§èƒ½æ¯”æ¨¡å‹å¹¶è¡Œæ›´å¥½ï¼Œå› ä¸ºå¯¹æ•°æ®è¿›è¡Œåˆ’åˆ†ä½¿å¾—å„ä¸ªGPUçš„è®¡ç®—å†…å®¹æ›´åŠ å‡åŒ€ã€‚

#### æ•°æ®å¹¶è¡Œçš„å¤§è‡´æµç¨‹



[![DataParallel](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/33/DataParallel.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/33/DataParallel.png)

ä¸»è¦åˆ†ä¸ºäº”éƒ¨

- 1ï¼šæ¯ä¸ªGPUè¯»å–ä¸€ä¸ªæ•°æ®å—ï¼ˆç°è‰²éƒ¨åˆ†ï¼‰
- 2ï¼šæ¯ä¸ªGPUè¯»å–å½“å‰æ¨¡å‹çš„å‚æ•°ï¼ˆæ©™è‰²éƒ¨åˆ†ï¼‰
- 3ï¼šæ¯ä¸ªGPUè®¡ç®—è‡ªå·±æ‹¿åˆ°æ•°æ®å—çš„æ¢¯åº¦ï¼ˆç»¿è‰²éƒ¨åˆ†ï¼‰
- 4ï¼šGPUå°†è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦ä¼ ç»™å†…å­˜ï¼ˆCPUï¼‰ï¼ˆç»¿è‰²ç®­å¤´ï¼‰
- 5ï¼šåˆ©ç”¨æ¢¯åº¦å¯¹æ¨¡å‹å‚æ•°è¿›è¡Œæ›´æ–°ï¼ˆæ©™è‰²ç®­å¤´ï¼‰

æ•°æ®å¹¶è¡Œå¹¶è¡Œæ€§è¾ƒå¥½ï¼Œä¸»è¦å› ä¸ºå½“æ¯ä¸ªGPUæ‹¿åˆ°çš„æ•°æ®é‡ç›¸åŒæ—¶è®¡ç®—é‡ä¹Ÿç›¸ä¼¼ï¼Œå„ä¸ªGPUçš„è¿ç®—æ—¶é—´ç›¸è¿‘ï¼Œæ€§èƒ½è¾ƒå¥½

### æ¨¡å‹å¹¶è¡Œ

å°†æ•´ä¸ªæ¨¡å‹åˆ†ä¸ºnä¸ªéƒ¨åˆ†ï¼Œæ¯ä¸ªGPUæ‹¿åˆ°è¿™ä¸ªéƒ¨åˆ†çš„å‚æ•°å’Œè´Ÿè´£ä¸Šä¸€ä¸ªéƒ¨åˆ†çš„GPUçš„è¾“å‡ºä½œä¸ºè¾“å…¥æ¥è¿›è¡Œè®¡ç®—ï¼Œsåå‘ä¼ æ’­åŒç†ã€‚

æ¨¡å‹å¹¶è¡Œé€šå¸¸ç”¨äºæ¨¡å‹ååˆ†å·¨å¤§ï¼Œå‚æ•°ä¼—å¤šï¼Œå³ä½¿åœ¨æ¯ä¸ªmini-batchåªæœ‰ä¸€ä¸ªæ ·æœ¬çš„æƒ…å†µä¸‹å•ä¸ªGPUçš„æ˜¾å­˜ä»ç„¶ä¸å¤Ÿçš„æƒ…å†µï¼Œä½†å¹¶è¡Œæ€§è¾ƒå·®ï¼Œå¯èƒ½æœ‰æ—¶ä¼šæœ‰GPUå¤„äºç­‰å¾…çŠ¶æ€ã€‚

### é€šé“å¹¶è¡Œ

é€šé“å¹¶è¡Œæ˜¯æ•°æ®å¹¶è¡Œå’Œæ¨¡å‹å¹¶è¡ŒåŒæ—¶è¿›è¡Œ

### æ€»ç»“

- å½“ä¸€ä¸ªæ¨¡å‹èƒ½ç”¨å•å¡è®¡ç®—æ—¶ï¼Œé€šå¸¸ä½¿ç”¨æ•°æ®å¹¶è¡Œæ‰©å±•åˆ°å¤šå¡
- æ¨¡å‹å¹¶è¡Œåˆ™ç”¨åœ¨è¶…å¤§æ¨¡å‹ä¸Š



## åˆ†å¸ƒå¼è®­ç»ƒ

### åˆ†å¸ƒå¼è®¡ç®—

- æœ¬è´¨ä¸Šæ¥è¯´å’Œä¹‹å‰è®²çš„å•æœºå¤šå¡å¹¶è¡Œæ²¡æœ‰åŒºåˆ«ã€‚äºŒè€…ä¹‹é—´çš„åŒºåˆ«æ˜¯åˆ†å¸ƒå¼è®¡ç®—æ˜¯é€šè¿‡ç½‘ç»œæŠŠæ•°æ®ä»ä¸€å°æœºå™¨æ¬åˆ°å¦ä¸€å°æœºå™¨
- æ ·æœ¬åˆ†å¸ƒåœ¨ä¸åŒç£ç›˜ä¸Šï¼Œå…è®¸æ‰€æœ‰æœºå™¨è¿›è¡Œè¯»å–s
- æœºå™¨/worker/æ ˆ

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/35/35-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/35/35-01.png)

### GPUæœºå™¨æ¶æ„

![image-20240719175039729](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240719175039729.png)

- æ€»çš„æ¥è¯´ï¼Œgpuåˆ°gpuçš„é€šè®¯æ˜¯å¾ˆå¿«çš„ï¼Œgpuåˆ°cpuæ…¢ä¸€ç‚¹ã€‚æœºå™¨åˆ°æœºå™¨æ›´æ…¢ã€‚å› è€Œæ€»ä½“æ€§èƒ½çš„å…³é”®å°±æ˜¯å°½é‡åœ¨æœ¬åœ°åšé€šè®¯è€Œå°‘åœ¨æœºå™¨ä¹‹é—´åšé€šè®¯S

##### æ ·ä¾‹ï¼šè®¡ç®—ä¸€ä¸ªå°æ‰¹é‡ï¼ˆå¦‚ä½•å‡å°‘è·¨æœºå™¨çš„å­¦ä¹ ï¼‰

- æ ·æœ¬åˆ†å‰²ï¼šæ¯ä¸ªworkerä»å‚æ•°æœåŠ¡å™¨é‚£é‡Œè·å–æ¨¡å‹å‚æ•°ï¼šé¦–å…ˆæŠŠæ ·æœ¬å¤åˆ¶åˆ°æœºå™¨çš„å†…å­˜ï¼Œç„¶åæŠŠæ ·æœ¬åˆ†åˆ°æ¯ä¸ªgpuä¸Š
- å¤åˆ¶å‚æ•°åˆ°æ¯ä¸ªgpuä¸Šï¼šåŒæ ·ï¼Œå…ˆæŠŠæ¯ä¸€æ¬¡çš„å‚æ•°æ”¾åˆ°å†…å­˜é‡Œï¼Œç„¶åå†å¤åˆ¶åˆ°æ¯ä¸ªgpuä¸Š
- æ¯ä¸ªgpuè®¡ç®—æ¢¯åº¦
- å†ä¸»å†…å­˜ä¸ŠæŠŠæ‰€æœ‰gpuä¸Šçš„æ¢¯åº¦åŠ èµ·æ¥ï¼ˆä¸»å†…å­˜æ•´åˆï¼‰
- æ¢¯åº¦ä»ä¸»å†…å­˜ä¼ å›æœåŠ¡å™¨
- æ¯ä¸ªæœåŠ¡å™¨å¯¹æ¢¯åº¦æ±‚å’Œï¼Œå¹¶æ›´æ–°å‚æ•°ï¼Œä¹‹åè¿›è¡Œä¸‹ä¸€è½®çš„è®¡ç®—

### å…³äºæ€§èƒ½

##### å¯¹äº**åŒæ­¥SGD**ï¼š

- è¿™é‡Œæ¯ä¸ªworkeréƒ½æ˜¯åŒæ­¥è®¡ç®—ä¸€ä¸ªæ‰¹é‡ï¼Œç§°ä¸ºåŒæ­¥SGD
- å‡è®¾æœ‰nä¸ªggpuï¼Œæ¯ä¸ªgpuæ¯æ¬¡å¤„ç†bä¸ªæ ·æœ¬ï¼Œé‚£ä¹ˆåŒæ­¥SGDç­‰ä»·äºå†å•gpuè¿è¡Œæ‰¹é‡å¤§å°ä¸ºnbçš„SGD
- åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œnä¸ªgpuå¯ä»¥å¾—åˆ°ç›¸å¯¹å•gpuçš„nå€åŠ é€Ÿï¼ˆåŒæ­¥ä¸”å¯ä»¥æ”¾å…¥nå€batchï¼‰

##### **æ€§èƒ½**ï¼š

- t1 = åœ¨å•gpuä¸Šè®¡ç®—bä¸ªæ ·æœ¬æ¢¯åº¦æ—¶é—´
- å‡è®¾æœ‰mä¸ªå‚æ•°ï¼Œä¸€ä¸ªworkeræ¯æ¬¡å‘é€å’Œæ¥å—mä¸ªå‚æ•°ã€æ¢¯åº¦
  - t2 = å‘é€å’Œæ¥å—æ‰€ç”¨æ—¶é—´
- æ¯ä¸ªæ‰¹é‡çš„è®¡ç®—æ—¶é—´ä¸ºmaxï¼ˆt1ï¼Œt2ï¼‰ ->å‘é€æ¥æ”¶ä¸è®¡ç®—ä¸¤ä¸ªæ˜¯å¹¶è¡Œçš„
  - é€‰å–è¶³å¤Ÿå¤§çš„bä½¿t1>t2ï¼šé€šä¿¡æ—¶é—´å¤§åˆ™å­˜åœ¨æ€§èƒ½é—®é¢˜ï¼ˆGPUåœ¨ç­‰å¾…æ•°æ®ï¼‰
  - å¢åŠ bæˆ–nå¯¼è‡´æ›´å¤§çš„æ‰¹é‡ å¤§å°ï¼Œå½“å€¼éœ€è¦æ›´å¤šè®¡ç®—æ¥å¾—åˆ°ç»™å®šçš„æ¨¡å‹ç²¾åº¦

##### æ€§èƒ½çš„æƒè¡¡

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/35/35-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/35/35-02.png)

å¯¹äºç³»ç»Ÿæ€§èƒ½è€Œè¨€ï¼ŒGPUçš„æ‰¹é‡å¤§å°å˜å¤§ï¼Œå¯ä»¥æ›´å¥½çš„åˆ©ç”¨GPUçš„æ€§èƒ½ï¼›

å¯¹äºè®­ç»ƒæœ‰æ•ˆæ€§è€Œè¨€ï¼ŒGPUæ‰¹é‡å˜å¤§éœ€è¦æ›´å¤šepochæ¥è®­ç»ƒç²¾åº¦ï¼Œæ¥åº”å¯¹æ”¶æ•›é€Ÿåº¦å˜æ…¢ã€‚

### å®è·µæ—¶çš„å»ºè®®

- ä½¿ç”¨ä¸€ä¸ªå¤§æ•°æ®é›†
- éœ€è¦å¥½çš„gpu-gpuå’Œæœºå™¨-æœºå™¨å¸¦å®½
- é«˜æ•ˆçš„æ•°æ®è¯»å–å’Œé¢„å¤„ç†
- æ¨¡å‹éœ€è¦æœ‰å¥½çš„è®¡ç®—å’Œé€šè®¯æ¯”ï¼Œflop/model sizeè¶Šå¤§è¶Šå¥½
  - Inception>ResNet>AlexNet
- ä½¿ç”¨è¶³å¤Ÿå¤§çš„æ‰¹é‡å¤§å°æ¥å¾—åˆ°æ›´å¥½çš„ç³»ç»Ÿæ€§èƒ½
- ä½¿ç”¨é«˜æ•ˆçš„ä¼˜åŒ–ç®—æ³•å¯¹åº”å¤§æ‰¹é‡å¤§å°

### æ€»ç»“

- åˆ†å¸ƒå¼åŒæ­¥æ•°æ®å¹¶è¡Œæ˜¯å¤šgpuæ•°æ®å¹¶è¡Œåœ¨å¤šæœºå™¨ä¸Šçš„æ‹“å±•
- ç½‘ç»œé€šè®¯é€šå¸¸æ˜¯ç“¶é¢ˆ
- éœ€è¦æ³¨æ„ä½¿ç”¨ç‰¹åˆ«å¤§çš„æ‰¹é‡å¤§å°æ—¶çš„æ”¶æ•›æ•ˆç‡
- æ›´å¤æ‚çš„åˆ†å¸ƒå¼æœ‰å¼‚æ­¥ã€æ¨¡å‹å¹¶è¡Œï¼ˆè¿™é‡Œæ²¡æœ‰ä»‹ç»ï¼‰



# å›¾åƒå¤„ç†æŠ€æœ¯

## æ•°æ®å¢å¹¿

### ä½¿ç”¨å¢å¼ºæ•°æ®è®­ç»ƒ

å¸¸è§çš„é—®é¢˜ï¼šé‡‡é›†æ•°æ®å¾—åˆ°çš„è®­ç»ƒåœºæ™¯ä¸å®é™…éƒ¨ç½²åœºæ™¯ã€‚-->å¢å¼ºæ¨¡å‹æ³›åŒ–æ€§

æ•°æ®å¢å¼ºæ˜¯æŒ‡åœ¨ä¸€ä¸ªå·²æœ‰æ•°æ®é›†ä¸Šæ“ä½œä½¿å…¶æœ‰æ›´å¤šçš„å¤šæ ·æ€§ã€‚

â€‹	å¯¹è¯­éŸ³æ¥è¯´å¯ä»¥åŠ å…¥ä¸åŒçš„èƒŒæ™¯å™ªéŸ³

â€‹	å¯¹å›¾ç‰‡è€Œè¨€å¯ä»¥æ”¹å˜å…¶é¢œè‰²ï¼Œå½¢çŠ¶ç­‰ã€‚

æ•°æ®å¢å¹¿å¾€å¾€æ˜¯åœ¨çº¿ç”Ÿæˆï¼Œå¹¶ä¸”æ˜¯éšæœºæ•°æ®ç”Ÿæˆã€‚é€šå¸¸åªåœ¨è®­ç»ƒæ—¶åšæ•°æ®å¢å¼ºè€Œæµ‹è¯•æ—¶ä¸ç”¨ã€‚å¯ä»¥å°†æ•°æ®å¢å¼ºç†è§£ä¸ºä¸€ä¸ªæ­£åˆ™é¡¹ã€‚

### å¢å¼ºæ‰‹æ®µ

#### ç¿»è½¬

ä¸€äº›ä¾‹å­ï¼šå·¦å³ç¿»è½¬ï¼Œä¸Šä¸‹ç¿»è½¬ï¼ˆæ ¹æ®æ¨¡å‹ç‰¹æ€§ï¼‰

è¦æ³¨æ„ä¸æ˜¯æ‰€æœ‰å¢å¼ºç­–ç•¥éƒ½æ€»æ˜¯å¯è¡Œï¼Œå¦‚å»ºç­‘å›¾ç‰‡ä¸Šä¸‹ç¿»è½¬å°±ä¸å¤ªåˆé€‚ï¼Œè€Œä¹‹å‰çš„æ ‘å¶åˆ†ç±»ç«èµ›ä¸­çš„æ ‘å¶å›¾ç‰‡å°±æ²¡å…³ç³»ã€‚

[![36-01](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/36/36-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/36/36-01.png)

#### åˆ‡å‰²

ä»å›¾ç‰‡ä¸­åˆ‡å‰²ä¸€å—ï¼Œå˜å½¢åˆ°å›ºå®šå½¢çŠ¶ã€‚

**å…·ä½“éšæœºåšæ³•ï¼š**

éšæœºå–ä¸€ä¸ªé«˜å®½æ¯”

éšæœºå–å›¾ç‰‡å¤§å°ï¼ˆåˆ‡ä¸‹éƒ¨åˆ†å åŸå›¾çš„ç™¾åˆ†æ•°ï¼‰

éšæœºå–ä½ç½®

[![36-02](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/36/36-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/36/36-02.png)

#### é¢œè‰²

æ”¹å˜è‰²è°ƒï¼Œé¥±å’Œåº¦ï¼Œæ˜äº®åº¦ã€‚

[![36-03](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/36/36-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/36/36-03.png)

#### å…¶ä»–

é«˜æ–¯æ¨¡ç³Šï¼Œéƒ¨åˆ†åƒç´ å˜é»‘ï¼Œå›¾ç‰‡å˜å½¢ï¼Œé”åŒ–ç­‰ç­‰ã€‚

ç†è®ºä¸Šè®²Photoshopèƒ½åšåˆ°çš„éƒ½å¯ä»¥ç”¨ä½œå›¾ç‰‡æ•°æ®å¢å¼ºã€‚

å¦‚æœæµ‹è¯•é›†ä¸­æœ‰ç±»ä¼¼çš„æ•ˆæœé‚£ä¹ˆç›¸åº”çš„æ•°æ®å¢å¹¿æ‰‹æ®µä¼šæ›´æœ‰æ•ˆã€‚

[![36-04](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/36/36-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/36/36-04.png)

### æ€»ç»“

- æ•°æ®å¢å¹¿é€šè¿‡å˜å½¢æ•°æ®æ¥è·å–å¤šæ ·æ€§ä»è€Œä½¿å¾—æ¨¡å‹æ³›åŒ–æ€§èƒ½æ›´å¥½
- å¸¸è§å›¾ç‰‡å¢å¹¿åŒ…æ‹¬ç¿»è½¬ï¼Œåˆ‡å‰²ï¼Œå˜è‰²

### ä»£ç å®ç°

transformså†…éƒ¨åˆ†å¤šç§ç¿»è½¬å‡½æ•°

```
#å‚ç›´æ°´å¹³ç¿»è½¬
torchvision.transforms.RandomHorizontalFlip()
torchvision.transforms.RandomVerticalFlip()

# éšå³è£å‰ªï¼šæœ€ç»ˆè£å‰ªå¤§å°ï¼Œéšæœºä¿ç•™ç™¾åˆ†æ¯”ï¼Œéšæœºé«˜å®½æ¯”
torchvision.transforms.RandomResizedCrop((200,200),scale=(0.1,1),ratio=(0.5,2))

# brightnessï¼ˆäº®åº¦ï¼‰,contrastï¼ˆå¯¹æ¯”åº¦ï¼‰,saturationï¼ˆé¥±å’Œåº¦ï¼‰,hueï¼ˆè‰²è°ƒï¼‰
# éšå³æ”¹å˜äº®åº¦ï¼šç¬¬ä¸€ä¸ªæ•°å€¼éšå³æ”¹å˜ä¸Šä¸‹äº®åº¦50%
torchvision.transforms.ColorJitter(brightness=0.5,contrast=0,saturation=0,hue=0)
# éšå³æ”¹å˜è‰²è°ƒï¼šç¬¬å››ä¸ªæ•°å€¼éšå³æ”¹å˜ä¸Šä¸‹äº®åº¦50%
torchvision.transforms.ColorJitter(brightness=0,contrast=0,saturation=0,hue=0.5)

# ç»„åˆå¤šç§å›¾åƒå¢å¹¿
torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),color_aug,shape_aug])
```

å…·ä½“ä½¿ç”¨æ–¹å¼

```
train_aug = torchvision.transforms.Compose([
	torchvision.transforms.RandomHorizontalFlip(),
	torchvision.transforms.ToTensor()])
	
test_aug = torchvision.transforms.Compose([
	torchvision.transforms.ToTensor()])
```

å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºè¯»å–å›¾åƒå’Œåº”ç”¨å›¾åƒå¢å¹¿

```
def load_cifar10(is_train,augs,batch_size):
	# æ¯æ¬¡è¯»å–è¿›å»è¿›è¡Œä¸€æ¬¡æ³›åŒ–
	dataset = torchvision.datasets.CIFAR10(
		root="../data".train=is_train,
		transform=augs,download=True)
	dataloader = torch.utils.data.DataLoader(
		dataset,batch_size=batch_size,shuffle=is_train,
		num_worker=4)
	return dataloader
```

### QAçŸ¥è¯†ç‚¹

1.ç†è®ºä¸Šï¼Œåœ¨åŸå§‹æ•°æ®è¶³å¤Ÿå¤šçš„æ—¶å€™å¯ä»¥ä¸ä½¿ç”¨å¢å¹¿ï¼Œä½†æ˜¯ç†æƒ³ä¸ŠåŸå§‹æ•°æ®æ— æ³•æŠµè¾¾çœŸå®åœºæ™¯çš„å¤šæ ·æ€§ã€‚





## å¾®è°ƒ

### èƒŒæ™¯

ç”±äºè®­ç»ƒæ ·æœ¬æ•°é‡æœ‰é™ï¼Œè®­ç»ƒæ¨¡å‹çš„å‡†ç¡®æ€§å¯èƒ½æ— æ³•æ»¡è¶³å®é™…è¦æ±‚ï¼Œè§£å†³æ–¹æ³•ï¼š

- æ”¶é›†æ›´å¤šçš„æ•°æ®ï¼Œä¹Ÿæ„å‘³ç€éœ€è¦å¤§é‡çš„æ—¶é—´å’Œé‡‘é’±ã€‚ 
- ä½¿ç”¨è¿ç§»å­¦ä¹ å°†ä»*æºæ•°æ®é›†*å­¦åˆ°çš„çŸ¥è¯†è¿ç§»åˆ°*ç›®æ ‡æ•°æ®é›†*ã€‚ ä¾‹å¦‚ï¼Œå°½ç®¡ImageNetæ•°æ®é›†ä¸­çš„å¤§å¤šæ•°å›¾åƒä¸æ¤…å­æ— å…³ï¼Œä½†åœ¨æ­¤æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹å¯èƒ½ä¼šæå–æ›´é€šç”¨çš„å›¾åƒç‰¹å¾ï¼Œè¿™æœ‰åŠ©äºè¯†åˆ«è¾¹ç¼˜ã€çº¹ç†ã€å½¢çŠ¶å’Œå¯¹è±¡ç»„åˆã€‚ è¿™äº›ç±»ä¼¼çš„ç‰¹å¾ä¹Ÿå¯èƒ½æœ‰æ•ˆåœ°è¯†åˆ«æ¤…å­ã€‚

### æ­¥éª¤

1. ***æºæ¨¡å‹***ï¼ˆpre-trainï¼‰ï¼šåœ¨æºæ•°æ®é›†ï¼ˆä¾‹å¦‚ImageNetæ•°æ®é›†ï¼‰ä¸Šé¢„è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ã€‚

2. åˆ›å»ºä¸€ä¸ªæ–°çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå³***ç›®æ ‡æ¨¡å‹***ï¼š

   â€‹		å¤åˆ¶æºæ¨¡å‹ä¸Šçš„æ‰€æœ‰æ¨¡å‹è®¾è®¡åŠå…¶å‚æ•°ï¼ˆè¾“å‡ºå±‚é™¤å¤–ï¼‰

   â€‹		æˆ‘ä»¬å‡å®šè¿™äº›æ¨¡å‹å‚æ•°åŒ…å«ä»æºæ•°æ®é›†ä¸­å­¦åˆ°çš„çŸ¥è¯†ï¼Œè¿™äº›çŸ¥è¯†ä¹Ÿå°†é€‚ç”¨äºç›®æ ‡æ•°æ®é›†ã€‚æˆ‘ä»¬è¿˜å‡è®¾æºæ¨¡å‹çš„è¾“å‡ºå±‚ä¸æºæ•°æ®é›†çš„æ ‡ç­¾å¯†åˆ‡ç›¸å…³ï¼›å› æ­¤ä¸åœ¨ç›®æ ‡æ¨¡å‹ä¸­ä½¿ç”¨è¯¥å±‚ã€‚

3. å‘ç›®æ ‡æ¨¡å‹æ·»åŠ è¾“å‡ºå±‚ï¼Œå…¶è¾“å‡ºæ•°æ˜¯ç›®æ ‡æ•°æ®é›†ä¸­çš„ç±»åˆ«æ•°ã€‚ç„¶åéšæœºåˆå§‹åŒ–è¯¥å±‚çš„æ¨¡å‹å‚æ•°ã€‚

4. åœ¨ç›®æ ‡æ•°æ®é›†ï¼ˆå¦‚æ¤…å­æ•°æ®é›†ï¼‰ä¸Šè®­ç»ƒç›®æ ‡æ¨¡å‹ã€‚è¾“å‡ºå±‚å°†ä»å¤´å¼€å§‹è¿›è¡Œè®­ç»ƒï¼Œè€Œæ‰€æœ‰å…¶ä»–å±‚çš„å‚æ•°å°†æ ¹æ®æºæ¨¡å‹çš„å‚æ•°è¿›è¡Œå¾®è°ƒã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/37/37-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/37/37-01.png)

### æŠ€å·§

##### å¯¹äºè®­ç»ƒ

**ä½¿ç”¨æ›´å¼ºçš„æ­£åˆ™åŒ–ï¼Œé€‰æ‹©æ›´å°çš„å­¦ä¹ ç‡ï¼Œé€‰æ‹©æ›´å°çš„è¿­ä»£ã€‚**

å¯¹äºä¸åŒçš„ä»»åŠ¡å¾€å¾€åªéœ€è¦æ”¹å˜æœ€åè¾“å‡ºå±‚ï¼Œè¿™ä¸€å±‚éšæœºåˆå§‹åŒ–å³å¯ã€‚

##### å›ºå®šä¸€äº›å±‚

å‰é¢çš„å±‚æ›´åŠ é€šç”¨/åº•å±‚ï¼Œå›ºå®šåº•éƒ¨ä¸€äº›å±‚çš„å‚æ•°ï¼Œä¸å‚ä¸æ›´æ–°ï¼›

åé¢çš„å±‚ä¸æˆ‘ä»¬çš„labelæ›´åŠ ç›¸å…³ï¼Œæ‰€ä»¥å¯¹è¿™éƒ¨åˆ†è¿›è¡Œä¿®æ”¹ã€‚

### æ€»ç»“

- è¿ç§»å­¦ä¹ ï¼šå°†ä»æºæ•°æ®é›†ä¸­å­¦åˆ°çš„çŸ¥è¯†â€œè¿ç§»â€åˆ°ç›®æ ‡æ•°æ®é›†ï¼Œå¾®è°ƒæ˜¯è¿ç§»å­¦ä¹ çš„å¸¸è§æŠ€å·§ã€‚
- é™¤è¾“å‡ºå±‚å¤–ï¼Œç›®æ ‡æ¨¡å‹ä»æºæ¨¡å‹ä¸­å¤åˆ¶æ‰€æœ‰æ¨¡å‹è®¾è®¡åŠå…¶å‚æ•°ï¼Œå¹¶æ ¹æ®ç›®æ ‡æ•°æ®é›†å¯¹è¿™äº›å‚æ•°è¿›è¡Œå¾®è°ƒã€‚ä½†æ˜¯ï¼Œç›®æ ‡æ¨¡å‹çš„è¾“å‡ºå±‚éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒã€‚
- é€šå¸¸ï¼Œå¾®è°ƒå‚æ•°ä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œè€Œä»å¤´å¼€å§‹è®­ç»ƒè¾“å‡ºå±‚å¯ä»¥ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡ã€‚

### ä»£ç 

å®šä¹‰å’Œåˆå§‹åŒ–æ¨¡å‹

```
# pretrained=Trueï¼šæ‹¿èµ°æ¨¡å‹åŠæ¨¡å‹è®­ç»ƒå¥½çš„å‚æ•°
pretrained_net = torchvision.models.resnet18(pretrained=True)

# from pretrained_net.fc we can get in_features/out_features
finetune_net = torchvision.models.resnet18(pretrained=True)
finetune_net.fc = nn.Linear(pretrained_net.fc.in_features,2)

# åªå¯¹æœ€åä¸€å±‚åšéšæœºåˆå§‹åŒ–
nn.init.xavier_uniform_(finetune_net.fc.weight)
```

å¾®è°ƒæ¨¡å‹

```
# æå–ä¸åŒ…æ‹¬å…¨è¿æ¥å±‚æƒé‡å’Œåç½®çš„å‚æ•°
param_1x = [
 	param for name,param in net.named_parameters()
 	if name not in ["fc.weight","fc.bias"]]
 	
# æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦åº”ç”¨ä¸åŒå­¦ä¹ ç‡çš„å‚æ•°
	if param_group:
	
		params=[
		{'params': param_1x, 'lr': learning_rate * 10},
    	{'params': [param for name, param in net.named_parameters() if name in ["fc.weight", "fc.bias"]], 'lr': learning_rate}
    	]
 		trainer = torch.potim.SGD(
 		params,lr=learning_rate,weight_decay=0.001)
 		
 	else:
		trainer = torch.potim.SGD(net.parameters(),
		lr=learning_rate,weight_decay=0.001)
 		
```





## ç‰©ä½“æ£€æµ‹å’Œæ•°æ®é›†

#### ç‰©ä½“æ£€æµ‹

###### å›¾ç‰‡åˆ†ç±»å’Œç›®æ ‡æ£€æµ‹åœ¨ä»»åŠ¡ä¸Šçš„åŒºåˆ«

å›¾ç‰‡åˆ†ç±»å·²çŸ¥æœ‰ä¸€ä¸ªç¡®å®šç›®æ ‡ï¼Œä»»åŠ¡æ˜¯**è¯†åˆ«è¯¥ç›®æ ‡å±äºä½•ç§åˆ†ç±»**ï¼›

ç›®æ ‡æ£€æµ‹ä¸ä»…éœ€è¦æ£€æµ‹å‡ºå›¾ç‰‡ä¸­æ‰€æœ‰æ„Ÿå…´è¶£çš„ç›®æ ‡ç±»åˆ«ï¼Œå¹¶ç¡®å®šå…¶**ä½ç½®**ï¼Œæ‰€ä»¥ç›®æ ‡æ£€æµ‹è¦æ¯”å›¾ç‰‡åˆ†ç±»æ›´å¤æ‚åº”ç”¨åœºæ™¯æ›´å¹¿ã€‚

###### å›¾ç‰‡åˆ†ç±»å’Œç›®æ ‡æ£€æµ‹åœ¨æ•°æ®é›†ä¸Šçš„åŒºåˆ«

ç”±äºç›®æ ‡æ£€æµ‹ä¸­æ¯ä¸€å¼ å›¾ç‰‡å¯èƒ½å­˜åœ¨å¤šä¸ªç›®æ ‡ï¼Œæ¯ä¸ªç›®æ ‡æˆ‘ä»¬ä¸ä»…éœ€è¦åˆ†ç±»ï¼Œè¿˜éœ€è¦ç¡®å®šè¾¹ç¼˜æ¡†ä»¥ç»™å‡ºç›®æ ‡ä½ç½®ä¿¡æ¯ï¼Œå› æ­¤**ç›®æ ‡æ£€æµ‹æ•°æ®é›†çš„æ ‡æ³¨æˆæœ¬è¦æ˜¾è‘—é«˜äºå›¾ç‰‡åˆ†ç±»**ï¼Œä¹Ÿå°±å¯¼è‡´äº†ç›®æ ‡æ£€æµ‹æ•°æ®é›†è¾ƒå°ã€‚

###### è¾¹ç¼˜æ¡†

ç”¨ä¸€ä¸ªå°½é‡å°çŸ©å½¢æ¡†å°†ç›®æ ‡ç‰©ä½“å¤§ä½“æ¡†èµ·æ¥ï¼Œè¾¹æ¡†çš„ä½ç½®ä¿¡æ¯å°±å¯ä»¥è¡¨ç¤ºç›®æ ‡ä½ç½®åœ¨å›¾ç‰‡ä¸­çš„ä½ç½®ä¿¡æ¯ï¼Œå¸¸è§çš„è¾¹ç¼˜æ¡†æœ‰ä¸¤ç§è¡¨ç¤ºæ–¹æ³•ï¼š

- ï¼ˆå·¦ä¸Šxï¼Œå·¦ä¸Šyï¼Œå³ä¸‹xï¼Œå³ä¸‹yï¼‰
- ï¼ˆå·¦ä¸Šxï¼Œå·¦ä¸Šyï¼Œå®½ï¼Œé«˜ï¼‰

1. ç›®æ ‡æ£€æµ‹æ•°æ®é›†çš„å¸¸è§è¡¨ç¤ºï¼š

   æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªç‰©ä½“ï¼šâ€œå›¾ç‰‡æ–‡ä»¶åï¼Œç‰©ä½“ç±»åˆ«ï¼Œè¾¹ç¼˜æ¡†â€

   ç”±äºè¾¹ç¼˜æ¡†ç”¨4ä¸ªæ•°å€¼è¡¨ç¤ºï¼Œå› æ­¤å¯¹äºæ¯ä¸€è¡Œçš„é‚£ä¸€ä¸ªç‰©ä½“è€Œè¨€ï¼Œéœ€è¦ç”¨6ä¸ªæ•°å€¼è¡¨ç¤ºã€‚

2. ç›®æ ‡æ£€æµ‹é¢†åŸŸå¸¸ç”¨æ•°æ®é›†ï¼š

   COCOï¼ˆ80ç±»ç‰©ä½“ï¼Œ330Kå›¾ç‰‡ï¼Œæ‰€æœ‰å›¾ç‰‡å…±æ ‡æ³¨1.5Mç‰©ä½“ï¼‰

#### è¾¹ç¼˜æ¡†å®ç°

**ç›®æ ‡çš„ä½ç½®**

åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å‡è®¾å›¾åƒä¸­åªæœ‰ä¸€ä¸ªä¸»è¦ç‰©ä½“å¯¹è±¡ï¼Œæˆ‘ä»¬åªå…³æ³¨å¦‚ä½•è¯†åˆ«å…¶ç±»åˆ«ã€‚ ç„¶è€Œï¼Œå¾ˆå¤šæ—¶å€™å›¾åƒé‡Œæœ‰å¤šä¸ªæˆ‘ä»¬æ„Ÿå…´è¶£çš„ç›®æ ‡ï¼Œæˆ‘ä»¬ä¸ä»…æƒ³çŸ¥é“å®ƒä»¬çš„ç±»åˆ«ï¼Œè¿˜æƒ³å¾—åˆ°å®ƒä»¬åœ¨å›¾åƒä¸­çš„å…·ä½“ä½ç½®ã€‚ 

åœ¨è®¡ç®—æœºè§†è§‰é‡Œï¼Œæˆ‘ä»¬å°†è¿™ç±»ä»»åŠ¡ç§°ä¸º***ç›®æ ‡æ£€æµ‹*ï¼ˆobject detectionï¼‰æˆ–*ç›®æ ‡è¯†åˆ«*ï¼ˆobject recognitionï¼‰ã€‚**ç›®æ ‡æ£€æµ‹åœ¨å¤šä¸ªé¢†åŸŸä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚ ä¾‹å¦‚ï¼Œåœ¨æ— äººé©¾é©¶é‡Œï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡è¯†åˆ«æ‹æ‘„åˆ°çš„è§†é¢‘å›¾åƒé‡Œçš„è½¦è¾†ã€è¡Œäººã€é“è·¯å’Œéšœç¢ç‰©çš„ä½ç½®æ¥è§„åˆ’è¡Œè¿›çº¿è·¯ã€‚ æœºå™¨äººä¹Ÿå¸¸é€šè¿‡è¯¥ä»»åŠ¡æ¥æ£€æµ‹æ„Ÿå…´è¶£çš„ç›®æ ‡ã€‚å®‰é˜²é¢†åŸŸåˆ™éœ€è¦æ£€æµ‹å¼‚å¸¸ç›®æ ‡ï¼Œå¦‚æ­¹å¾’æˆ–è€…ç‚¸å¼¹ã€‚

```
%matplotlib inline
import torch
from d2l import torch as d2l

# ä¸‹é¢åŠ è½½æœ¬èŠ‚å°†ä½¿ç”¨çš„ç¤ºä¾‹å›¾åƒã€‚å¯ä»¥çœ‹åˆ°å›¾åƒå·¦è¾¹æ˜¯ä¸€åªç‹—ï¼Œå³è¾¹æ˜¯ä¸€åªçŒ«ã€‚ å®ƒä»¬æ˜¯è¿™å¼ å›¾åƒé‡Œçš„ä¸¤ä¸ªä¸»è¦ç›®æ ‡ã€‚

d2l.set_figsize()
img = d2l.plt.imread('../img/catdog.jpg')
d2l.plt.imshow(img);
```

**è¾¹ç•Œæ¡†**

- åœ¨ç›®æ ‡æ£€æµ‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨***è¾¹ç•Œæ¡†*ï¼ˆbounding boxï¼‰æ¥æè¿°å¯¹è±¡çš„ç©ºé—´ä½ç½®**ã€‚ è¾¹ç•Œæ¡†æ˜¯çŸ©å½¢çš„ï¼Œç”±çŸ©å½¢å·¦ä¸Šè§’çš„ä»¥åŠå³ä¸‹è§’çš„*x*å’Œ*y*åæ ‡å†³å®šã€‚ å¦ä¸€ç§å¸¸ç”¨çš„è¾¹ç•Œæ¡†è¡¨ç¤ºæ–¹æ³•æ˜¯è¾¹ç•Œæ¡†ä¸­å¿ƒçš„(*x*,*y*)è½´åæ ‡ä»¥åŠæ¡†çš„å®½åº¦å’Œé«˜åº¦ã€‚

- åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰åœ¨è¿™ä¸¤ç§è¡¨ç¤ºæ³•ä¹‹é—´è¿›è¡Œè½¬æ¢çš„å‡½æ•°ï¼š`box_corner_to_center`ä»ä¸¤è§’è¡¨ç¤ºæ³•è½¬æ¢ä¸ºä¸­å¿ƒå®½åº¦è¡¨ç¤ºæ³•

  `box_center_to_corner`åä¹‹äº¦ç„¶ã€‚ 

  è¾“å…¥å‚æ•°`boxes`å¯ä»¥æ˜¯é•¿åº¦ä¸º4çš„å¼ é‡ï¼Œä¹Ÿå¯ä»¥æ˜¯å½¢çŠ¶ä¸ºï¼ˆ*n*ï¼Œ4ï¼‰çš„äºŒç»´å¼ é‡ï¼Œå…¶ä¸­*n*æ˜¯è¾¹ç•Œæ¡†çš„æ•°é‡ã€‚

```
# 
def box_corner_to_center(boxes):
    """ä»ï¼ˆå·¦ä¸Šï¼Œå³ä¸‹ï¼‰è½¬æ¢åˆ°ï¼ˆä¸­é—´ï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰"""
    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    cx = (x1 + x2) / 2
    cy = (y1 + y2) / 2
    w = x2 - x1
    h = y2 - y1
    boxes = torch.stack((cx, cy, w, h), axis=-1)
    return boxes

#@save
def box_center_to_corner(boxes):
    """ä»ï¼ˆä¸­é—´ï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰è½¬æ¢åˆ°ï¼ˆå·¦ä¸Šï¼Œå³ä¸‹ï¼‰"""
    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]
    x1 = cx - 0.5 * w
    y1 = cy - 0.5 * h
    x2 = cx + 0.5 * w
    y2 = cy + 0.5 * h
    boxes = torch.stack((x1, y1, x2, y2), axis=-1)
    return boxes
```

- æˆ‘ä»¬å°†æ ¹æ®åæ ‡ä¿¡æ¯å®šä¹‰å›¾åƒä¸­ç‹—å’ŒçŒ«çš„è¾¹ç•Œæ¡†ã€‚ å›¾åƒä¸­åæ ‡çš„åŸç‚¹æ˜¯å›¾åƒçš„å·¦ä¸Šè§’ï¼Œå‘å³çš„æ–¹å‘ä¸º*x*è½´çš„æ­£æ–¹å‘ï¼Œå‘ä¸‹çš„æ–¹å‘ä¸º*y*è½´çš„æ­£æ–¹å‘ã€‚

```
# bboxæ˜¯è¾¹ç•Œæ¡†çš„è‹±æ–‡ç¼©å†™
dog_bbox, cat_bbox = [60.0, 45.0, 378.0, 516.0], [400.0, 112.0, 655.0, 493.0]
```

- æˆ‘ä»¬å¯ä»¥å°†è¾¹ç•Œæ¡†åœ¨å›¾ä¸­ç”»å‡ºï¼Œä»¥æ£€æŸ¥å…¶æ˜¯å¦å‡†ç¡®ã€‚ ç”»ä¹‹å‰ï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªè¾…åŠ©å‡½æ•°`bbox_to_rect`ã€‚ å®ƒå°†è¾¹ç•Œæ¡†è¡¨ç¤ºæˆ`matplotlib`çš„è¾¹ç•Œæ¡†æ ¼å¼ã€‚

```
#@save
def bbox_to_rect(bbox, color):
    # å°†è¾¹ç•Œæ¡†(å·¦ä¸Šx,å·¦ä¸Šy,å³ä¸‹x,å³ä¸‹y)æ ¼å¼è½¬æ¢æˆmatplotlibæ ¼å¼ï¼š
    # ((å·¦ä¸Šx,å·¦ä¸Šy),å®½,é«˜)
    return d2l.plt.Rectangle(
        xy=(bbox[0], bbox[1]), width=bbox[2]-bbox[0], height=bbox[3]-bbox[1],
        fill=False, edgecolor=color, linewidth=2)
```

- åœ¨å›¾åƒä¸Šæ·»åŠ è¾¹ç•Œæ¡†ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸¤ä¸ªç‰©ä½“çš„ä¸»è¦è½®å»“åŸºæœ¬ä¸Šåœ¨ä¸¤ä¸ªæ¡†å†…ã€‚

```
fig = d2l.plt.imshow(img)
fig.axes.add_patch(bbox_to_rect(dog_bbox, 'blue'))
fig.axes.add_patch(bbox_to_rect(cat_bbox, 'red'));
```

##### å°ç»“

- ç›®æ ‡æ£€æµ‹ä¸ä»…å¯ä»¥è¯†åˆ«å›¾åƒä¸­æ‰€æœ‰æ„Ÿå…´è¶£çš„ç‰©ä½“ï¼Œè¿˜èƒ½è¯†åˆ«å®ƒä»¬çš„ä½ç½®ï¼Œè¯¥ä½ç½®é€šå¸¸ç”±çŸ©å½¢è¾¹ç•Œæ¡†è¡¨ç¤ºã€‚
- æˆ‘ä»¬å¯ä»¥åœ¨ä¸¤ç§å¸¸ç”¨çš„è¾¹ç•Œæ¡†è¡¨ç¤ºï¼ˆä¸­é—´ï¼Œå®½åº¦ï¼Œé«˜åº¦ï¼‰å’Œï¼ˆå·¦ä¸Šï¼Œå³ä¸‹ï¼‰åæ ‡ä¹‹é—´è¿›è¡Œè½¬æ¢ã€‚

#### æ•°æ®é›†

ç›®æ ‡æ£€æµ‹é¢†åŸŸæ²¡æœ‰åƒMNISTå’ŒFashion-MNISTé‚£æ ·çš„å°æ•°æ®é›†ã€‚ ä¸ºäº†å¿«é€Ÿæµ‹è¯•ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œæˆ‘ä»¬æ”¶é›†å¹¶æ ‡è®°äº†ä¸€ä¸ªå°å‹æ•°æ®é›†ã€‚ é¦–å…ˆï¼Œæˆ‘ä»¬æ‹æ‘„äº†ä¸€ç»„é¦™è•‰çš„ç…§ç‰‡ï¼Œå¹¶ç”Ÿæˆäº†1000å¼ ä¸åŒè§’åº¦å’Œå¤§å°çš„é¦™è•‰å›¾åƒã€‚ ç„¶åï¼Œæˆ‘ä»¬åœ¨ä¸€äº›èƒŒæ™¯å›¾ç‰‡çš„éšæœºä½ç½®ä¸Šæ”¾ä¸€å¼ é¦™è•‰çš„å›¾åƒã€‚ æœ€åï¼Œæˆ‘ä»¬åœ¨å›¾ç‰‡ä¸Šä¸ºè¿™äº›é¦™è•‰æ ‡è®°äº†è¾¹ç•Œæ¡†ã€‚

1. ä¸‹è½½æ•°æ®é›†

- åŒ…å«æ‰€æœ‰å›¾åƒå’ŒCSVæ ‡ç­¾æ–‡ä»¶çš„é¦™è•‰æ£€æµ‹æ•°æ®é›†å¯ä»¥ç›´æ¥ä»äº’è”ç½‘ä¸‹è½½ã€‚

```
import os
import pandas as pd
from mxnet import gluon, image, np, npx
from d2l import mxnet as d2l

# set_np()åˆå§‹åŒ–numpyçš„å…¼å®¹æ ¼å¼
npx.set_np()


d2l.DATA_HUB['banana-detection'] = (
    d2l.DATA_URL + 'banana-detection.zip',
    '5de26c8fce5ccdea9f91267273464dc968d20d72')
```

è¯»å–æ•°æ®é›†

- é€šè¿‡`read_data_bananas`å‡½æ•°ï¼Œæˆ‘ä»¬è¯»å–é¦™è•‰æ£€æµ‹æ•°æ®é›†ã€‚ è¯¥æ•°æ®é›†åŒ…æ‹¬ä¸€ä¸ªçš„CSVæ–‡ä»¶ï¼Œå†…å«ç›®æ ‡ç±»åˆ«æ ‡ç­¾å’Œä½äºå·¦ä¸Šè§’å’Œå³ä¸‹è§’çš„çœŸå®è¾¹ç•Œæ¡†åæ ‡ã€‚

```
def read_data_bananas(is_train=True):
    """è¯»å–é¦™è•‰æ£€æµ‹æ•°æ®é›†ä¸­çš„å›¾åƒå’Œæ ‡ç­¾"""
    # ä¸‹è½½å¹¶è‡ªåŠ¨è§£å‹æ•°æ®é›†
    data_dir = d2l.download_extract('banana-detection')
    
    # is_train å‚æ•°ï¼ˆå†³å®šæ˜¯è¯»å–è®­ç»ƒæ•°æ®è¿˜æ˜¯éªŒè¯æ•°æ®ï¼‰
    csv_fname = os.path.join(data_dir, 'bananas_train' if is_train else 'bananas_val', 'label.csv')
    
    
    csv_data = pd.read_csv(csv_fname)
    csv_data = csv_data.set_index('img_name')
    
    images, targets = [], []
    for img_name, target in csv_data.iterrows():
    	# torchvision.io.read_image å‡½æ•°åŠ è½½å›¾åƒæ•°æ®
    	# å¹¶è‡ªåŠ¨å°†å…¶è½¬æ¢ä¸º PyTorch çš„ tensor æ ¼å¼
        images.append(torchvision.io.read_image(
            os.path.join(data_dir, 'bananas_train' if is_train else 'bananas_val', 'images', f'{img_name}')))
        
       # è¿™é‡Œçš„targetåŒ…å«ï¼ˆç±»åˆ«ï¼Œå·¦ä¸Šè§’xï¼Œå·¦ä¸Šè§’yï¼Œå³ä¸‹è§’xï¼Œå³ä¸‹è§’yï¼‰ï¼Œ
       # å…¶ä¸­æ‰€æœ‰å›¾åƒéƒ½å…·æœ‰ç›¸åŒçš„é¦™è•‰ç±»ï¼ˆç´¢å¼•ä¸º0ï¼‰
        targets.append(list(target))
    
    # å½’ä¸€åŒ–å¤„ç†
    # unsqueeze(1) æ˜¯ä¸ºäº†ç¡®ä¿æ ‡ç­¾çš„ç»´åº¦ä¸æ¨¡å‹æœŸæœ›çš„è¾“å…¥ç»´åº¦åŒ¹é…
    return images, torch.tensor(targets).unsqueeze(1) / 256
```

- é€šè¿‡ä½¿ç”¨`read_data_bananas`å‡½æ•°è¯»å–å›¾åƒå’Œæ ‡ç­¾ï¼Œä»¥ä¸‹`BananasDataset`ç±»åˆ«å°†å…è®¸æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰`Dataset`å®ä¾‹æ¥åŠ è½½é¦™è•‰æ£€æµ‹æ•°æ®é›†ã€‚

```
class BananasDataset(torch.utils.data.Dataset):
    """ä¸€ä¸ªç”¨äºåŠ è½½é¦™è•‰æ£€æµ‹æ•°æ®é›†çš„è‡ªå®šä¹‰æ•°æ®é›†"""
    def __init__(self, is_train):
        self.features, self.labels = 	
        read_data_bananas(is_train)
        
        print('read ' + str(len(self.features)) + (f' training examples' if is_train else f' validation examples'))

    def __getitem__(self, idx):
        return (self.features[idx].float(), self.labels[idx])

    def __len__(self):
        return len(self.features)
```

- æœ€åï¼Œæˆ‘ä»¬å®šä¹‰`load_data_bananas`å‡½æ•°ï¼Œæ¥ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿”å›ä¸¤ä¸ªæ•°æ®åŠ è½½å™¨å®ä¾‹ã€‚å¯¹äºæµ‹è¯•é›†ï¼Œæ— é¡»æŒ‰éšæœºé¡ºåºè¯»å–å®ƒã€‚

```
def load_data_bananas(batch_size):
    """åŠ è½½é¦™è•‰æ£€æµ‹æ•°æ®é›†"""
    train_iter = torch.utils.data.DataLoader(
    BananasDataset(is_train=True),batch_size, shuffle=True)
    val_iter = torch.utils.data.DataLoader(
    BananasDataset(is_train=False),batch_size)
    
    return train_iter, val_iter
```

- è®©æˆ‘ä»¬è¯»å–ä¸€ä¸ªå°æ‰¹é‡ï¼Œå¹¶æ‰“å°å…¶ä¸­çš„å›¾åƒå’Œæ ‡ç­¾çš„å½¢çŠ¶ã€‚ å›¾åƒçš„å°æ‰¹é‡çš„å½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ã€é€šé“æ•°ã€é«˜åº¦ã€å®½åº¦ï¼‰ï¼Œçœ‹èµ·æ¥å¾ˆçœ¼ç†Ÿï¼šå®ƒä¸æˆ‘ä»¬ä¹‹å‰å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­çš„ç›¸åŒã€‚ æ ‡ç­¾çš„å°æ‰¹é‡çš„å½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œ*m*ï¼Œ5ï¼‰ï¼Œå…¶ä¸­*m*æ˜¯æ•°æ®é›†çš„ä»»ä½•å›¾åƒä¸­è¾¹ç•Œæ¡†å¯èƒ½å‡ºç°çš„æœ€å¤§æ•°é‡ã€‚

```
batch_size, edge_size = 32, 256
train_iter, _ = load_data_bananas(batch_size)
batch = next(iter(train_iter))
batch[0].shape, batch[1].shape
```

#### å°ç»“

- æˆ‘ä»¬æ”¶é›†çš„é¦™è•‰æ£€æµ‹æ•°æ®é›†å¯ç”¨äºæ¼”ç¤ºç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚
- ç”¨äºç›®æ ‡æ£€æµ‹çš„æ•°æ®åŠ è½½ä¸å›¾åƒåˆ†ç±»çš„æ•°æ®åŠ è½½ç±»ä¼¼ã€‚ä½†æ˜¯ï¼Œåœ¨ç›®æ ‡æ£€æµ‹ä¸­ï¼Œæ ‡ç­¾è¿˜åŒ…å«çœŸå®è¾¹ç•Œæ¡†çš„ä¿¡æ¯ï¼Œå®ƒä¸å‡ºç°åœ¨å›¾åƒåˆ†ç±»ä¸­ã€‚





## é”šæ¡†

### å®šä¹‰

#### é”šæ¡†ï¼ˆAnchor Boxesï¼‰

ä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒï¼Œç”Ÿæˆå¤šä¸ªç¼©æ”¾æ¯”å’Œå®½é«˜æ¯”ï¼ˆaspect ratioï¼‰ä¸åŒçš„è¾¹ç•Œæ¡†ã€‚ è¿™äº›è¾¹ç•Œæ¡†è¢«ç§°ä¸º*é”šæ¡†*ï¼ˆanchor boxï¼‰ã€‚

é”šæ¡†æ˜¯ä¸€ç§é¢„å®šä¹‰çš„æ¡†ï¼Œç”¨äºä½œä¸ºå¯¹è±¡æ£€æµ‹ç®—æ³•ä¸­çš„å‚è€ƒç‚¹ã€‚**è¿™äº›æ¡†æœ‰å›ºå®šçš„å¤§å°å’Œæ¯”ä¾‹ï¼Œç”¨æ¥é¢„æµ‹å®é™…å¯¹è±¡å¯èƒ½å‡ºç°çš„ä½ç½®ï¼ˆé¢„è®¾å¥½çš„ï¼‰ã€‚**é”šæ¡†çš„ä¸»è¦ç›®çš„æ˜¯æä¾›ä¸€ä¸ªåˆå§‹çš„ã€å›ºå®šçš„å‚è€ƒç³»ç»Ÿï¼Œä½¿å¾—æ£€æµ‹æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°åœ¨è¿™äº›å‚è€ƒæ¡†çš„åŸºç¡€ä¸Šè°ƒæ•´æ¥å‡†ç¡®é¢„æµ‹å¯¹è±¡çš„ä½ç½®ã€‚

- **ä½œç”¨**ï¼šåœ¨è®­ç»ƒå¯¹è±¡æ£€æµ‹æ¨¡å‹æ—¶ï¼Œæ¯ä¸ªé”šæ¡†éƒ½ä¼šå°è¯•åŒ¹é…å›¾åƒä¸­æœ€æ¥è¿‘çš„çœŸå®å¯¹è±¡ã€‚å¦‚æœä¸€ä¸ªé”šæ¡†ä¸æŸä¸ªçœŸå®å¯¹è±¡çš„é‡å ç¨‹åº¦ï¼ˆé€šå¸¸ä½¿ç”¨äº¤å¹¶æ¯”ï¼ŒIntersection over Union, IoUï¼‰é«˜äºæŸä¸ªé˜ˆå€¼ï¼Œåˆ™è¿™ä¸ªé”šæ¡†è¢«è®¤ä¸ºæ˜¯æ­£æ ·æœ¬ï¼Œæ¨¡å‹å°†è¯•å›¾è°ƒæ•´è¿™ä¸ªé”šæ¡†çš„å¤§å°å’Œä½ç½®æ¥æ›´å¥½åœ°è¦†ç›–è¿™ä¸ªå¯¹è±¡ã€‚
- **åº”ç”¨**ï¼šé”šæ¡†åœ¨è®¸å¤šç°ä»£å¯¹è±¡æ£€æµ‹æ¡†æ¶ä¸­éƒ½æœ‰åº”ç”¨ï¼Œå¦‚ Faster R-CNNã€SSDï¼ˆSingle Shot MultiBox Detectorï¼‰ç­‰ã€‚è¿™äº›æ¡†æ¶ä½¿ç”¨é”šæ¡†ä½œä¸ºå­¦ä¹ ç›®æ ‡ä½ç½®å’Œå°ºå¯¸çš„åŸºç¡€ã€‚

##### è¾¹ç•Œæ¡†ï¼ˆBounding Boxesï¼‰

è¾¹ç•Œæ¡†æ˜¯å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸­çš„ä¸€ä¸ªæœ¯è¯­ï¼ŒæŒ‡çš„æ˜¯å›´ç»•è¯†åˆ«å¯¹è±¡çš„çŸ©å½¢æ¡†ã€‚**å®ƒä»¬æè¿°äº†å¯¹è±¡åœ¨å›¾åƒä¸­çš„ä½ç½®å’ŒèŒƒå›´ã€‚**ï¼ˆçœŸå®å­˜åœ¨ï¼‰

- **å‚æ•°**ï¼šè¾¹ç•Œæ¡†é€šå¸¸ç”±å››ä¸ªåæ ‡å®šä¹‰ï¼Œ(x_min, y_min, x_max, y_max) æˆ– (x, y, width, height)ï¼Œå…¶ä¸­ (x, y) ä»£è¡¨æ¡†çš„å·¦ä¸Šè§’åæ ‡ï¼Œè€Œ width å’Œ height åˆ†åˆ«ä»£è¡¨æ¡†çš„å®½åº¦å’Œé«˜åº¦ã€‚
- **åŠŸèƒ½**ï¼šåœ¨å¯¹è±¡æ£€æµ‹ä¸­ï¼Œè¾¹ç•Œæ¡†æ˜¯æ¨¡å‹è¾“å‡ºçš„ä¸€éƒ¨åˆ†ï¼Œç”¨æ¥æ ‡ç¤ºæ¨¡å‹è®¤ä¸ºæœ‰å¯¹è±¡å­˜åœ¨çš„åŒºåŸŸã€‚**æ¨¡å‹çš„ä»»åŠ¡æ˜¯æ­£ç¡®é¢„æµ‹å¯¹è±¡çš„ç±»åˆ«åŠå…¶è¾¹ç•Œæ¡†çš„ä½ç½®**ã€‚
- **è¯„ä¼°**ï¼šåœ¨æµ‹è¯•å¯¹è±¡æ£€æµ‹æ¨¡å‹æ—¶ï¼Œé¢„æµ‹çš„è¾¹ç•Œæ¡†ä¼šä¸çœŸå®çš„è¾¹ç•Œæ¡†ï¼ˆæ ‡æ³¨æ•°æ®ä¸­ç»™å‡ºï¼‰æ¯”è¾ƒï¼Œé€šè¿‡è®¡ç®—å®ƒä»¬çš„ IoU æ¥è¯„ä¼°æ¨¡å‹çš„ç²¾ç¡®åº¦ã€‚é«˜ IoU å€¼è¡¨ç¤ºé¢„æµ‹çš„è¾¹ç•Œæ¡†ä¸çœŸå®æ¡†éå¸¸æ¥è¿‘ï¼Œå³é¢„æµ‹å‡†ç¡®ã€‚

#### é”šæ¡†ä¸è¾¹ç•Œæ¡†çš„å…³ç³»

è™½ç„¶é”šæ¡†å’Œè¾¹ç•Œæ¡†éƒ½æ˜¯ç”¨æ¥å®šä½å›¾åƒä¸­çš„å¯¹è±¡ï¼Œä½†å®ƒä»¬çš„åŠŸèƒ½å’Œç”¨é€”æœ‰æ‰€ä¸åŒã€‚é”šæ¡†æ˜¯ç”¨æ¥ä½œä¸ºå¯¹è±¡æ£€æµ‹ç®—æ³•ä¸­çš„**å‚è€ƒå’Œèµ·ç‚¹**ï¼Œè€Œè¾¹ç•Œæ¡†åˆ™æ˜¯**ç®—æ³•çš„æœ€ç»ˆè¾“å‡º**ï¼Œè¡¨ç¤ºæ¨¡å‹æ£€æµ‹åˆ°çš„å¯¹è±¡çš„å…·ä½“ä½ç½®ã€‚é”šæ¡†é€šå¸¸åœ¨ç®—æ³•å†…éƒ¨ä½¿ç”¨ï¼Œè€Œè¾¹ç•Œæ¡†åˆ™æ˜¯ç®—æ³•å¯¹å¤–è¾“å‡ºçš„å¯¹è±¡ä½ç½®ä¿¡æ¯ã€‚

### IoU-äº¤å¹¶æ¯”

æ¯”è¾ƒç›¸ä¼¼åº¦

![image-20240721115744680](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240721115744680.png)

### èµ‹äºˆé”šæ¡†æ ‡å·

- å°†æ¯ä¸ªé”šæ¡†è§†ä½œä¸€ä¸ªè®­ç»ƒæ ·æœ¬ã€‚è¦ä¹ˆå°†é”šæ¡†æ ‡æ³¨æˆèƒŒæ™¯ï¼ˆè´Ÿç±»æ ·æœ¬ï¼‰ï¼Œè¦ä¹ˆå…³è”ä¸Šä¸€ä¸ªçœŸå®è¾¹ç¼˜æ¡†ï¼šä¼šäº§ç”Ÿå¤§é‡çš„è´Ÿç±»æ ·æœ¬ã€‚
- æ¯æ¬¡æŠŠå›¾ç‰‡è¯»è¿›æ¥æˆ‘ä»¬éƒ½ä¼šå¯¹å›¾ç‰‡è¿›è¡Œâ€œèµ‹äºˆé”šæ¡†æ ‡å·â€çš„æ“ä½œã€‚

### ä½¿ç”¨ï¼ˆNMSï¼‰éæå¤§å€¼æŠ‘åˆ¶è¾“å‡º



### ä»£ç 

- åˆ†é…é”šæ¡†
- è®¡ç®—IoUï¼Œåˆ é™¤èƒŒæ™¯é”šæ¡†
- ç¡®å®šæ¯ä¸ªé”šæ¡†çš„*ç±»åˆ«*ï¼ˆclassï¼‰å’Œ*åç§»é‡*ï¼ˆoffsetï¼‰

#### é”šæ¡†

```python
import torch
from d2l import torch as d2l

# ç²¾ç®€è¾“å‡ºï¼Œæ§åˆ¶è¾“å‡ºç²¾åº¦
torch.set_printoptions(2)
```

#### ç”Ÿæˆå¤šä¸ªé”šæ¡†

å‡è®¾è¾“å…¥å›¾åƒçš„é«˜åº¦ä¸ºâ„ï¼Œå®½åº¦ä¸ºğ‘¤ã€‚ æˆ‘ä»¬ä»¥å›¾åƒçš„æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒç”Ÿæˆä¸åŒå½¢çŠ¶çš„é”šæ¡†ï¼š*ç¼©æ”¾æ¯”*ä¸ºğ‘ âˆˆ(0,1]ï¼Œ*å®½é«˜æ¯”*ä¸ºğ‘Ÿ>0ã€‚

**ç¼©æ”¾æ¯”**ï¼šä»£è¡¨é”šæ¡†å°ºå¯¸ä¸å›¾åƒå°ºå¯¸çš„æ¯”ä¾‹ã€‚å¦‚æœ s=1ï¼Œåˆ™é”šæ¡†çš„å¤§å°åœ¨æŸä¸ªç»´åº¦ä¸Šå¯èƒ½ä¸å›¾åƒçš„å¤§å°ç›¸åŒã€‚

**å®½é«˜æ¯”**ï¼šé”šæ¡†å®½åº¦å’Œé«˜åº¦çš„æ¯”ä¾‹ã€‚ä¸€ä¸ªå¤§äº1çš„ rå€¼è¡¨ç¤ºé”šæ¡†æ¯”å›¾åƒæ›´å®½ï¼Œè€Œå°äº1çš„å€¼åˆ™è¡¨ç¤ºé”šæ¡†æ¯”å›¾åƒæ›´é«˜ã€‚é€šè¿‡æ”¹å˜å®½é«˜æ¯”ï¼Œå¯ä»¥ç”Ÿæˆå„ç§å½¢çŠ¶çš„é”šæ¡†ï¼Œä»¥æ›´å¥½åœ°é€‚åº”å›¾åƒä¸­å¯èƒ½çš„ä¸åŒå¯¹è±¡å½¢çŠ¶ã€‚

![image-20240722143854123](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240722143854123.png)

è¯·æ³¨æ„ï¼Œå½“ä¸­å¿ƒä½ç½®ç»™å®šæ—¶ï¼Œå·²çŸ¥å®½å’Œé«˜çš„é”šæ¡†æ˜¯ç¡®å®šçš„ã€‚

è¦ç”Ÿæˆå¤šä¸ªä¸åŒå½¢çŠ¶çš„é”šæ¡†ï¼Œè®©æˆ‘ä»¬è®¾ç½®è®¸å¤šç¼©æ”¾æ¯”ï¼ˆscaleï¼‰å–å€¼ğ‘ 1,â€¦,ğ‘ ğ‘›å’Œè®¸å¤šå®½é«˜æ¯”ï¼ˆaspect ratioï¼‰å–å€¼ğ‘Ÿ1,â€¦,ğ‘Ÿğ‘šã€‚ å½“ä½¿ç”¨è¿™äº›æ¯”ä¾‹å’Œé•¿å®½æ¯”çš„æ‰€æœ‰ç»„åˆä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒæ—¶ï¼Œè¾“å…¥å›¾åƒå°†æ€»å…±æœ‰ğ‘¤â„ğ‘›ğ‘šä¸ªé”šæ¡†ã€‚ å°½ç®¡è¿™äº›é”šæ¡†å¯èƒ½ä¼šè¦†ç›–æ‰€æœ‰çœŸå®è¾¹ç•Œæ¡†ï¼Œä½†è®¡ç®—å¤æ‚æ€§å¾ˆå®¹æ˜“è¿‡é«˜ã€‚ åœ¨å®è·µä¸­ï¼Œ**æˆ‘ä»¬åªè€ƒè™‘**åŒ…å«ğ‘ 1æˆ–ğ‘Ÿ1çš„**ç»„åˆï¼š**

(**(ğ‘ 1,ğ‘Ÿ1),(ğ‘ 1,ğ‘Ÿ2),â€¦,(ğ‘ 1,ğ‘Ÿğ‘š),(ğ‘ 2,ğ‘Ÿ1),(ğ‘ 3,ğ‘Ÿ1),â€¦,(ğ‘ ğ‘›,ğ‘Ÿ1).**)

ä¹Ÿå°±æ˜¯è¯´ï¼Œä»¥åŒä¸€åƒç´ ä¸ºä¸­å¿ƒçš„é”šæ¡†çš„æ•°é‡æ˜¯ğ‘›+ğ‘šâˆ’1ã€‚ å¯¹äºæ•´ä¸ªè¾“å…¥å›¾åƒï¼Œå°†å…±ç”Ÿæˆğ‘¤â„(ğ‘›+ğ‘šâˆ’1)ä¸ªé”šæ¡†ã€‚

ä¸Šè¿°ç”Ÿæˆé”šæ¡†çš„æ–¹æ³•åœ¨ä¸‹é¢çš„`multibox_prior`å‡½æ•°ä¸­å®ç°ã€‚ æˆ‘ä»¬æŒ‡å®šè¾“å…¥å›¾åƒã€å°ºå¯¸åˆ—è¡¨å’Œå®½é«˜æ¯”åˆ—è¡¨ï¼Œç„¶åæ­¤å‡½æ•°å°†è¿”å›æ‰€æœ‰çš„é”šæ¡†ã€‚

```python
# ç”Ÿæˆé”šæ¡†
def multibox_prior(data, sizes, ratios):
    """ç”Ÿæˆä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒå…·æœ‰ä¸åŒå½¢çŠ¶çš„é”šæ¡†"""
    
    # data.shapeé€šå¸¸è¿”å›å¼ é‡çš„çš„ç»´åº¦
    # äºŒç»´æ•°æ®ï¼š(channels, height, width)
    in_height, in_width = data.shape[-2:]
    
    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)
    # ç”Ÿæˆçš„é”šæ¡†æ•°é‡
    boxes_per_pixel = (num_sizes + num_ratios - 1)
    size_tensor = torch.tensor(sizes, device=device)
    ratio_tensor = torch.tensor(ratios, device=device)

    # ä¸ºäº†å°†é”šç‚¹ç§»åŠ¨åˆ°åƒç´ çš„ä¸­å¿ƒï¼Œéœ€è¦è®¾ç½®åç§»é‡ã€‚
    # å› ä¸ºä¸€ä¸ªåƒç´ çš„é«˜ä¸º1ä¸”å®½ä¸º1ï¼Œæˆ‘ä»¬é€‰æ‹©åç§»æˆ‘ä»¬çš„ä¸­å¿ƒ0.5
    offset_h, offset_w = 0.5, 0.5
    steps_h = 1.0 / in_height  # åœ¨yè½´ä¸Šç¼©æ”¾æ­¥é•¿
    steps_w = 1.0 / in_width  # åœ¨xè½´ä¸Šç¼©æ”¾æ­¥é•¿

    # ç”Ÿæˆé”šæ¡†çš„æ‰€æœ‰ä¸­å¿ƒç‚¹
    # torch.arange(in_heightï¼‰ä¼šç”Ÿæˆä¸€ä¸ªä»0åˆ°in_height-1çš„æ•´æ•°åºåˆ—
    #  + offset_h æ˜¯ä¸ºäº†å°†èµ·å§‹ä½ç½®ä»è¾¹ç¼˜ç§»åˆ°ä¸­å¿ƒ
    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h
    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w
    
    # torch.meshgrid ç”Ÿæˆä¸€ä¸ªç½‘æ ¼ï¼Œè¿™ä¸ªç½‘æ ¼ä¸Šçš„æ¯ä¸€ç‚¹éƒ½æ˜¯ä¸€ä¸ªä¸­å¿ƒç‚¹çš„åæ ‡
    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')
    # åæ ‡æ‹‰å¹³ä¸ºä¸€ç»´æ•°ç»„
    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)

    # ç”Ÿæˆâ€œboxes_per_pixelâ€ä¸ªé«˜å’Œå®½ï¼Œ
    # ä¹‹åç”¨äºåˆ›å»ºé”šæ¡†çš„å››è§’åæ ‡(xmin,xmax,ymin,ymax)
    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),
                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\
                   * in_height / in_width  # å¤„ç†çŸ©å½¢è¾“å…¥
    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),
                   sizes[0] / torch.sqrt(ratio_tensor[1:])))
    
    # é™¤ä»¥2æ¥è·å¾—åŠé«˜å’ŒåŠå®½
    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(in_height * in_width, 1) / 2

    # æ¯ä¸ªä¸­å¿ƒç‚¹éƒ½å°†æœ‰â€œboxes_per_pixelâ€ä¸ªé”šæ¡†ï¼Œ
    # æ‰€ä»¥ç”Ÿæˆå«æ‰€æœ‰é”šæ¡†ä¸­å¿ƒçš„ç½‘æ ¼ï¼Œé‡å¤äº†â€œboxes_per_pixelâ€æ¬¡
    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],dim=1).repeat_interleave(boxes_per_pixel, dim=0)
    output = out_grid + anchor_manipulations
    return output.unsqueeze(0)
```

##### **æ˜¾ç¤ºä»¥å›¾åƒä¸­ä»¥æŸä¸ªåƒç´ ä¸ºä¸­å¿ƒçš„æ‰€æœ‰é”šæ¡†**

```python
def show_bboxes(axes, bboxes, labels=None, colors=None):
    """æ˜¾ç¤ºæ‰€æœ‰è¾¹ç•Œæ¡†"""
    def _make_list(obj, default_values=None):
        if obj is None:
            obj = default_values
        elif not isinstance(obj, (list, tuple)):
            obj = [obj]
        return obj

    labels = _make_list(labels)
    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'c'])
    for i, bbox in enumerate(bboxes):
        color = colors[i % len(colors)]
        rect = d2l.bbox_to_rect(bbox.detach().numpy(), color)
        axes.add_patch(rect)
        if labels and len(labels) > i:
            text_color = 'k' if color == 'w' else 'w'
            axes.text(rect.xy[0], rect.xy[1], labels[i],
                      va='center', ha='center', fontsize=9, color=text_color,
                      bbox=dict(facecolor=color, lw=0))
```

#### äº¤å¹¶æ¯”IoU

```
def box_iou(boxes1, boxes2):
# å…¶ä¸­æ¯ä¸ªè¾¹ç•Œæ¡†ç”¨å››ä¸ªåæ ‡è¡¨ç¤ºï¼ˆé€šå¸¸æ˜¯ xmin, ymin, xmax, ymaxï¼‰ã€‚
    """è®¡ç®—ä¸¤ä¸ªé”šæ¡†æˆ–è¾¹ç•Œæ¡†åˆ—è¡¨ä¸­æˆå¯¹çš„äº¤å¹¶æ¯”"""
    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *
                              (boxes[:, 3] - boxes[:, 1]))
    # boxes1,boxes2,areas1,areas2çš„å½¢çŠ¶:
    # boxes1ï¼š(boxes1çš„æ•°é‡,4),
    # boxes2ï¼š(boxes2çš„æ•°é‡,4),
    # areas1ï¼š(boxes1çš„æ•°é‡,),
    # areas2ï¼š(boxes2çš„æ•°é‡,)
    areas1 = box_area(boxes1)
    areas2 = box_area(boxes2)
    
    # inter_upperlefts,inter_lowerrights,intersçš„å½¢çŠ¶:
    # (boxes1çš„æ•°é‡,boxes2çš„æ•°é‡,2)
    inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])
    inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])
    
    # å¦‚æœäº¤é›†ä¸å­˜åœ¨ï¼ˆå³å®½æˆ–é«˜ä¸ºè´Ÿå€¼ï¼‰ï¼Œé€šè¿‡clamp(min=0) ç¡®ä¿å…¶å€¼ä¸ºé›¶
    inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)
    
    # inter_areasandunion_areasçš„å½¢çŠ¶:(boxes1çš„æ•°é‡,boxes2çš„æ•°é‡)
    inter_areas = inters[:, :, 0] * inters[:, :, 1]
    union_areas = areas1[:, None] + areas2 - inter_areas
    return inter_areas / union_areas
```

#### å°†çœŸå®è¾¹ç•Œæ¡†åˆ†é…ç»™é”šæ¡†

æˆ‘ä»¬éœ€è¦æ¯ä¸ªé”šæ¡†çš„*ç±»åˆ«*ï¼ˆclassï¼‰å’Œ*åç§»é‡*ï¼ˆoffsetï¼‰æ ‡ç­¾ï¼Œå…¶ä¸­å‰è€…æ˜¯ä¸é”šæ¡†ç›¸å…³çš„å¯¹è±¡çš„ç±»åˆ«ï¼Œåè€…æ˜¯çœŸå®è¾¹ç•Œæ¡†ç›¸å¯¹äºé”šæ¡†çš„åç§»é‡ã€‚

è¦æ ‡è®°ä»»ä½•ç”Ÿæˆçš„é”šæ¡†ï¼Œæˆ‘ä»¬å¯ä»¥å‚è€ƒåˆ†é…åˆ°çš„æœ€æ¥è¿‘æ­¤é”šæ¡†çš„çœŸå®è¾¹ç•Œæ¡†çš„ä½ç½®å’Œç±»åˆ«æ ‡ç­¾ã€‚ ä¸‹æ–‡å°†ä»‹ç»ä¸€ä¸ªç®—æ³•ï¼Œå®ƒèƒ½å¤ŸæŠŠæœ€æ¥è¿‘çš„çœŸå®è¾¹ç•Œæ¡†åˆ†é…ç»™é”šæ¡†ã€‚

```
# çœŸå®è¾¹ç•Œæ¡†é›†åˆ ground_truthï¼Œé”šæ¡†é›†åˆ anchorsï¼Œè¿ç®—è®¾å¤‡ deviceï¼Œä»¥åŠä¸€ä¸ª IoU é˜ˆå€¼ iou_threshold
def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5):
    """å°†æœ€æ¥è¿‘çš„çœŸå®è¾¹ç•Œæ¡†åˆ†é…ç»™é”šæ¡†"""
    # num_anchors å’Œ num_gt_boxes åˆ†åˆ«æ˜¯é”šæ¡†å’ŒçœŸå®è¾¹ç•Œæ¡†çš„æ•°é‡ã€‚
    num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]
    
    # ä½äºç¬¬iè¡Œå’Œç¬¬jåˆ—çš„å…ƒç´ x_ijæ˜¯é”šæ¡†iå’ŒçœŸå®è¾¹ç•Œæ¡†jçš„IoU
    jaccard = box_iou(anchors, ground_truth)
    
    # å¯¹äºæ¯ä¸ªé”šæ¡†ï¼Œåˆ†é…çš„çœŸå®è¾¹ç•Œæ¡†çš„å¼ é‡
    # åˆå§‹åŒ–ï¼štorch.full æ˜¯ä¸€ä¸ªç”¨æ¥åˆ›å»ºå…·æœ‰æŒ‡å®šå½¢çŠ¶å’Œå¡«å……å•ä¸€å€¼çš„å¼ é‡çš„å‡½æ•°ã€‚
    # torch.full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False)
    # size (tuple æˆ– list)ï¼šå¼ é‡å½¢çŠ¶ï¼Œ(3, 4) è¡¨ç¤ºä¸€ä¸ª3è¡Œ4åˆ—çš„çŸ©é˜µã€‚
    # fill_value (scalar)ï¼šç”¨äºå¡«å……å¼ é‡çš„å€¼ã€‚
    anchors_bbox_map = torch.full((num_anchors,), -1, dtype=torch.long,device=device)
    
    
    # æ ¹æ®é˜ˆå€¼ï¼Œå†³å®šæ˜¯å¦åˆ†é…çœŸå®è¾¹ç•Œæ¡†
    max_ious, indices = torch.max(jaccard, dim=1)
    
    # anc_i æ˜¯æ‰€æœ‰ IoU è¶…è¿‡é˜ˆå€¼çš„é”šæ¡†çš„ç´¢å¼•åˆ—è¡¨ã€‚
	# box_j æ˜¯è¿™äº›é”šæ¡†å¯¹åº”çš„æœ€åŒ¹é…çœŸå®è¾¹ç•Œæ¡†çš„ç´¢å¼•ã€‚
    # torch.nonzero æ˜¯ä¸€ä¸ª PyTorch å‡½æ•°ï¼Œç”¨äºè¿”å›ä¸€ä¸ªå¼ é‡ä¸­æ‰€æœ‰éé›¶å…ƒç´ çš„ç´¢å¼•ã€‚
    anc_i = torch.nonzero(max_ious >= iou_threshold).reshape(-1)
    box_j = indices[max_ious >= iou_threshold]
    anchors_bbox_map[anc_i] = box_j
    col_discard = torch.full((num_anchors,), -1)
    row_discard = torch.full((num_gt_boxes,), -1)
   
   for _ in range(num_gt_boxes):
        max_idx = torch.argmax(jaccard)
        box_idx = (max_idx % num_gt_boxes).long()
        anc_idx = (max_idx / num_gt_boxes).long()
        anchors_bbox_map[anc_idx] = box_idx
        jaccard[:, box_idx] = col_discard
        jaccard[anc_idx, :] = row_discard
    
    return anchors_bbox_map
```

#### æ ‡è®°ç±»åˆ«å’Œåç§»é‡

ç±»åˆ«ï¼šä¸çœŸå®è¾¹ç•Œæ¡†ç›¸åŒï¼›å¦‚æœä¸€ä¸ªé”šæ¡†æ²¡æœ‰è¢«åˆ†é…çœŸå®è¾¹ç•Œæ¡†ï¼Œæˆ‘ä»¬åªéœ€å°†é”šæ¡†çš„ç±»åˆ«æ ‡è®°ä¸º*èƒŒæ™¯*ï¼ˆbackgroundï¼‰ã€‚ èƒŒæ™¯ç±»åˆ«çš„é”šæ¡†é€šå¸¸è¢«ç§°ä¸º*è´Ÿç±»*é”šæ¡†ï¼Œå…¶ä½™çš„è¢«ç§°ä¸º*æ­£ç±»*é”šæ¡†ã€‚

åç§»é‡ï¼šé”šæ¡†ğ´çš„åç§»é‡å°†æ ¹æ®ğµå’Œğ´ä¸­å¿ƒåæ ‡çš„ç›¸å¯¹ä½ç½®ä»¥åŠè¿™ä¸¤ä¸ªæ¡†çš„ç›¸å¯¹å¤§å°è¿›è¡Œæ ‡è®°ã€‚ç»™å®šæ¡†ğ´å’Œğµï¼Œä¸­å¿ƒåæ ‡åˆ†åˆ«ä¸º(ğ‘¥ğ‘,ğ‘¦ğ‘)å’Œ(ğ‘¥ğ‘,ğ‘¦ğ‘)ï¼Œå®½åº¦åˆ†åˆ«ä¸ºğ‘¤ğ‘å’Œğ‘¤ğ‘ï¼Œé«˜åº¦åˆ†åˆ«ä¸ºâ„ğ‘å’Œâ„ğ‘ï¼Œå¯ä»¥å°†ğ´çš„åç§»é‡æ ‡è®°ä¸ºï¼š
	![image-20240722155710056](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240722155710056.png)

```
def offset_boxes(anchors, assigned_bb, eps=1e-6):
    """å¯¹é”šæ¡†åç§»é‡çš„è½¬æ¢"""
    c_anc = d2l.box_corner_to_center(anchors)
    c_assigned_bb = d2l.box_corner_to_center(assigned_bb)
    offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]
    offset_wh = 5 * torch.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])
    offset = torch.cat([offset_xy, offset_wh], axis=1)
    return offset
    
def multibox_target(anchors, labels):
    """ä½¿ç”¨çœŸå®è¾¹ç•Œæ¡†æ ‡è®°é”šæ¡†"""
    batch_size, anchors = labels.shape[0], anchors.squeeze(0)
    batch_offset, batch_mask, batch_class_labels = [], [], []
    device, num_anchors = anchors.device, anchors.shape[0]
    for i in range(batch_size):
        label = labels[i, :, :]
        anchors_bbox_map = assign_anchor_to_bbox(
            label[:, 1:], anchors, device)
        bbox_mask = ((anchors_bbox_map >= 0).float().unsqueeze(-1)).repeat(
            1, 4)
        # å°†ç±»æ ‡ç­¾å’Œåˆ†é…çš„è¾¹ç•Œæ¡†åæ ‡åˆå§‹åŒ–ä¸ºé›¶
        class_labels = torch.zeros(num_anchors, dtype=torch.long,
                                   device=device)
        assigned_bb = torch.zeros((num_anchors, 4), dtype=torch.float32,
                                  device=device)
        # ä½¿ç”¨çœŸå®è¾¹ç•Œæ¡†æ¥æ ‡è®°é”šæ¡†çš„ç±»åˆ«ã€‚
        # å¦‚æœä¸€ä¸ªé”šæ¡†æ²¡æœ‰è¢«åˆ†é…ï¼Œæ ‡è®°å…¶ä¸ºèƒŒæ™¯ï¼ˆå€¼ä¸ºé›¶ï¼‰
        indices_true = torch.nonzero(anchors_bbox_map >= 0)
        bb_idx = anchors_bbox_map[indices_true]
        class_labels[indices_true] = label[bb_idx, 0].long() + 1
        assigned_bb[indices_true] = label[bb_idx, 1:]
        # åç§»é‡è½¬æ¢
        offset = offset_boxes(anchors, assigned_bb) * bbox_mask
        batch_offset.append(offset.reshape(-1))
        batch_mask.append(bbox_mask.reshape(-1))
        batch_class_labels.append(class_labels)
    bbox_offset = torch.stack(batch_offset)
    bbox_mask = torch.stack(batch_mask)
    class_labels = torch.stack(batch_class_labels)
    return (bbox_offset, bbox_mask, class_labels)
```

#### ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶é¢„æµ‹è¾¹ç•Œæ¡†

```
def offset_inverse(anchors, offset_preds):
    """æ ¹æ®å¸¦æœ‰é¢„æµ‹åç§»é‡çš„é”šæ¡†æ¥é¢„æµ‹è¾¹ç•Œæ¡†"""
    anc = d2l.box_corner_to_center(anchors)
    pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]
    pred_bbox_wh = torch.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]
    pred_bbox = torch.cat((pred_bbox_xy, pred_bbox_wh), axis=1)
    predicted_bbox = d2l.box_center_to_corner(pred_bbox)
    return predicted_bbox
```

##### **ä»¥ä¸‹`nms`å‡½æ•°æŒ‰é™åºå¯¹ç½®ä¿¡åº¦è¿›è¡Œæ’åºå¹¶è¿”å›å…¶ç´¢å¼•**

```
def nms(boxes, scores, iou_threshold):
    """å¯¹é¢„æµ‹è¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦è¿›è¡Œæ’åº"""
    B = torch.argsort(scores, dim=-1, descending=True)
    keep = []  # ä¿ç•™é¢„æµ‹è¾¹ç•Œæ¡†çš„æŒ‡æ ‡
    while B.numel() > 0:
        i = B[0]
        keep.append(i)
        if B.numel() == 1: break
        iou = box_iou(boxes[i, :].reshape(-1, 4),
                      boxes[B[1:], :].reshape(-1, 4)).reshape(-1)
        inds = torch.nonzero(iou <= iou_threshold).reshape(-1)
        B = B[inds + 1]
    return torch.tensor(keep, device=boxes.device)
```

**å°†éæå¤§å€¼æŠ‘åˆ¶åº”ç”¨äºé¢„æµ‹è¾¹ç•Œæ¡†**

```
def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,pos_threshold=0.009999999):
    """ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶æ¥é¢„æµ‹è¾¹ç•Œæ¡†"""
    device, batch_size = cls_probs.device, cls_probs.shape[0]
    anchors = anchors.squeeze(0)
    num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]
    out = []
    for i in range(batch_size):
        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4)
        conf, class_id = torch.max(cls_prob[1:], 0)
        predicted_bb = offset_inverse(anchors, offset_pred)
        keep = nms(predicted_bb, conf, nms_threshold)

        # æ‰¾åˆ°æ‰€æœ‰çš„non_keepç´¢å¼•ï¼Œå¹¶å°†ç±»è®¾ç½®ä¸ºèƒŒæ™¯
        all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)
        combined = torch.cat((keep, all_idx))
        uniques, counts = combined.unique(return_counts=True)
        non_keep = uniques[counts == 1]
        all_id_sorted = torch.cat((keep, non_keep))
        class_id[non_keep] = -1
        class_id = class_id[all_id_sorted]
        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]
        # pos_thresholdæ˜¯ä¸€ä¸ªç”¨äºéèƒŒæ™¯é¢„æµ‹çš„é˜ˆå€¼
        below_min_idx = (conf < pos_threshold)
        class_id[below_min_idx] = -1
        conf[below_min_idx] = 1 - conf[below_min_idx]
        pred_info = torch.cat((class_id.unsqueeze(1),
                               conf.unsqueeze(1),
                               predicted_bb), dim=1)
        out.append(pred_info)
    return torch.stack(out)
```





## ç‰©ä½“æ£€æµ‹ç®—æ³•ï¼šRCNN,SSD,YOLO

### åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œ

#### R-CNN

- ä½¿ç”¨å¯å‘å¼æœç´¢ç®—æ³•æ¥é€‰æ‹©é”šæ¡†
- ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ¥å¯¹æ¯ä¸ªé”šæ¡†æŠ½å–ç‰¹å¾ï¼ˆæ¯ä¸ªé”šæ¡†å½“ä½œä¸€ä¸ªå›¾ç‰‡ï¼Œç”¨CNNï¼‰
- è®­ç»ƒä¸€ä¸ªSVMæ¥ç±»åˆ«åˆ†ç±»ï¼ˆç¥ç»ç½‘ç»œä¹‹å‰ï¼Œcategory predictionï¼‰
- è®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹æ¥é¢„æµ‹è¾¹ç¼˜æ¡†åç§»ï¼ˆbounding box predictionï¼‰
- **å…´è¶£åŒºåŸŸï¼ˆRolï¼‰æ± åŒ–å±‚**ï¼ˆæœ‰åˆ©äºå°ºå¯¸æ ‡å‡†åŒ–ï¼›å¹¶æ‰¹é‡å¤„ç†ï¼‰
  - ç»™å®šä¸€ä¸ªé”šæ¡†ï¼Œ**å‡åŒ€åˆ†å‰²**ï¼ˆå¦‚æœæ²¡æ³•å‡åŒ€åˆ†å‰²ï¼Œå–æ•´ï¼‰æˆ n x m å—ï¼Œ**è¾“å‡ºæ¯å—çš„æœ€å¤§å€¼**ï¼ˆmax poolingï¼‰
  - ä¸ç®¡é”šæ¡†å¤šå¤§ï¼Œæ€»æ˜¯è¾“å‡ºnmä¸ªå€¼
  - ç›®çš„ï¼šæ¯ä¸ªé”šæ¡†éƒ½å¯ä»¥å˜æˆæƒ³è¦çš„å½¢çŠ¶

#### Fast RCNN

- ä½¿ç”¨CNNå¯¹**æ•´å¼ å›¾ç‰‡åšå·ç§¯å±‚ï¼Œç„¶ååˆ©ç”¨Rolæ± åŒ–å±‚æŠ½å–ç‰¹å¾**ï¼ˆå¿«çš„å…³é”®ï¼‰

- ä½¿ç”¨Rolæ± åŒ–å±‚å¯¹æ¯ä¸ªé”šæ¡†ï¼ˆå°†åœ¨åŸå›¾ç‰‡ä¸­æœç´¢åˆ°çš„é”šæ¡†ï¼Œæ˜ å°„åˆ°CNNå¾—åˆ°çš„ç»“æœä¸Šï¼‰ï¼Œç”Ÿæˆå›ºå®šé•¿åº¦çš„ç‰¹å¾

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/44/44-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/44/44-01.png)

#### Faster RCNN

- ä½¿ç”¨ä¸€ä¸ª **åŒºåŸŸææ¡ˆç½‘ç»œï¼ˆRPNï¼‰æ¥æ›¿ä»£å¯å‘å¼æœç´¢è·å¾—æ›´å¥½çš„é”šæ¡†**

  RPN æ˜¯ Faster R-CNN çš„æ ¸å¿ƒï¼Œç”¨äºå®æ—¶ç”Ÿæˆé«˜è´¨é‡çš„åŒºåŸŸææ¡ˆã€‚å®ƒæ˜¯ä¸€ä¸ªå…¨å·ç§¯ç½‘ç»œï¼Œå¯ä»¥åŒæ—¶é¢„æµ‹è¾¹ç•Œæ¡†ä½ç½®å’Œå¯¹è±¡å­˜åœ¨çš„åˆ†æ•°ã€‚

  RPN ä½¿ç”¨äº†ä¸€ç»„é¢„å®šä¹‰çš„é”šæ¡†ï¼ˆanchorsï¼‰ï¼Œè¿™äº›é”šæ¡†å…·æœ‰ä¸åŒçš„å°ºå¯¸å’Œå®½é«˜æ¯”ã€‚RPN è¯„ä¼°æ¯ä¸ªé”šæ¡†æ˜¯å¦åŒ…å«å¯¹è±¡ï¼Œå¹¶è°ƒæ•´å…¶ä½ç½®ï¼ˆé€šè¿‡è¾¹ç•Œæ¡†å›å½’ï¼‰ä»¥æ›´å¥½åœ°åŒ¹é…æ½œåœ¨å¯¹è±¡ã€‚

- å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå°†CNNç»“æœè¾“å…¥åˆ°å·ç§¯å±‚ï¼Œç„¶åç”¨é”šæ¡†å»åœˆåŒºåŸŸï¼Œè¿™äº›é”šæ¡†æœ‰å¥½æœ‰åï¼Œç„¶åè¿›è¡Œé¢„æµ‹ï¼Œbinary é¢„æµ‹æ˜¯é¢„æµ‹è¿™ä¸ªé”šæ¡†çš„å¥½åï¼Œå³æœ‰æ²¡æœ‰æœ‰æ•ˆçš„åœˆä½ç‰©ä½“ï¼Œbounding box predictioné¢„æµ‹æ˜¯å¯¹é”šæ¡†è¿›è¡Œä¸€äº›æ”¹è¿›ï¼Œæœ€åç”¨NMSï¼ˆéæå¤§å€¼æŠ‘åˆ¶ï¼‰å¯¹é”šæ¡†è¿›è¡Œåˆå¹¶ã€‚

- å…·ä½“æ¥è¯´ï¼ŒåŒºåŸŸæè®®ç½‘ç»œçš„è®¡ç®—æ­¥éª¤å¦‚ä¸‹ï¼š

  1. ä½¿ç”¨å¡«å……ä¸º1çš„3Ã—3çš„å·ç§¯å±‚ï¼ˆä¿æŒè¾“å…¥è¾“å‡ºçš„å®½é«˜ä¸å˜ï¼‰å˜æ¢å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å‡ºï¼Œå¹¶å°†è¾“å‡ºé€šé“æ•°è®°ä¸ºcã€‚è¿™æ ·ï¼Œå·ç§¯ç¥ç»ç½‘ç»œä¸ºå›¾åƒæŠ½å–çš„ç‰¹å¾å›¾ä¸­çš„æ¯ä¸ªå•å…ƒå‡å¾—åˆ°ä¸€ä¸ªé•¿åº¦ä¸ºcçš„æ–°ç‰¹å¾ã€‚
  2. ä»¥ç‰¹å¾å›¾çš„æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒï¼Œç”Ÿæˆå¤šä¸ªä¸åŒå¤§å°å’Œå®½é«˜æ¯”çš„é”šæ¡†å¹¶æ ‡æ³¨å®ƒä»¬ã€‚
  3. ä½¿ç”¨é”šæ¡†ä¸­å¿ƒå•å…ƒé•¿åº¦ä¸ºcçš„ç‰¹å¾ï¼Œåˆ†åˆ«é¢„æµ‹è¯¥é”šæ¡†çš„äºŒå…ƒç±»åˆ«ï¼ˆå«ç›®æ ‡è¿˜æ˜¯èƒŒæ™¯ï¼‰å’Œè¾¹ç•Œæ¡†ã€‚
  4. ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶ï¼Œä»é¢„æµ‹ç±»åˆ«ä¸ºç›®æ ‡çš„é¢„æµ‹è¾¹ç•Œæ¡†ä¸­ç§»é™¤ç›¸ä¼¼çš„ç»“æœã€‚æœ€ç»ˆè¾“å‡ºçš„é¢„æµ‹è¾¹ç•Œæ¡†å³æ˜¯å…´è¶£åŒºåŸŸæ±‡èšå±‚æ‰€éœ€çš„æè®®åŒºåŸŸã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/44/44-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/44/44-02.png)

#### Mask RCNN

åƒç´ çº§çš„å¯¹è±¡åˆ†å‰²

- å¦‚æœæœ‰**åƒç´ çº§åˆ«çš„æ ‡å·**ï¼Œä½¿ç”¨FCNï¼ˆfully convolutional networkï¼‰åˆ©ç”¨è¿™äº›ä¿¡æ¯ã€‚å¯ä»¥æå‡CNNçš„æ€§èƒ½

- **Rol align**ã€‚è§£å†³äº† Faster R-CNN ä¸­ RoI Pooling å±‚çš„å¯¹é½é—®é¢˜ã€‚RoI Pooling åœ¨æŠ½æ ·è¿‡ç¨‹ä¸­å¯¹è¾“å…¥è¿›è¡Œäº†é‡åŒ–ï¼ˆå³å››èˆäº”å…¥ï¼‰ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´è¾¹ç•Œæ¡†å’Œå®é™…ç‰¹å¾ä¹‹é—´çš„è½»å¾®é”™ä½ã€‚RoIAlign é€šè¿‡ä½¿ç”¨**åŒçº¿æ€§æ’å€¼**æ¥ç²¾ç¡®åœ°è®¡ç®—è¾“å…¥ç‰¹å¾å›¾ä¸Šä»»æ„ä½ç½®çš„å€¼ï¼Œä»è€Œä¿è¯äº†ç‰¹å¾çš„ç²¾ç¡®å¯¹é½ã€‚

- åŒçº¿æ€§æ’å€¼ï¼š

  åŒçº¿æ€§æ’å€¼çš„åŸºæœ¬æ€æƒ³æ˜¯**åœ¨ä¸¤ä¸ªæ–¹å‘ä¸Šè¿›è¡Œçº¿æ€§æ’å€¼**ã€‚å‡è®¾æˆ‘ä»¬éœ€è¦åœ¨ä¸€ä¸ªç»™å®šçš„å›¾åƒä¸Šæ‰¾åˆ°ä¸€ä¸ªéæ•´æ•°åæ ‡ï¼ˆx, yï¼‰å¤„çš„åƒç´ å€¼ã€‚**å‘¨å›´çš„å››ä¸ªæœ€è¿‘çš„æ•´æ•°åƒç´ ç‚¹ï¼ˆé€šå¸¸æ˜¯è¿™ä¸ªç‚¹çš„å››ä¸ªè§’è½ï¼‰å°†è¢«ç”¨äºè®¡ç®—è¿™ä¸ªç‚¹çš„åƒç´ å€¼ã€‚**

  è®¾è¿™å››ä¸ªç‚¹ä¸ºï¼š

  - Q11=(x1,y1)
  - Q12=(x1,y2)
  - Q21=(x2,y1)
  - Q22=(x2,y2)

  å¹¶ä¸”å¯¹åº”çš„åƒç´ å€¼ä¸º f(Q11),f(Q12),f(Q21),f(Q22)

  ä¸ºäº†åœ¨ç‚¹ (x,y)å¤„è¿›è¡Œæ’å€¼ï¼ŒåŒçº¿æ€§æ’å€¼é€šè¿‡ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š

  1. **æ°´å¹³æ–¹å‘çš„çº¿æ€§æ’å€¼**ï¼š

     - å¯¹ y1è¡Œè¿›è¡Œæ’å€¼å¾—åˆ°

       R1=f(Q11)Ã—(x2âˆ’x)+f(Q21)Ã—(xâˆ’x1)

     - å¯¹ y2è¡Œè¿›è¡Œæ’å€¼å¾—åˆ° ï¼š

       R2=f(Q12)Ã—(x2âˆ’x)+f(Q22)Ã—(xâˆ’x1)

  2. **å‚ç›´æ–¹å‘çš„çº¿æ€§æ’å€¼**ï¼š

     - ä½¿ç”¨ R1å’Œ R2å¯¹ y è¿›è¡Œæ’å€¼

       P=R1Ã—(y2âˆ’y)+R2Ã—(yâˆ’y1)

  è¿™é‡Œçš„ På°±æ˜¯ç‚¹ (x,y)(x, y)(x,y) å¤„çš„æ’å€¼ç»“æœã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/44/44-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/44/44-03.png)

#### æ€»ç»“

- R-CNNæ˜¯æœ€æ—©ä¹Ÿæ˜¯æœ€æœ‰åçš„ä¸€ç±»åŸºäºé”šæ¡†å’ŒCNNçš„ç›®æ ‡æ£€æµ‹ç®—æ³•
- Fast/Faster RCNN æŒç»­æå‡æ€§èƒ½
- Faster RCNNå’ŒMask RCNNæ˜¯åœ¨è¦æ±‚é«˜ç²¾åº¦åœºæ™¯ä¸‹å¸¸ç”¨çš„ç®—æ³•ï¼ˆä½†æ˜¯é€Ÿåº¦æ˜¯æœ€æ…¢çš„ï¼‰

### å•å‘å¤šæ¡†æ£€æµ‹ï¼ˆSSD single shot detectionï¼‰

- ç”Ÿæˆé”šæ¡†
  - å¯¹æ¯ä¸ªåƒç´ ï¼Œç”Ÿæˆå¤šä¸ªä»¥å®ƒä¸ºä¸­å¿ƒçš„é”šæ¡†
  - ç»™å®š n ä¸ªå¤§å°$s_1,...,s_n$å’Œmä¸ªé«˜å®½æ¯”ï¼Œç”Ÿæˆn+m-1ä¸ªé”šæ¡†ï¼Œå…¶å¤§å°å’Œé«˜å®½æ¯”åˆ†åˆ«ä¸ºï¼š$(s_1,r_1),(s_2,r_1)...,(s_n,r_1),(s_1,r_2),...,(s_1,r_m)$
- SSDæ¨¡å‹
  - å¯¹å¤šä¸ªåˆ†è¾¨ç‡ä¸‹(ä»åŸºç¡€ç½‘ç»œä¸­çš„å¤šä¸ªå±‚ä¸Šæå–ç‰¹å¾å›¾ï¼Œç”¨ä»¥æ£€æµ‹ä¸åŒå°ºå¯¸çš„å¯¹è±¡ã€‚æ¯ä¸€å±‚çš„ç‰¹å¾å›¾éƒ½ä¼šè¢«ç”¨æ¥é¢„æµ‹å¯¹è±¡çš„ç±»åˆ«å’Œä½ç½®)çš„å·ç§¯ç‰¹å¾ï¼Œç”Ÿæˆé”šæ¡†ï¼Œé¢„æµ‹
  - åˆ†è¾¨ç‡ï¼šåœ¨åŸºç¡€ç¥ç»ç½‘ç»œä¸­ï¼Œæ¯ä¸€å±‚çš„è¾“å‡ºå…·æœ‰ä¸åŒçš„ç©ºé—´åˆ†è¾¨ç‡ï¼Œè¶Šæ¥è¿‘è¾“å…¥å±‚çš„åˆ†è¾¨ç‡è¶Šé«˜ï¼ˆæ›´ç»†ç²’åº¦çš„ä¿¡æ¯ï¼‰ï¼Œè¶Šæ¥è¿‘è¾“å‡ºå±‚çš„åˆ†è¾¨ç‡è¶Šä½ï¼›
  - ç‰¹å¾å›¾çš„ä½¿ç”¨ï¼šä½å±‚ç‰¹å¾å›¾ï¼Œå…·æœ‰è¾ƒé«˜åˆ†è¾¨ç‡ï¼Œé€‚åˆç”¨æ¥æ£€æµ‹å°ç‰©ä½“ï¼›åä¹‹ã€‚
  - ä¸€ä¸ªåŸºç¡€ç½‘ç»œï¼ŒæŠ½å–ç‰¹å¾ï¼ˆä¸æ˜¯æ‰€æœ‰å±‚éƒ½ä¼šè¢«ç”¨åˆ°ï¼‰ï¼Œç„¶åç”¨å¤šä¸ªå·ç§¯å±‚æ¥å‡åŠé«˜å®½
  - åœ¨æ¯æ®µéƒ½ç”Ÿæˆé”šæ¡†
    - åº•éƒ¨æ®µæ‹Ÿåˆå°ç‰©ä½“
    - é¡¶éƒ¨æ®µæ‹Ÿåˆå¤§ç‰©ä½“
  - å¯¹æ¯ä¸ªé”šæ¡†é¢„æµ‹ç±»åˆ«å’Œè¾¹ç¼˜æ¡†

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/44/44-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/44/44-04.png)

#### æ€»ç»“

- é€Ÿåº¦å¿«ï¼Œç²¾åº¦å¾ˆä½ã€‚è¿™ä¹ˆå¤šå¹´ï¼Œä½œè€…æ²¡æœ‰æŒç»­çš„æå‡ï¼Œä½†æ˜¯å¯å‘äº†åé¢çš„ä¸€ç³»åˆ—å·¥ä½œï¼Œå®ç°ä¸Šç›¸å¯¹æ¯”è¾ƒç®€å•ã€‚
- SSDé€šè¿‡å•ç¥ç»ç½‘ç»œæ¥æ£€æµ‹æ¨¡å‹ï¼ˆsingle shotï¼‰
- ä»¥åƒç´ ä¸ºä¸­å¿ƒçš„äº§ç”Ÿå¤šä¸ªé”šæ¡†
- åœ¨å¤šä¸ªæ®µçš„è¾“å‡ºä¸Šè¿›è¡Œå¤šå°ºåº¦çš„æ£€æµ‹

### YOLOï¼ˆyou only look onceï¼‰

- YOLOå°†å›¾ç‰‡å‡åˆ†ä¸º S X S ä¸ªé”šæ¡†
- æ¯ä¸ªé”šæ¡†é¢„æµ‹ B ä¸ªè¾¹ç¼˜æ¡†ï¼ˆé˜²æ­¢å¤šä¸ªç‰©ä½“å‡ºç°åœ¨ä¸€ä¸ªé”šæ¡†é‡Œé¢ï¼‰
- åç»­ç‰ˆæœ¬ v2 v3 v4 æœ‰æŒç»­æ”¹è¿›
- éé”šæ¡†ç®—æ³•

### SSDä»£ç å®ç°

##### æ¨¡å‹

å›æƒ³ä¸€ä¸‹åœ¨ :numref:`sec_multiscale-object-detection`ä¸­ï¼Œé€šè¿‡æ·±åº¦ç¥ç»ç½‘ç»œåˆ†å±‚è¡¨ç¤ºå›¾åƒçš„å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹çš„è®¾è®¡ã€‚ ç”±äºæ¥è¿‘ :numref:`fig_ssd`é¡¶éƒ¨çš„å¤šå°ºåº¦ç‰¹å¾å›¾è¾ƒå°ï¼Œä½†å…·æœ‰è¾ƒå¤§çš„æ„Ÿå—é‡ï¼Œå®ƒä»¬é€‚åˆæ£€æµ‹è¾ƒå°‘ä½†è¾ƒå¤§çš„ç‰©ä½“ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œ**é€šè¿‡å¤šå°ºåº¦ç‰¹å¾å—ï¼Œå•å‘å¤šæ¡†æ£€æµ‹ç”Ÿæˆä¸åŒå¤§å°çš„é”šæ¡†**ï¼Œå¹¶é€šè¿‡**é¢„æµ‹è¾¹ç•Œæ¡†çš„ç±»åˆ«å’Œåç§»é‡æ¥æ£€æµ‹å¤§å°ä¸åŒçš„ç›®æ ‡**ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªå¤šå°ºåº¦ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚

![image-20240724162125469](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240724162125469.png)

åœ¨ä¸‹é¢ï¼Œæˆ‘ä»¬å°†ä»‹ç» :numref:`fig_ssd`ä¸­ä¸åŒå—çš„å®æ–½ç»†èŠ‚ã€‚ é¦–å…ˆï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦‚ä½•å®æ–½ç±»åˆ«å’Œè¾¹ç•Œæ¡†é¢„æµ‹ã€‚

##### **ç±»åˆ«é¢„æµ‹å±‚**

å…·ä½“æ¥è¯´ï¼Œç±»åˆ«é¢„æµ‹å±‚ä½¿ç”¨ä¸€ä¸ªä¿æŒè¾“å…¥é«˜å’Œå®½çš„å·ç§¯å±‚ã€‚ è¿™æ ·ä¸€æ¥ï¼Œè¾“å‡ºå’Œè¾“å…¥åœ¨ç‰¹å¾å›¾å®½å’Œé«˜ä¸Šçš„ç©ºé—´åæ ‡ä¸€ä¸€å¯¹åº”ã€‚ è€ƒè™‘è¾“å‡ºå’Œè¾“å…¥åŒä¸€ç©ºé—´åæ ‡ï¼ˆğ‘¥ã€ğ‘¦ï¼‰ï¼šè¾“å‡ºç‰¹å¾å›¾ä¸Šï¼ˆğ‘¥ã€ğ‘¦ï¼‰åæ ‡çš„é€šé“é‡ŒåŒ…å«äº†ä»¥è¾“å…¥ç‰¹å¾å›¾ï¼ˆğ‘¥ã€ğ‘¦ï¼‰åæ ‡ä¸ºä¸­å¿ƒç”Ÿæˆçš„æ‰€æœ‰é”šæ¡†çš„ç±»åˆ«é¢„æµ‹ã€‚ å› æ­¤è¾“å‡ºé€šé“æ•°ä¸ºğ‘(ğ‘+1)ï¼Œå…¶ä¸­ç´¢å¼•ä¸º**ğ‘–(ğ‘+1)+ğ‘—ï¼ˆ0â‰¤ğ‘—â‰¤ğ‘ï¼‰çš„é€šé“ä»£è¡¨äº†ç´¢å¼•ä¸ºğ‘–çš„é”šæ¡†æœ‰å…³ç±»åˆ«ç´¢å¼•ä¸ºğ‘—çš„é¢„æµ‹**ã€‚

- ä¿ç•™ç©ºé—´ä¿¡æ¯

- å°†é€šé“å¯¹åº”ä¸ºé”šæ¡†ä¿¡æ¯

ä¸‹é¢ï¼Œæˆ‘ä»¬å®šä¹‰äº†è¿™æ ·ä¸€ä¸ªç±»åˆ«é¢„æµ‹å±‚ï¼Œé€šè¿‡å‚æ•°`num_anchors`å’Œ`num_classes`åˆ†åˆ«æŒ‡å®šäº†ğ‘å’Œğ‘ã€‚ è¯¥å›¾å±‚ä½¿ç”¨å¡«å……ä¸º1çš„3Ã—3çš„å·ç§¯å±‚ï¼ˆä¿æŒé«˜å®½ä¸å˜ï¼‰ã€‚æ­¤å·ç§¯å±‚çš„è¾“å…¥å’Œè¾“å‡ºçš„å®½åº¦å’Œé«˜åº¦ä¿æŒä¸å˜ã€‚

```
import torch
import torchvision
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

# num_inputsæ˜¯è¾“å…¥çš„é€šé“æ•°
def cls_predictors(
	num_inputs,num_anchors,num_classes):
	return nn.Conv2d(
	num_inputs,(num_classes+1)*num_anchors,
	kernel_size=3,padding=1) 
```

##### **è¾¹ç•Œæ¡†é¢„æµ‹å±‚**

è¾¹ç•Œæ¡†é¢„æµ‹å±‚çš„è®¾è®¡ä¸ç±»åˆ«é¢„æµ‹å±‚çš„è®¾è®¡ç±»ä¼¼ã€‚ å”¯ä¸€ä¸åŒçš„æ˜¯ï¼Œè¿™é‡Œéœ€è¦ä¸ºæ¯ä¸ªé”šæ¡†é¢„æµ‹4ä¸ªåç§»é‡ï¼Œè€Œä¸æ˜¯ğ‘+1ä¸ªç±»åˆ«ã€‚

###### ä¸ºä»€ä¹ˆæ˜¯ `num_anchors * 4`ï¼Ÿ

åœ¨ç›®æ ‡æ£€æµ‹ä¸­ï¼Œå½“é¢„æµ‹è¾¹ç•Œæ¡†ï¼ˆbounding boxesï¼‰æ—¶ï¼Œæ¯ä¸ªé”šæ¡†éœ€è¦é¢„æµ‹4ä¸ªå€¼ï¼šè¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ (x, y)ã€å®½åº¦å’Œé«˜åº¦ã€‚å› æ­¤ï¼Œå¦‚æœä½ æœ‰`num_anchors`ä¸ªé”šæ¡†ï¼Œæ¯ä¸ªéƒ½éœ€è¦é¢„æµ‹4ä¸ªå€¼ï¼Œé‚£ä¹ˆæ€»å…±å°±æ˜¯ `num_anchors * 4` ä¸ªè¾“å‡ºã€‚

```
def bbox_predictors(num_inputs,num_anchors):
	return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)
```

##### **è¿ç»“å¤šå°ºåº¦çš„é¢„æµ‹**

æ­£å¦‚æˆ‘ä»¬æ‰€æåˆ°çš„ï¼Œå•å‘å¤šæ¡†æ£€æµ‹ä½¿ç”¨å¤šå°ºåº¦ç‰¹å¾å›¾æ¥ç”Ÿæˆé”šæ¡†å¹¶é¢„æµ‹å…¶ç±»åˆ«å’Œåç§»é‡ã€‚ åœ¨ä¸åŒçš„å°ºåº¦ä¸‹ï¼Œç‰¹å¾å›¾çš„å½¢çŠ¶æˆ–ä»¥åŒä¸€å•å…ƒä¸ºä¸­å¿ƒçš„é”šæ¡†çš„æ•°é‡å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚ å› æ­¤ï¼Œä¸åŒå°ºåº¦ä¸‹é¢„æµ‹è¾“å‡ºçš„å½¢çŠ¶å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚

**æœ¬è´¨å°±æ˜¯ç”±äºé”šæ¡†ä¸ä¸€è‡´ï¼Œå¯¼è‡´å°ºå¯¸ä¸ä¸€è‡´**

**è§£å†³æ–¹æ³•**ï¼šå°†é€šé“ç»´ç§»åˆ°æœ€åä¸€ç»´ã€‚ç”±äºä¸åŒå°ºåº¦ä¸‹æ‰¹é‡å¤§å°ä¸å˜ï¼Œæˆ‘ä»¬å°†é¢„æµ‹ç»“æœè½¬å˜æˆäºŒç»´çš„ï¼ˆæ‰¹é‡å¤§å°ï¼Œé«˜Ã—å®½Ã—é€šé“æ•°ï¼‰çš„æ ¼å¼ã€‚

```
# åŸç†è§£æ:åœ¨è°ƒç”¨ permute(0,2,3,1) çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ¥é€ä¸ªè§£é‡Šæ¯ä¸ªå‚æ•°çš„å«ä¹‰ï¼š
# 0: è¿™è¡¨ç¤ºåŸå§‹å¼ é‡çš„ç¬¬ä¸€ä¸ªç»´åº¦ï¼ˆbatch_sizeï¼‰å°†ä¿æŒåœ¨ç¬¬ä¸€ä¸ªä½ç½®ã€‚
# 2: è¿™è¡¨ç¤ºåŸå§‹å¼ é‡çš„ç¬¬ä¸‰ä¸ªç»´åº¦ï¼ˆheightï¼‰å°†ç§»åŠ¨åˆ°æ–°é¡ºåºçš„ç¬¬äºŒä¸ªä½ç½®ã€‚

# start_dim=1 æŒ‡çš„æ˜¯ä»å¼ é‡çš„ç¬¬äºŒä¸ªç»´åº¦ï¼ˆå³ç´¢å¼•ä¸º1çš„ç»´åº¦ï¼Œå¯¹äºæ’åˆ—åçš„ (batch_size, height, width, channels) æ˜¯ heightï¼‰å¼€å§‹å±•å¹³ç›´åˆ°æœ€åä¸€ä¸ªç»´åº¦ã€‚

def flatten_pred(pred):
	return torch.flatten(pred.permute(0,2,3,1),start_dim=1)
	
def concat_pred(preds):
	return torch.cat([flatten_pred(p) for p in preds],dim=1)
```

##### **é«˜å’Œå®½å‡åŠå—**

ä¸ºäº†åœ¨å¤šä¸ªå°ºåº¦ä¸‹æ£€æµ‹ç›®æ ‡ï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢å®šä¹‰äº†é«˜å’Œå®½å‡åŠå—`down_sample_blk`ï¼Œè¯¥æ¨¡å—å°†è¾“å…¥ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦å‡åŠã€‚ äº‹å®ä¸Šï¼Œè¯¥å—åº”ç”¨äº†åœ¨ :numref:`subsec_vgg-blocks`ä¸­çš„VGGæ¨¡å—è®¾è®¡ã€‚ æ›´å…·ä½“åœ°è¯´ï¼Œæ¯ä¸ªé«˜å’Œå®½å‡åŠå—ç”±ä¸¤ä¸ªå¡«å……ä¸º1çš„3Ã—3çš„å·ç§¯å±‚ã€ä»¥åŠæ­¥å¹…ä¸º2çš„2Ã—2æœ€å¤§æ±‡èšå±‚ç»„æˆã€‚ æˆ‘ä»¬çŸ¥é“ï¼Œå¡«å……ä¸º1çš„3Ã—3å·ç§¯å±‚ä¸æ”¹å˜ç‰¹å¾å›¾çš„å½¢çŠ¶ã€‚ä½†æ˜¯ï¼Œå…¶åçš„2Ã—2çš„æœ€å¤§æ±‡èšå±‚å°†è¾“å…¥ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦å‡å°‘äº†ä¸€åŠã€‚ å¯¹äºæ­¤é«˜å’Œå®½å‡åŠå—çš„è¾“å…¥å’Œè¾“å‡ºç‰¹å¾å›¾ï¼Œå› ä¸º1Ã—2+(3âˆ’1)+(3âˆ’1)=6ï¼Œæ‰€ä»¥è¾“å‡ºä¸­çš„æ¯ä¸ªå•å…ƒåœ¨è¾“å…¥ä¸Šéƒ½æœ‰ä¸€ä¸ª6Ã—6çš„æ„Ÿå—é‡ã€‚å› æ­¤ï¼Œé«˜å’Œå®½å‡åŠå—ä¼šæ‰©å¤§æ¯ä¸ªå•å…ƒåœ¨å…¶è¾“å‡ºç‰¹å¾å›¾ä¸­çš„æ„Ÿå—é‡ã€‚

**å°±æ˜¯åˆ©ç”¨VGGé‡Œé¢çš„max_poolingå»ä½¿å¾—é«˜å®½å‡åŠ**

```
def down_sample_blk(in_channels,out_channels):
	blk=[]
	for _ in range(2):
		blk.append(nn.Conv2d(in_channels,
	out_channels,kernel_size=2,padding=1))
		blk.append(nn.BatchNorm2d(
					out_channels))
        blk.append(nn.ReLU())
        in_channels = out_channels
    blk.append(nn.MaxPool2d(2))
    return nn.sequential(*blk)
```

##### åŸºæœ¬ç½‘ç»œå—

åŸºæœ¬ç½‘ç»œå—ç”¨äºä»è¾“å…¥å›¾åƒä¸­æŠ½å–ç‰¹å¾ã€‚ ä¸ºäº†è®¡ç®—ç®€æ´ï¼Œæˆ‘ä»¬æ„é€ äº†ä¸€ä¸ªå°çš„åŸºç¡€ç½‘ç»œï¼Œè¯¥ç½‘ç»œä¸²è”3ä¸ªé«˜å’Œå®½å‡åŠå—ï¼Œå¹¶é€æ­¥å°†é€šé“æ•°ç¿»å€ã€‚

**èå…¥ä¸Šé¢è®²çš„é«˜å®½å‡åŠï¼Œè¿™æ¬¡åŠ è¿›å»é€šé“ç¿»å€**

```
def base_net():
	blk=[]
	# æ¯ä¸€å±‚çš„å·ç§¯æ ¸çš„æ•°é‡,ä¹Ÿå°±æ˜¯æ¯ä¸€å±‚çš„è¾“å…¥é€šé“å’Œè¾“å…¥é€šé“
	num_filters = [3, 16, 32, 64]
	for i in range(len(num_filters)-1):
		blk.append(down_sample_blk(num_filters[i],num_filters[i+1]))
		return nn.sequential(*blk)
```

##### å®Œæ•´çš„æ¨¡å‹

[**å®Œæ•´çš„å•å‘å¤šæ¡†æ£€æµ‹æ¨¡å‹ç”±äº”ä¸ªæ¨¡å—ç»„æˆ**]ã€‚æ¯ä¸ªå—ç”Ÿæˆçš„ç‰¹å¾å›¾**æ—¢ç”¨äºç”Ÿæˆé”šæ¡†**ï¼Œåˆç”¨äº**é¢„æµ‹è¿™äº›é”šæ¡†çš„ç±»åˆ«å’Œåç§»é‡**ã€‚

åœ¨è¿™äº”ä¸ªæ¨¡å—ä¸­ï¼Œ

ç¬¬ä¸€ä¸ªæ˜¯åŸºæœ¬ç½‘ç»œå—ï¼Œ

ç¬¬äºŒä¸ªåˆ°ç¬¬å››ä¸ªæ˜¯é«˜å’Œå®½å‡åŠå—ï¼Œ

æœ€åä¸€ä¸ªæ¨¡å—ä½¿ç”¨å…¨å±€æœ€å¤§æ± å°†é«˜åº¦å’Œå®½åº¦éƒ½é™åˆ°1ã€‚

ä»æŠ€æœ¯ä¸Šè®²ï¼Œç¬¬äºŒåˆ°ç¬¬äº”ä¸ªåŒºå—éƒ½æ˜¯ :numref:`fig_ssd`ä¸­çš„å¤šå°ºåº¦ç‰¹å¾å—ã€‚

```
# è¿™é‡Œå¯ä¾›é€‰æ‹©ä¸åŒçš„ç½‘ç»œå¿«
def get_blk(i):
    if i == 0:
        blk = base_net()
    elif i == 1:
        blk = down_sample_blk(64, 128)
    elif i == 4:
        blk = nn.AdaptiveMaxPool2d((1,1))
    else:
    	# è¿™ä¸ªåœ°æ–¹çš„é€šé“ä¸å†è¿›è¡Œæ”¹å˜ï¼Œè€Œæ˜¯è¿›è¡Œç©ºé—´ä¸Šçš„å‹ç¼©
        blk = down_sample_blk(128, 128)
    return blk
```

**ä¸ºæ¯ä¸ªå—å®šä¹‰å‰å‘ä¼ æ’­**

è¾“å‡ºåŒ…æ‹¬ï¼šCNNç‰¹å¾å›¾`Y`ï¼›

åœ¨å½“å‰å°ºåº¦ä¸‹æ ¹æ®`Y`ç”Ÿæˆçš„é”šæ¡†ï¼›

é¢„æµ‹çš„è¿™äº›é”šæ¡†çš„ç±»åˆ«å’Œåç§»é‡ï¼ˆåŸºäº`Y`ï¼‰

```
def blk_forward(X,blk,size,ratio,cls_predictor,bbox_predictor):
	Y = blk(X)multibox_prior(Y, sizes=size, ratios=ratio)
	anchor = d2l.multibox_prior(Y, sizes=size, ratios=ratio)
	cls_preds = cls_predictor(Y)
    bbox_preds = bbox_predictor(Y)
    return (Y, anchors, cls_preds, bbox_preds)
```

ç°åœ¨ï¼Œæˆ‘ä»¬å°±å¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼[**å®šä¹‰å®Œæ•´çš„æ¨¡å‹**]`TinySSD`äº†ã€‚

##### TinySSD

```python
class TinySSD(nn.Module):
    def __init__(self, num_classes, **kwargs):
        super(TinySSD, self).__init__(**kwargs)
        self.num_classes = num_classes
        idx_to_in_channels = [64, 128, 128, 128, 128]
        for i in range(5):
            # å³èµ‹å€¼è¯­å¥self.blk_i=get_blk(i)
            
            '''
åœ¨Pythonä¸­ï¼Œsetattr() å‡½æ•°ç”¨äºè®¾ç½®å¯¹è±¡çš„å±æ€§ã€‚å…¶é€šå¸¸æ ¼å¼ä¸º setattr(object, name, value)ï¼Œå…¶ä¸­ object æ˜¯éœ€è¦è®¾ç½®å±æ€§çš„å¯¹è±¡ï¼Œname æ˜¯è¦è®¾ç½®çš„å±æ€§åç§°ï¼ˆä½œä¸ºå­—ç¬¦ä¸²ï¼‰ï¼Œè€Œ value æ˜¯å±æ€§å€¼ã€‚
			'''
			
            setattr(self, f'blk_{i}', get_blk(i))
            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i],                                     num_anchors, num_classes))
            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i],num_anchors))

    def forward(self, X):
        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5
        for i in range(5):
            # getattr(self,'blk_%d'%i)å³è®¿é—®self.blk_i
            X, anchors[i], cls_preds[i], bbox_preds[i] = 	blk_forward(X, getattr(self, f'blk_{i}'), sizes[i], ratios[i],getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}'))
        anchors = torch.cat(anchors, dim=1)
        cls_preds = concat_preds(cls_preds)
        
        '''Class predictions are reshaped to ensure the final output has a dimension of [batch_size, num_predictions, num_classes + 1]'''
        cls_preds = cls_preds.reshape(
            cls_preds.shape[0], -1, self.num_classes + 1)
        bbox_preds = concat_preds(bbox_preds)
        return anchors, cls_preds, bbox_preds
```

##### è®­ç»ƒæ¨¡å‹

- ###### è¯»å–æ•°æ®é›†å’Œåˆå§‹åŒ–

- ###### **å®šä¹‰æŸå¤±å‡½æ•°å’Œè¯„ä»·å‡½æ•°**

- ###### **è®­ç»ƒæ¨¡å‹**

- ###### **é¢„æµ‹ç›®æ ‡**

- ###### **ç­›é€‰æ‰€æœ‰ç½®ä¿¡åº¦ä¸ä½äº0.9çš„è¾¹ç•Œæ¡†ï¼Œåšä¸ºæœ€ç»ˆè¾“å‡º**

```
###### è¯»å–æ•°æ®é›†å’Œåˆå§‹åŒ–
# åˆå§‹åŒ–å†…å®¹åŒ…æ‹¬æ‰¹é‡å¤§å°/è®¾å¤‡/ç½‘ç»œç±»å‹/ä¼˜åŒ–ç®—æ³•
batch_size = 32
train_iter, _ = d2l.load_data_bananas(batch_size)
device, net = d2l.try_gpu(), TinySSD(num_classes=1)
trainer = torch.optim.SGD(net.parameters(), lr=0.2, weight_decay=5e-4)

###### **å®šä¹‰æŸå¤±å‡½æ•°å’Œè¯„ä»·å‡½æ•°**
# é”šæ¡†ç±»åˆ«æŸå¤±ï¼›é”šæ¡†åç§»é‡çš„æŸå¤±
cls_loss = nn.CrossEntrophyLoss(reduction = 'none')
bbox_loss = nn.L1Loss(reduction = 'none')

def calc_loss(cls_preds,cls_labels,bbox_preds, bbox_labels, bbox_masks):
	batch_size,num_classes = cls_preds.shape[0], cls_preds.shape[2]
	bbox = bbox_loss(bbox_preds * bbox_masks,
                     bbox_labels * bbox_masks).mean(dim=1)
    return cls + bbox

def cls_eval(cls_preds, cls_labels):
    # ç”±äºç±»åˆ«é¢„æµ‹ç»“æœæ”¾åœ¨æœ€åä¸€ç»´ï¼Œargmaxéœ€è¦æŒ‡å®šæœ€åä¸€ç»´ã€‚
    return float((cls_preds.argmax(dim=-1).type(
        cls_labels.dtype) == cls_labels).sum())

def bbox_eval(bbox_preds, bbox_labels, bbox_masks):
    return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())
    
    
###### **è®­ç»ƒæ¨¡å‹**
num_epochs, timer = 20, d2l.Timer()
animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                        legend=['class error', 'bbox mae'])
net = net.to(device)
for epoch in range(num_epochs):
    # è®­ç»ƒç²¾ç¡®åº¦çš„å’Œï¼Œè®­ç»ƒç²¾ç¡®åº¦çš„å’Œä¸­çš„ç¤ºä¾‹æ•°
    # ç»å¯¹è¯¯å·®çš„å’Œï¼Œç»å¯¹è¯¯å·®çš„å’Œä¸­çš„ç¤ºä¾‹æ•°
    metric = d2l.Accumulator(4)
    net.train()
    for features, target in train_iter:
        timer.start()
        trainer.zero_grad()
        X, Y = features.to(device), target.to(device)
        
        # ç”Ÿæˆå¤šå°ºåº¦çš„é”šæ¡†ï¼Œä¸ºæ¯ä¸ªé”šæ¡†é¢„æµ‹ç±»åˆ«å’Œåç§»é‡
        anchors, cls_preds, bbox_preds = net(X)
        
        # ä¸ºæ¯ä¸ªé”šæ¡†æ ‡æ³¨ç±»åˆ«å’Œåç§»é‡
        bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, Y)
        
        # æ ¹æ®ç±»åˆ«å’Œåç§»é‡çš„é¢„æµ‹å’Œæ ‡æ³¨å€¼è®¡ç®—æŸå¤±å‡½æ•°
        l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks)
        l.mean().backward()
        trainer.step()
        metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(),bbox_eval(bbox_preds, bbox_labels, bbox_masks),bbox_labels.numel())
    cls_err, bbox_mae = 1 - metric[0] / metric[1], metric[2] / metric[3]
    animator.add(epoch + 1, (cls_err, bbox_mae))
print(f'class err {cls_err:.2e}, bbox mae {bbox_mae:.2e}')
print(f'{len(train_iter.dataset) / timer.stop():.1f} examples/sec on '
      f'{str(device)}')


###### **é¢„æµ‹ç›®æ ‡**
X = torchvision.io.read_image('../img/banana.jpg').		unsqueeze(0).float()
img = X.squeeze(0).permute(1, 2, 0).long()

def predict(X):
    net.eval()
    anchors, cls_preds, bbox_preds = net(X.to(device))
    cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1)
    output = d2l.multibox_detection(cls_probs, bbox_preds, anchors)
    idx = [i for i, row in enumerate(output[0]) if row[0] != -1]
    return output[0, idx]
    
output = predict(X)

###### **ç­›é€‰æ‰€æœ‰ç½®ä¿¡åº¦ä¸ä½äº0.9çš„è¾¹ç•Œæ¡†ï¼Œåšä¸ºæœ€ç»ˆè¾“å‡º**
def display(img, output, threshold):
    d2l.set_figsize((5, 5))
    fig = d2l.plt.imshow(img)
    for row in output:
        score = float(row[1])
        if score < threshold:
            continue
        h, w = img.shape[0:2]
        bbox = [row[2:6] * torch.tensor((w, h, w, h), device=row.device)]
        d2l.show_bboxes(fig.axes, bbox, '%.2f' % score, 'w')

display(img, output.cpu(), threshold=0.9)
```



## è¯­ä¹‰åˆ†å‰²

### è¯­ä¹‰åˆ†å‰²

æœ‰æ—¶åªèƒ½å®ç°æ¡†é€‰çš„ç›®æ ‡æ£€æµ‹è¿˜æ˜¯å¤ªç²—ç³™äº†ï¼Œæ— æ³•å¾—åˆ°æ›´ç²¾ç»†çš„ä¿¡æ¯ã€‚è¯­ä¹‰åˆ†å‰²å°†å›¾ç‰‡ä¸­çš„æ¯ä¸ªåƒç´ åˆ†ç±»åˆ°å¯¹åº”çš„ç±»åˆ«ã€‚

åˆ†å‰²è¿™ä¸€æ¦‚å¿µåœ¨è®¡ç®—æœºè§†è§‰ä¸­ç”±æ¥å·²ä¹…ã€‚æœ€æ—©çš„å›¾ç‰‡åˆ†å‰²å¯¹ç»™å®šå›¾ç‰‡ä½¿ç”¨èšç±»ç­‰æ–¹æ³•æŠŠè¯­ä¹‰ä¸Šæ¯”è¾ƒåƒçš„åƒç´ æ”¾åœ¨ä¸€èµ·ï¼Œä½†é€šå¸¸ä¸ä¼šå‘Šè¯‰æˆ‘ä»¬è¿™äº›åƒç´ åˆ°åº•æ˜¯ä»€ä¹ˆã€‚è€Œè¯­ä¹‰åˆ†å‰²å¯ä»¥å‘Šè¯‰æˆ‘ä»¬æ¯ä¸ªåƒç´ å¯¹åº”çš„labelæ˜¯ä»€ä¹ˆã€‚

è¿™ä¹Ÿæ„å‘³ç€æˆ‘ä»¬éœ€è¦å¯¹å›¾ç‰‡çš„æ¯ä¸€ä¸ªåƒç´ éƒ½åšlabelï¼Œä½¿å¾—è¯­ä¹‰åˆ†å‰²æˆä¸ºäº†ä¸€ä¸ªæ¯”è¾ƒç²¾ç»†ä¸”å¤§çš„ä»»åŠ¡ã€‚è¯­ä¹‰åˆ†å‰²çš„æ•°æ®é›†æˆæœ¬ä¹Ÿè¾ƒé«˜ï¼Œå¾€å¾€è§„æ¨¡å°åƒç´ é«˜ã€‚å¸¸ç”¨çš„æ•°æ®é›†ä¹‹ä¸€æ˜¯Pascal VOC2012ã€‚

[![46-01](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/46/46-01.jpg)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/46/46-01.jpg)

### åº”ç”¨



èƒŒæ™¯è™šåŒ–ï¼šä¼ ç»Ÿçš„èƒŒæ™¯æ›¿æ¢å¾€å¾€é‡‡ç”¨ç»¿å¹•ã€‚åœ¨æ²¡æœ‰ç»¿å¹•çš„æƒ…å†µä¸‹ä¼ ç»Ÿç›¸æœºå¯ä»¥é€šè¿‡å…‰åœˆæ¥å®ç°èƒŒæ™¯è™šåŒ–ï¼Œå¯¹äºæ‰‹æœºç­‰è®¾å¤‡è€Œè¨€èƒŒæ™¯è™šåŒ–é€šå¸¸ä½¿ç”¨çš„éƒ½æ˜¯è¯­ä¹‰åˆ†å‰²æˆ–ç»“åˆå›¾åƒæ™¯æ·±ä¿¡æ¯ã€‚

è·¯é¢åˆ†å‰²ï¼šå¦‚æ— äººé©¾é©¶æ—¶ç”¨äºå®æ—¶è¯†åˆ«å‘¨å›´ç‰©ä½“ï¼Œå®ç°æ‰¾è·¯çš„åŠŸèƒ½ã€‚

### å®ä¾‹åˆ†å‰²

è¯­ä¹‰åˆ†å‰²åªå…³å¿ƒåƒç´ å±äºå“ªä¸€ç±»ï¼Œè€Œå®ä¾‹åˆ†å‰²åˆ™æ›´è¿›ä¸€æ­¥ï¼Œå¦‚å›¾ç‰‡é‡Œæœ‰ä¸¤åªç‹—ï¼Œåˆ™éœ€è¦å¾—å‡ºå“ªä¸ªåƒç´ å±äºå“ªä¸€åªç‹—ã€‚å¯ä»¥å°†å…¶ç†è§£ä¸ºç›®æ ‡æ£€æµ‹çš„è¿›åŒ–ç‰ˆæœ¬ã€‚

**è¯­ä¹‰åˆ†å‰²å¯¹äºæ¯ä¸€ä¸ªåƒç´ ç”Ÿæˆä¸€ä¸ªæ ‡å·**



[![46-02](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/46/46-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/46/46-02.png)

### è¯­ä¹‰åˆ†å‰²å’Œæ•°æ®é›†

æœ€é‡è¦çš„è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ä¹‹ä¸€æ˜¯**Pascal VOC2012**

ä¸€èˆ¬æ¯”è¾ƒå¤§çš„æ•°æ®é›†ä¸ä¼šå…¨éƒ¨è¯»åˆ°å†…å­˜ä¸­ï¼Œä½†æ˜¯ä»¥ä¸‹ä¸ºäº†æ“ä½œæ–¹ä¾¿

```
#@save
import os
import torch
import torchvision
from d2l import torch as d2l

d2l.DATA_HUB['voc2012'] = (d2l.DATA_URL + 'VOCtrainval_11-May-2012.tar','4e443f8a2eca6b1dac8a6c57641b67dd40621a49')
voc_dir = d2l.download_extract('voc2012', 'VOCdevkit/VOC2012')

def read_voc_images(voc_dir, is_train=True):
    """è¯»å–æ‰€æœ‰VOCå›¾åƒå¹¶æ ‡æ³¨"""
    txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation',
                             'train.txt' if is_train else 'val.txt')
    mode = torchvision.io.image.ImageReadMode.RGB
    with open(txt_fname, 'r') as f:
        images = f.read().split()
    features, labels = [], []
    for i, fname in enumerate(images):
        features.append(torchvision.io.read_image(os.path.join(
            voc_dir, 'JPEGImages', f'{fname}.jpg')))
        labels.append(torchvision.io.read_image(os.path.join(
            voc_dir, 'SegmentationClass' ,f'{fname}.png'), mode))
    return features, labels

train_features, train_labels = read_voc_images(voc_dir, True)
```

**åˆ—ä¸¾RGBé¢œè‰²å’Œç±»å**ï¼Œ**é¢œè‰²å’Œç±»åä¸€ä¸€å¯¹åº”å¹¶å®Œæˆæ˜ å°„**

```
#@save
VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],
                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],
                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],
                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],
                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],
                [0, 64, 128]]

#@save
VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',
               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
               'diningtable', 'dog', 'horse', 'motorbike', 'person',
               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']
               
               
def voc_colormap2label():
	voc_colormap2label = torch.zeros(256**3,dtype=torch.long)
	for i,colormap in enumerate(VOC_CLASSES):
		colormap2label[  (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i
	return colormap2label
	
def voc_label_indices(colormap, colormap2label):
# å°†è¾“å…¥çš„ colormap ä» [C, H, W] æ ¼å¼è½¬æ¢ä¸º [H, W, C] æ ¼å¼
	colormap = colormap.permute(1, 2, 0).numpy().astype('int32')
 	idx = ((colormap[:,:,0]*256+colormap[:,:,1])*256+colormap[:,:,2])
 	return colormap2label[idx]
	
```

åœ¨è¯­ä¹‰åˆ†å‰²ä¸­ï¼Œè¯­ä¹‰åƒç´ ä¸ç±»åˆ«å®Œå…¨ä¸€ä¸€æ˜ å°„ï¼Œå¦‚æœç¼©æ”¾å›¾åƒï¼Œéœ€è¦å°†é¢„æµ‹çš„åƒç´ ç±»åˆ«é‡æ–°æ˜ å°„å›åŸå§‹å°ºå¯¸çš„è¾“å…¥å›¾åƒã€‚ ä¸ºäº†é¿å…è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†å›¾åƒè£å‰ªä¸ºå›ºå®šå°ºå¯¸ï¼Œè€Œä¸æ˜¯å†ç¼©æ”¾ã€‚ å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬[**ä½¿ç”¨å›¾åƒå¢å¹¿ä¸­çš„éšæœºè£å‰ªï¼Œè£å‰ªè¾“å…¥å›¾åƒå’Œæ ‡ç­¾çš„ç›¸åŒåŒºåŸŸ**]ã€‚

```
def voc_rand_crop(feature,label,height,width):
	# è·å–è£å‰ªåŒºåŸŸçš„å‚æ•°
	react = torchvision.transforms.RandomCrop.get_param(features,(height,width))
	 # ç‰¹å¾å›¾åƒä¸æ ‡ç­¾å›¾åƒ
	 # ä½¿ç”¨å¾—åˆ°çš„è£å‰ªå‚æ•°è£å‰ªç‰¹å¾å›¾åƒ
	 # ä½¿ç”¨ç›¸åŒçš„è£å‰ªå‚æ•°è£å‰ªæ ‡ç­¾å›¾åƒ
	 feature = torchvision.transforms.functional.crop(feature,*react)
	 label = torchvision.transforms.functional.crop(label,*react)
	 
	 return featrue,label
```

##### **è‡ªå®šä¹‰è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ç±»**

```
def __init__(self, is_train, crop_size, voc_dir):
        self.transform = torchvision.transforms.Normalize(
            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        self.crop_size = crop_size
        features, labels = read_voc_images(voc_dir, is_train=is_train)
        self.features = [self.normalize_image(feature)
                         for feature in self.filter(features)]
        self.labels = self.filter(labels)
        self.colormap2label = voc_colormap2label()
        print('read ' + str(len(self.features)) + ' examples')

    def normalize_image(self, img):
        return self.transform(img.float() / 255)

    def filter(self, imgs):
        return [img for img in imgs if (
            img.shape[1] >= self.crop_size[0] and
            img.shape[2] >= self.crop_size[1])]

    def __getitem__(self, idx):
        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],
                                       *self.crop_size)
        return (feature, voc_label_indices(label, self.colormap2label))

    def __len__(self):
        return len(self.features)
```

##### æ•´åˆæ‰€æœ‰ç»„ä»¶

```
def load_data_voc(batch_size,crop_size):
	# åŠ è½½å¹¶è§£å‹
	voc_dir = d2l.download_extract('voc2012', os.path.join(
        'VOCdevkit', 'VOC2012'))
    #å·¥ä½œçš„GPU
    num_workers = d2l.get_dataloader_workers()
    
    train_iter = torch.utils.data.DataLoader(
        VOCSegDataset(True, crop_size, voc_dir), batch_size,shuffle=True, drop_last=True, num_workers=num_workers)
    
    test_iter = torch.utils.data.DataLoader(
        VOCSegDataset(False, crop_size, voc_dir), batch_size,drop_last=True, num_workers=num_workers)
        
    return train_iter, test_iter
```







## è½¬ç½®å·ç§¯

å¦‚æœè¾“å…¥å’Œè¾“å‡ºå›¾åƒçš„ç©ºé—´ç»´åº¦ç›¸åŒï¼Œåœ¨ä»¥åƒç´ çº§åˆ†ç±»çš„è¯­ä¹‰åˆ†å‰²ä¸­å°†ä¼šå¾ˆæ–¹ä¾¿ã€‚ ä¾‹å¦‚ï¼Œè¾“å‡ºåƒç´ æ‰€å¤„çš„é€šé“ç»´å¯ä»¥ä¿æœ‰è¾“å…¥åƒç´ åœ¨åŒä¸€ä½ç½®ä¸Šçš„åˆ†ç±»ç»“æœã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡è½¬ç½®å·ç§¯å¢åŠ ä¸Šé‡‡æ ·ä¸­é—´å±‚ç‰¹å¾å›¾çš„ç©ºé—´ç»´åº¦ã€‚

### è½¬ç½®å·ç§¯

- è½¬ç½®å·ç§¯å’Œå·ç§¯çš„åŒºåˆ«ï¼š
  - å·ç§¯ä¸ä¼šå¢å¤§è¾“å…¥çš„é«˜å®½ï¼Œé€šå¸¸è¦ä¹ˆä¸å˜ã€è¦ä¹ˆå‡åŠ
  - è½¬ç½®å·ç§¯åˆ™å¯ä»¥ç”¨æ¥å¢å¤§è¾“å…¥é«˜å®½
- è½¬ç½®å·ç§¯çš„å…·ä½“å®ç°ï¼š

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/47/47-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/47/47-01.png)

å¦‚å›¾æ‰€ç¤ºï¼Œinputé‡Œçš„æ¯ä¸ªå…ƒç´ å’Œkernelç›¸ä¹˜ï¼Œæœ€åæŠŠå¯¹åº”ä½ç½®ç›¸åŠ ï¼Œç›¸å½“äºå·ç§¯çš„é€†å˜æ¢

- ä¸ºä»€ä¹ˆç§°ä¹‹ä¸ºâ€œè½¬ç½®ï¼š
  - å¯¹äºå·ç§¯Y=X*W
    - å¯ä»¥å¯¹Wæ„é€ ä¸€ä¸ªVï¼Œä½¿å¾—å·ç§¯ç­‰ä»·äºçŸ©é˜µä¹˜æ³•Y'=VX'
    - è¿™é‡ŒY',X'æ˜¯Y,Xå¯¹åº”çš„å‘é‡ç‰ˆæœ¬
  - è½¬ç½®å·ç§¯ç­‰ä»·äºY'=VTX'
  - å¦‚æœå·ç§¯å°†è¾“å…¥ä»ï¼ˆhï¼Œwï¼‰å˜æˆäº†ï¼ˆhâ€˜ï¼Œwâ€™ï¼‰
    - åŒæ ·è¶…å‚æ•°çš„è½¬ç½®å·ç§¯åˆ™ä»ï¼ˆhâ€˜ï¼Œwâ€™ï¼‰å˜æˆä¸ºï¼ˆhï¼Œwï¼‰

### è½¬ç½®å·ç§¯æ˜¯ä¸€ç§å·ç§¯

- é‡æ–°æ’åˆ—è¾“å…¥å’Œæ ¸

  - å½“å¡«å……ä¸º0æ­¥å¹…ä¸º1æ—¶ï¼š
    - å°†è¾“å…¥å¡«å……k-1ï¼ˆkæ—¶æ ¸çª—å£ï¼‰
    - å°†æ ¸çŸ©é˜µä¸Šä¸‹ã€å·¦å³ç¿»è½¬
    - ç„¶ååšæ­£å¸¸å·ç§¯ï¼ˆå¡«å……0ã€æ­¥å¹…1ï¼‰

  ![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/47/47-02.png)

  - å½“å¡«å……ä¸ºpæ­¥å¹…ä¸º1æ—¶ï¼š
    - å°†è¾“å¦‚å¡«å……k-p-1ï¼ˆkæ˜¯æ ¸çª—å£ï¼‰
    - å°†æ ¸çŸ©é˜µä¸Šä¸‹ã€å·¦å³ç¿»è½¬
    - ç„¶ååšæ­£å¸¸å·ç§¯ï¼ˆå¡«å……0ã€æ­¥å¹…1ï¼‰

  ![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/47/47-03.png)

  - å½“å¡«å……ä¸ºpæ­¥å¹…ä¸ºsæ—¶ï¼š
    - åœ¨è¡Œå’Œåˆ—ä¹‹é—´æ’å…¥s-1è¡Œæˆ–åˆ—
    - å°†è¾“å¦‚å¡«å……k-p-1ï¼ˆkæ˜¯æ ¸çª—å£ï¼‰
    - å°†æ ¸çŸ©é˜µä¸Šä¸‹ã€å·¦å³ç¿»è½¬
    - ç„¶ååšæ­£å¸¸å·ç§¯ï¼ˆå¡«å……0ã€æ­¥å¹…1ï¼‰

  ![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/47/47-04.png)

- å½¢çŠ¶æ¢ç®—

  - è¾“å…¥é«˜ï¼ˆå®½ï¼‰ä¸ºnï¼Œæ ¸kï¼Œå¡«å……pï¼Œæ­¥å¹…sï¼š
    - è½¬ç½®å·ç§¯ï¼šnâ€˜=sn+k-2p-s
    - å·ç§¯ï¼šnâ€™=[(n-k-2p+s)/s]å‘ä¸‹å–æ•´
  - å¦‚æœè®©é«˜å®½æˆå€å¢åŠ ï¼Œé‚£ä¹ˆk=2p+s

- åŒåå·ç§¯çš„å…³ç³»

  - æ•°å­¦ä¸Šçš„åå·ç§¯æ˜¯æŒ‡å·ç§¯çš„é€†è¿ç®—
    - è‹¥Y=convï¼ˆX,Kï¼‰ï¼Œé‚£ä¹ˆX=deconvï¼ˆY,Kï¼‰
  - åå·ç§¯å¾ˆå°‘ç”¨åœ¨æ·±åº¦å­¦ä¹ ä¸­
    - æˆ‘ä»¬è¯´çš„åå·ç§¯ç¥ç»ç½‘ç»œæŒ‡ç”¨äº†è½¬ç½®å·ç§¯çš„ç¥ç»ç½‘ç»œ

- æ€»ç»“

  - è½¬ç½®å·ç§¯æ˜¯ä¸€ç§å˜åŒ–äº†è¾“å…¥å’Œæ ¸çš„å·ç§¯ï¼Œæ¥å¾—åˆ°ä¸Šé‡‡ç”¨çš„ç›®çš„
  - ä¸ç­‰åŒäºæ•°å­¦ä¸Šçš„åå·ç§¯æ“ä½œ

### ä»£ç å®ç°

```
# åŸºæœ¬æ“ä½œ
def trans_conv(X,K):
	h,w = K.shape
	Y = torch.zeros(X.shape[0]-h+1,X.shape[1]-w+1)
	for i in range(X.shape[0]):
		for j in range(X.shape[1]):
			Y[i:i+h,j:j+w]+=X[i,j]*K
	return Y
	
# ä½¿ç”¨é«˜çº§APIè·å¾—ç›¸åŒçš„ç»“æœ
# batch,é€šé“ï¼Œé«˜å®½
X, K = X.reshape(1, 1, 2, 2), K.reshape(1, 1, 2, 2)
# è¾“å…¥é€šé“ï¼Œè¾“å‡ºé€šé“ï¼Œæ ¸å¤§å°
tconv = nn.ConvTranspose2d(1, 1, kernel_size=2, bias=False)
# è®¾ç½®å·ç§¯å‚æ•°
tconv.weight.data = K
#è½¬ç½®å·ç§¯è°ƒç”¨APIè¿ç®—
tconv(X)
```

##### **å¡«å……ã€æ­¥å¹…å’Œå¤šé€šé“**

å¸¸è§„å·ç§¯çš„å¡«å……æ”¾åœ¨è¾“å…¥ï¼Œè½¬ç½®å·ç§¯çš„å¡«å……æ”¾åœ¨è¾“å‡ºã€‚ä¾‹å¦‚ï¼Œå½“å°†é«˜å’Œå®½ä¸¤ä¾§çš„å¡«å……æ•°æŒ‡å®šä¸º1æ—¶ï¼Œè½¬ç½®å·ç§¯çš„è¾“å‡ºä¸­å°†åˆ é™¤ç¬¬ä¸€å’Œæœ€åçš„è¡Œä¸åˆ—ã€‚

æ­¥å¹…è¢«æŒ‡å®šä¸ºä¸­é—´ç»“æœï¼ˆè¾“å‡ºï¼‰

å¯¹äºå¤šä¸ªè¾“å…¥å’Œè¾“å‡ºé€šé“ï¼Œè½¬ç½®å·ç§¯ä¸å¸¸è§„å·ç§¯ä»¥ç›¸åŒæ–¹å¼è¿ä½œã€‚

##### **ä¸çŸ©é˜µå˜æ¢çš„è”ç³»**

ç”¨çŸ©é˜µä¹˜æ³•æ¥å®ç°å·ç§¯

```
X = torch.arrange(9.0).reshape(3,3)
K = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
Y = d2l.corr2d(X,K)

'''å·ç§¯æ ¸Ké‡å†™ä¸ºåŒ…å«å¤§é‡0çš„ç¨€ç–æƒé‡çŸ©é˜µWã€‚ æƒé‡çŸ©é˜µçš„å½¢çŠ¶æ˜¯ï¼ˆ4ï¼Œ9ï¼‰ï¼Œå…¶ä¸­é0å…ƒç´ æ¥è‡ªå·ç§¯æ ¸Kã€‚'''

def kernel2matrix(K)ï¼š
	k,W=torch.zeros(5),torch.zeros((4,9))
	k[:2],k[3:] = K[0,:],K[1:]
	W[0, :5], W[1, 1:6], W[2, 3:8], W[3, 4:] = k, k, k, k
    return W
    
'''é€è¡Œè¿ç»“è¾“å…¥Xï¼Œè·å¾—äº†ä¸€ä¸ªé•¿åº¦ä¸º9çš„çŸ¢é‡ã€‚ ç„¶åï¼ŒWçš„çŸ©é˜µä¹˜æ³•å’Œå‘é‡åŒ–çš„Xç»™å‡ºäº†ä¸€ä¸ªé•¿åº¦ä¸º4çš„å‘é‡ã€‚ é‡å¡‘å®ƒä¹‹åï¼Œå¯ä»¥è·å¾—ä¸ä¸Šé¢çš„åŸå§‹å·ç§¯æ“ä½œæ‰€å¾—ç›¸åŒçš„ç»“æœYï¼šæˆ‘ä»¬åˆšåˆšä½¿ç”¨çŸ©é˜µä¹˜æ³•å®ç°äº†å·ç§¯ã€‚'''
```

åŒç†å¯ä»¥å®ç°è½¬ç½®å·ç§¯ã€‚æƒ³è¦é€šè¿‡çŸ©é˜µç›¸ä¹˜æ¥å®ç°å®ƒï¼Œæˆ‘ä»¬åªéœ€è¦å°†æƒé‡çŸ©é˜µ`W`çš„å½¢çŠ¶è½¬ç½®ä¸º(9,4)ã€‚

```
Z = trans_conv(Y, K)
```







## å…¨è¿æ¥å·ç§¯ç¥ç»ç½‘ç»œï¼ˆFCNï¼‰

- FCNæ˜¯æ·±åº¦ç¥ç»ç½‘ç»œæ¥åšè¯­ä¹‰åˆ†å‰²çš„å¥ å®šæ€§å·¥ä½œ
- ä»–ç”¨**è½¬ç½®å·ç§¯å±‚**æ¥æ›¿æ¢CNNæœ€åçš„å…¨è¿æ¥å±‚ï¼ˆè¿˜æœ‰æ± åŒ–å±‚ï¼‰ï¼Œä»è€Œå®ç°æ¯ä¸ªåƒç´ çš„é¢„æµ‹ã€‚ï¼ˆå¦‚æœè¾“å…¥çš„å›¾ç‰‡æ˜¯224 x 224ï¼Œç»è¿‡CNNå˜æˆ 7 x 7ï¼Œç»è¿‡ transposed convï¼Œå¯ä»¥è¿˜åŸåˆ° 224 x 224 x kï¼Œkä¸ºé€šé“æ•°ï¼‰
- ä¿ç•™ç©ºé—´ä¿¡æ¯

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/48/48-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/48/48-01.png)

### ä»£ç 

CNNå·ç§¯ç¥ç»ç½‘ç»œ

1*1å·ç§¯å±‚ï¼ˆæŠŠé€šé“æ•°æ”¹æˆç±»åˆ«å¤§å°ï¼‰

è½¬ç½®å·ç§¯å°†ç‰¹å¾é«˜å®½å˜åŒ–æˆè¾“å…¥å›¾åƒçš„å°ºå¯¸

```
%matplotlib inline
import torch
import torchvision
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

# æ‹¿èµ°resnetçš„æ¡†æ¶å»æ‰åé¢å…¨è¿æ¥å±‚çš„éƒ¨åˆ†
pretrained_net = torchvision.models.resnet18(pretrained=True)
net = nn.Sequential(*list(pretrained_net.children())[:-2])
```



```
'''ç»™å®šé«˜åº¦ä¸º320å’Œå®½åº¦ä¸º480çš„è¾“å…¥ï¼Œnetçš„å‰å‘ä¼ æ’­å°†è¾“å…¥çš„é«˜å’Œå®½å‡å°è‡³åŸæ¥çš„ï¼Œå³10å’Œ15ã€‚'''
X = torch.rand(size=(1, 3, 320, 480))

'''ä½¿ç”¨å·ç§¯å±‚å°†è¾“å‡ºé€šé“æ•°è½¬æ¢ä¸ºPascal VOC2012æ•°æ®é›†çš„ç±»æ•°ï¼ˆ21ç±»ï¼‰ã€‚] æœ€åéœ€è¦(å°†ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦å¢åŠ 32å€)ï¼Œä»è€Œå°†å…¶å˜å›è¾“å…¥å›¾åƒçš„é«˜å’Œå®½ã€‚'''

# ä»¤ k=2*p+sï¼Œä½¿å¾—æœ€ç»ˆç»“æœåªå¢å¤§så€
num_classes = 21
net.add_module('final_conv',nn.Con2d(512, num_classes, kernel_size=1))
net.add_module('transpose_conv', nn.ConvTranspose2d(num_classes, num_classes,
    kernel_size=64, padding=16, stride=32))
```

##### åˆå§‹åŒ–è½¬ç½®å·ç§¯å±‚

###### åŒçº¿æ€§æ’å€¼

1. å°†è¾“å‡ºå›¾åƒçš„åæ ‡(ğ‘¥,ğ‘¦)æ˜ å°„åˆ°è¾“å…¥å›¾åƒçš„åæ ‡(ğ‘¥â€²,ğ‘¦â€²)ä¸Šã€‚ ä¾‹å¦‚ï¼Œæ ¹æ®è¾“å…¥ä¸è¾“å‡ºçš„å°ºå¯¸ä¹‹æ¯”æ¥æ˜ å°„ã€‚ è¯·æ³¨æ„ï¼Œæ˜ å°„åçš„ğ‘¥â€²å’Œğ‘¦â€²æ˜¯å®æ•°ã€‚
2. åœ¨è¾“å…¥å›¾åƒä¸Šæ‰¾åˆ°ç¦»åæ ‡(ğ‘¥â€²,ğ‘¦â€²)æœ€è¿‘çš„4ä¸ªåƒç´ ã€‚
3. è¾“å‡ºå›¾åƒåœ¨åæ ‡(ğ‘¥,ğ‘¦)ä¸Šçš„åƒç´ ä¾æ®è¾“å…¥å›¾åƒä¸Šè¿™4ä¸ªåƒç´ åŠå…¶ä¸(ğ‘¥â€²,ğ‘¦â€²)çš„ç›¸å¯¹è·ç¦»æ¥è®¡ç®—ã€‚

###### æ ¸å¿ƒæ­¥éª¤

**æ ¸å¿ƒä½ç½®**ï¼š

- æ ¸çš„ä¸­å¿ƒä½ç½®å–å†³äºæ ¸å¤§å° (`kernel_size`)ã€‚**å¯¹äºå¥‡æ•°å¤§å°çš„æ ¸ï¼Œä¸­å¿ƒæ˜¯æ˜ç¡®çš„ï¼›å¯¹äºå¶æ•°å¤§å°çš„æ ¸ï¼Œä¸­å¿ƒåœ¨ä¸¤ä¸ªåƒç´ ä¹‹é—´**ã€‚

**æ ¸ç”Ÿæˆ**ï¼š

- `og` åŒ…å«ä¸¤ä¸ªé€šè¿‡ `torch.arange` ç”Ÿæˆçš„å¼ é‡ï¼Œåˆ†åˆ«**ä»£è¡¨æ ¸çš„è¡Œå’Œåˆ—**ã€‚è¿™äº›å¼ é‡ç”¨äºè®¡ç®—æ¯ä¸ªä½ç½®ä¸æ ¸ä¸­å¿ƒçš„è·ç¦»ã€‚
- `filt` é€šè¿‡åŒçº¿æ€§æ’å€¼å…¬å¼è®¡ç®—ï¼Œå¯¹æ¯ä¸ªå…ƒç´ çš„å€¼è¿›è¡Œè®¡ç®—ï¼ŒåŸºäºå…¶åˆ°ä¸­å¿ƒçš„è·ç¦»ã€‚**æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œè·ç¦»ä¸­å¿ƒè¶Šè¿‘çš„ç‚¹æƒé‡è¶Šå¤§**ã€‚

**æƒé‡çŸ©é˜µåˆå§‹åŒ–**ï¼š

- åˆå§‹åŒ–ä¸€ä¸ªå½¢çŠ¶ä¸º (in_channels, out_channels, kernel_size, kernel_size) çš„é›¶å¼ é‡ã€‚**è¿™ä¿è¯äº†æ¯ä¸ªè¾“å…¥é€šé“åˆ°æ¯ä¸ªè¾“å‡ºé€šé“éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„å·ç§¯æ ¸**ã€‚

**å¡«å……å·ç§¯æ ¸**ï¼š

- å°†è®¡ç®—å¾—åˆ°çš„åŒçº¿æ€§æ ¸ (`filt`) å¤åˆ¶åˆ°æ¯ä¸€ä¸ªè¾“å…¥é€šé“å¯¹åº”çš„è¾“å‡ºé€šé“çš„ä½ç½®ã€‚è¿™æ ·ç¡®ä¿äº†æ‰€æœ‰çš„é€šé“éƒ½ä½¿ç”¨ç›¸åŒçš„åŒçº¿æ€§æ’å€¼æ ¸ï¼Œè¿™æ˜¯å› ä¸ºåŒçº¿æ€§æ’å€¼æ˜¯é€šé“æ— å…³çš„ã€‚

```
def bililinear_kernel(in_channels, out_channels, kernel_size):
	# è®¡ç®—æ ¸ä¸­å¿ƒç‚¹çš„ä½ç½®
    factor = (kernel_size + 1) // 2
    if kernel_size % 2 == 1:
        center = factor - 1
    else:
        center = factor - 0.5
    og = (torch.arange(kernel_size).reshape(-1,1),torch.arange(kernel_size).reshape(1,-1))    
    filt = (1 - torch.abs(og[0] - center) / factor) * \
           (1 - torch.abs(og[1] - center) / factor)
    weight = torch.zeros((in_channels, out_channels,kernel_size, kernel_size))
    weight[range(in_channels),
    range(out_channels),:,:] = filt
    
    return weight
    
```

å…¨å·ç§¯ç½‘ç»œ[**ç”¨åŒçº¿æ€§æ’å€¼çš„ä¸Šé‡‡æ ·åˆå§‹åŒ–è½¬ç½®å·ç§¯å±‚ã€‚å¯¹äº1Ã—1å·ç§¯å±‚ï¼Œæˆ‘ä»¬ä½¿ç”¨Xavieråˆå§‹åŒ–å‚æ•°ã€‚**]

```
W = bilinear_kernel(num_classes, num_classes, 64)
net.transpose_conv.weight.data.copy_(W);
```



## æ ·å¼è¿ç§»

æ ·å¼è¿ç§»ç±»ä¼¼äºæ‰‹æœºç›¸æœºä¸­çš„æ»¤é•œï¼ŒæŒ‡çš„æ˜¯ç»™å®šå†…å®¹å›¾ç‰‡å’Œé£æ ¼å›¾ç‰‡ï¼Œåˆæˆä¸€å¼ æ–°çš„å›¾ç‰‡ï¼Œä½¿å¾—ä»–çš„å†…å®¹ä¸å†…å®¹å›¾ç‰‡ç›¸ä¼¼ï¼Œè€Œé£æ ¼å´æ˜¯é£æ ¼å›¾ç‰‡çš„æ ·å­ï¼Œå¦‚ä¸‹ä¾‹ï¼š

[![æ ·å¼è¿ç§»ç¤ºä¾‹](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/49/%E6%A0%B7%E5%BC%8F%E8%BF%81%E7%A7%BB%E7%A4%BA%E4%BE%8B.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/49/æ ·å¼è¿ç§»ç¤ºä¾‹.png)

### ç›®çš„

[å¦‚ä½•ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œè‡ªåŠ¨å°†ä¸€ä¸ªå›¾åƒä¸­çš„é£æ ¼åº”ç”¨åœ¨å¦ä¸€å›¾åƒä¹‹ä¸Šï¼Œå³*é£æ ¼è¿ç§»*ï¼ˆstyle transferï¼‰]

è¾“å…¥å›¾åƒï¼šå†…å®¹å›¾åƒå’Œé£æ ¼å›¾åƒã€‚ä½¿ç”¨ç¥ç»ç½‘ç»œä¿®æ”¹å†…å®¹å›¾åƒï¼Œä½¿å…¶åœ¨é£æ ¼ä¸Šæ¥è¿‘é£æ ¼å›¾åƒã€‚

### æ–¹æ³•

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¯ä»¥ç”¨ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæ¥å®ç°æ ·å¼è¿ç§»ï¼š

- 1ï¼šå°†å†…å®¹å›¾åƒä½œä¸ºåˆå§‹åŒ–å›¾åƒ	ï¼Œä¹‹åå°†è¿™å¼ å›¾ç‰‡ä¸­çš„åƒç´ ä½œä¸ºå‚æ•°è¿›è¡Œæ›´æ–°ï¼Œæœ€ç»ˆå¾—åˆ°åˆæˆçš„å›¾ç‰‡ã€‚**è¯¥åˆæˆå›¾åƒæ˜¯é£æ ¼è¿ç§»è¿‡ç¨‹ä¸­å”¯ä¸€éœ€è¦æ›´æ–°çš„å˜é‡**ï¼Œå³é£æ ¼è¿ç§»æ‰€éœ€è¿­ä»£çš„æ¨¡å‹å‚æ•°ã€‚
- 2ï¼šå°†å†…å®¹å›¾ç‰‡ï¼Œå½“å‰çš„åˆæˆå›¾ç‰‡ï¼Œæ ·å¼å›¾ç‰‡åˆ†åˆ«è¾“å…¥ä¸€ä¸ªç›¸åŒçš„é¢„è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œ
- 3ï¼šå‡è®¾è¯¥ç¥ç»ç½‘ç»œçš„ä¸åŒå±‚åˆ†åˆ«æå–ä¸å†…å®¹å’Œé£æ ¼ç›¸å…³çš„ä¿¡æ¯ï¼Œå¯ä»¥æ®æ­¤å¾—åˆ°ä¸€ä¸ªæŸå¤±ï¼š
  - å°†åˆæˆå›¾ç‰‡ä¸**å†…å®¹**ç›¸å…³çš„å±‚çš„è¾“å‡ºä¸**å†…å®¹**å›¾ç‰‡å¯¹åº”å±‚çš„è¾“å‡ºè¿›è¡Œå¤„ç†ï¼Œå¾—åˆ°**å†…å®¹æŸå¤±**
  - å°†åˆæˆå›¾ç‰‡ä¸**é£æ ¼**ç›¸å…³çš„å±‚çš„è¾“å‡ºä¸**é£æ ¼**å›¾ç‰‡å¯¹åº”å±‚çš„è¾“å‡ºè¿›è¡Œå¤„ç†ï¼Œå¾—åˆ°**é£æ ¼æŸå¤±**
  - å¯¹åˆæˆå›¾ç‰‡æœ¬èº«ï¼Œç»Ÿè®¡å›¾ç‰‡ä¸­çš„é«˜é¢‘å™ªç‚¹ï¼ˆå³è¿‡æ˜æˆ–è¿‡æš—åƒç´ ç‚¹ï¼‰ï¼Œå¾—åˆ°**å…¨å˜åˆ†æŸå¤±**
  - å°†ä¸‰éƒ¨åˆ†æŸå¤±åŠ èµ·æ¥å¾—åˆ°æ€»çš„æ ·å¼è¿ç§»çš„**æŸå¤±å‡½æ•°**
- 4ï¼šåˆ©ç”¨3å®šä¹‰çš„æŸå¤±å‡½æ•°ï¼Œä»¥åˆæˆå›¾ç‰‡çš„æ¯ä¸ªåƒç´ ç‚¹ä¸ºå‚æ•°è¿›è¡Œæ¢¯åº¦ä¸‹é™ï¼Œå¾—åˆ°æœ€ç»ˆåˆæˆçš„å›¾ç‰‡

[![CNNå®ç°](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/49/CNN%E5%AE%9E%E7%8E%B0.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/49/CNNå®ç°.png)

### å†…å®¹æŸå¤±

ç¥ç»ç½‘ç»œå†…å®¹ç›¸å…³å±‚çš„è¾“å‡ºçš„ç›¸ä¼¼åº¦å¯ä»¥ç›´æ¥ååº”ä¸¤å¼ å›¾ç‰‡åœ¨å†…å®¹ä¸Šçš„ç›¸ä¼¼åº¦ï¼Œå› æ­¤å†…å®¹æŸå¤±å¯ä»¥ç›´æ¥å°†å¯¹åº”å±‚çš„è¾“å‡ºè§†ä¸ºå†…å®¹ç›´æ¥æ±‚å¹³æ–¹å·®æŸå¤±ã€‚

### é£æ ¼æŸå¤±ï¼šæ ¼æ‹‰å§†çŸ©é˜µ

å¯¹äºå†…å®¹å±‚ï¼Œå¯ä»¥ç›´æ¥å°†å¯¹åº”å±‚çš„è¾“å‡ºæ±‚å¹³æ–¹å·®æŸå¤±ï¼Œä½†æ˜¯å¯¹äºé£æ ¼åˆ™ç•¥æœ‰ä¸åŒ

ä¸€èˆ¬è®¤ä¸ºï¼Œé£æ ¼å±‚å¯¹åº”çš„è¾“å‡ºçš„å¤šä¸ªé€šé“åˆ†åˆ«å¯¹åº”ç€ä¸åŒç±»å‹çš„ä¿¡æ¯ï¼Œå¦‚æœå°†è¾“å‡ºçš„å½¢çŠ¶ä»$[batch_size=1,channels,h,w]$è½¬åŒ–ä¸º$[channels,h*w]$å°±èƒ½å¾—åˆ°é€šé“æ•°ä¸ªå‘é‡ï¼Œä»¥$x_1,x_2...x_c$è¡¨ç¤ºï¼Œä»£è¡¨ä¸åŒé€šé“æ‰€æå–å‡ºçš„ä¸åŒä¿¡æ¯ï¼Œè€Œé£æ ¼å¯ä»¥è§†ä½œè¿™äº›ä¿¡æ¯ä¹‹é—´çš„å…³è”ï¼Œå³ç›¸ä¼¼åº¦ã€‚

å®šä¹‰æ ¼æ‹‰å§†çŸ©é˜µ$\bold X * \bold X^T \in R^{c \cdot c}$ï¼ŒçŸ©é˜µçš„ç¬¬iè¡Œç¬¬jåˆ—å³å‘é‡$x_i$ä¸$x_j$çš„å†…ç§¯ï¼Œè¿™ä¸ªçŸ©é˜µå°±ä»£è¡¨äº†ä¸€å¼ å›¾ç‰‡çš„é£æ ¼ã€‚

å¯¹äºç”Ÿæˆå›¾ç‰‡å’Œé£æ ¼å›¾ç‰‡çš„æ ¼æ‹‰å§†çŸ©é˜µæ±‚å¹³æ–¹å·®æŸå¤±å°±èƒ½å¾—åˆ°æ‰€éœ€çš„é£æ ¼æŸå¤±

æ­¤å¤–ï¼Œä¸ºäº†è®©é£æ ¼æŸå¤±ä¸å—æ ¼æ‹‰å§†çŸ©é˜µåŠå‘é‡çš„å¤§å°å½±å“ï¼Œå®é™…å°†æ ¼æ‹‰å§†çŸ©é˜µé™¤ä»¥è¿™äº›å¤§å°$channnels*h*w$ã€‚

### å…¨å˜åˆ†æŸå¤±

ç”¨äºå»é™¤é«˜é¢‘å™ªç‚¹ï¼ˆè¿‡æ˜è¿‡æš—åƒç´ ç‚¹ï¼‰ $$ \sum_{i, j} \left|x_{i, j} - x_{i+1, j}\right| + \left|x_{i, j} - x_{i, j+1}\right| $$

### ä»£ç 

##### é˜…è¯»å†…å®¹å’Œé£æ ¼å›¾åƒ

```
import torch
import torchvision
from torch import nn
from d2l import torch as d2l

# è¯»å‡ºå›¾åƒå¤§å°
d2l.set_figsize()
content_img = d2l.Image.open(
				'../img/rainier.jpg')
d2l.plt.imshow(content_img)

style_img = d2l.Image.open(
				'../img/autumn-oak.jpg')
d2l.plt.imshow(style_img)
```

##### é¢„å¤„ç†å’Œåå¤„ç†

é¢„å¤„ç†å‡½æ•°preprocessï¼šå¯¹è¾“å…¥å›¾åƒåœ¨RGBä¸‰ä¸ªé€šé“åˆ†åˆ«åšæ ‡å‡†åŒ–ï¼Œå¹¶å°†ç»“æœå˜æ¢æˆå·ç§¯ç¥ç»ç½‘ç»œæ¥å—çš„è¾“å…¥æ ¼å¼ã€‚ 

â€‹		**ç»´åº¦æ ¼å¼**ï¼šå¯¹äºå¤§å¤šæ•°æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆå¦‚PyTorchå’ŒTensorFlowï¼‰ï¼ŒCNNæ¥å—çš„è¾“å…¥é€šå¸¸æ˜¯ä¸€ä¸ªå››ç»´å¼ é‡ï¼Œå…¶å½¢çŠ¶ä¸º `(N, C, H, W)`ï¼š

åå¤„ç†å‡½æ•°postprocessï¼šå°†è¾“å‡ºå›¾åƒä¸­çš„åƒç´ å€¼è¿˜åŸå›æ ‡å‡†åŒ–ä¹‹å‰çš„å€¼ã€‚ ç”±äºå›¾åƒæ‰“å°å‡½æ•°è¦æ±‚æ¯ä¸ªåƒç´ çš„æµ®ç‚¹æ•°å€¼åœ¨0ï½1ä¹‹é—´ï¼Œæˆ‘ä»¬å¯¹å°äº0å’Œå¤§äº1çš„å€¼åˆ†åˆ«å–0å’Œ1ã€‚

- **å¯è§†åŒ–**ï¼šåœ¨è¿›è¡Œå›¾åƒå¤„ç†æˆ–åˆ†ææ—¶ï¼ŒåŸå§‹å›¾åƒæ•°æ®é€šå¸¸ä¼šè¢«æ ‡å‡†åŒ–æˆ–å½’ä¸€åŒ–ä»¥é€‚åº”ç½‘ç»œè®­ç»ƒçš„éœ€è¦ã€‚ä½†ä¸ºäº†å¯è§†åŒ–æˆ–å±•ç¤ºè¿™äº›å›¾åƒï¼Œéœ€è¦å°†å¤„ç†åçš„æ•°æ®è¿˜åŸåˆ°åŸå§‹çš„æ•°æ®èŒƒå›´ï¼ˆé€šå¸¸æ˜¯0åˆ°255çš„æ•´æ•°ï¼‰ï¼Œä½¿å›¾åƒå¯¹äººçœ¼æ¥è¯´æ˜¯è‡ªç„¶å’Œç†è§£çš„ã€‚
- **ä¿å­˜å’Œä½¿ç”¨**ï¼šå¦‚æœè¦å°†å¤„ç†åçš„å›¾åƒç”¨äºå…¶ä»–åº”ç”¨ï¼Œå¦‚å›¾åƒç¼–è¾‘è½¯ä»¶æˆ–å…¶ä»–å›¾åƒå¤„ç†æµç¨‹ï¼Œé€šå¸¸éœ€è¦è¿˜åŸåˆ°æ ‡å‡†çš„é¢œè‰²èŒƒå›´å†…ã€‚è¿™æ ·åšç¡®ä¿äº†å›¾åƒçš„å…¼å®¹æ€§å’Œå®ç”¨æ€§ã€‚
- **é¿å…æ•°æ®å¤±çœŸ**ï¼šæ ‡å‡†åŒ–è¿‡ç¨‹å¯èƒ½ä¼šæ”¹å˜åƒç´ å€¼çš„åˆ†å¸ƒï¼Œå¯¹è¶…å‡º[0,1]èŒƒå›´çš„å€¼è¿›è¡Œè£å‰ªï¼ˆè®¾ç½®ä¸º0æˆ–1ï¼‰ï¼Œè¿™æœ‰åŠ©äºä¿æŒæ•°æ®çš„å®Œæ•´æ€§å’Œå›¾åƒçš„è´¨é‡ã€‚

```
rgb_mean = torch.tensor([0.485, 0.456, 0.406])
rgb_std = torch.tensor([0.229, 0.224, 0.225])

def progress(img,image_shape):
	transforms = torchvision.transforms.Compose([
torchvision.transforms.Resize(image_shape),
torchvision.transforms.ToTensor(),
torchvision.transforms.Normalize(mean=rgb_mean, std=rgb_std)])
    return transforms(img).unsqueeze(0)
    
    
def postprocess(img):
	img = img[0].to(rgb_std.device)
	img = torch.clamp(img.permute(1, 2, 0) * rgb_std + rgb_mean, 0, 1)
    
    return torchvision.transforms.
    ToPILImage()(img.permute(2, 0, 1))
```

##### åˆå§‹åŒ–åˆæˆå›¾åƒ

**åˆæˆçš„å›¾åƒæ˜¯è®­ç»ƒæœŸé—´å”¯ä¸€éœ€è¦æ›´æ–°çš„å˜é‡**ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¨¡å‹`SynthesizedImage`ï¼Œå¹¶å°†åˆæˆçš„å›¾åƒè§†ä¸ºæ¨¡å‹å‚æ•°ã€‚æ¨¡å‹çš„å‰å‘ä¼ æ’­åªéœ€è¿”å›æ¨¡å‹å‚æ•°å³å¯ã€‚

```
class SynthesizedImage(nn.Module):
    def __init__(self, img_shape, **kwargs):
        super(SynthesizedImage, self).__init__(**kwargs)
        self.weight = nn.Parameter(torch.rand(*img_shape))

    def forward(self):
        return self.weight
        
'''åˆ›å»ºäº†åˆæˆå›¾åƒçš„æ¨¡å‹å®ä¾‹ï¼Œå¹¶å°†å…¶åˆå§‹åŒ–ä¸ºå›¾åƒX'''     
def get_inits(X,device,il,style_Y):
	gen_img = SynthesizedImage(X).to(device)
	gen_img.weight.data.copy_(X.data)
    trainer = torch.optim.Adam(gen_img.parameters(),lr=lr)
    styles_Y_gram = [gram(Y) for Y in styles_Y]
    return gen_img(), styles_Y_gram, trainer
```

##### æŠ½å–å›¾åƒç‰¹å¾

ä¸ºäº†æŠ½å–å›¾åƒçš„å†…å®¹ç‰¹å¾å’Œé£æ ¼ç‰¹å¾ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©VGGç½‘ç»œä¸­æŸäº›å±‚çš„è¾“å‡ºã€‚ ä¸€èˆ¬æ¥è¯´ï¼Œè¶Šé è¿‘è¾“å…¥å±‚ï¼Œè¶Šå®¹æ˜“æŠ½å–å›¾åƒçš„ç»†èŠ‚ä¿¡æ¯ï¼›åä¹‹ï¼Œåˆ™è¶Šå®¹æ˜“æŠ½å–å›¾åƒçš„å…¨å±€ä¿¡æ¯ã€‚ ä¸ºäº†é¿å…åˆæˆå›¾åƒè¿‡å¤šä¿ç•™å†…å®¹å›¾åƒçš„ç»†èŠ‚ï¼Œæˆ‘ä»¬é€‰æ‹©VGGè¾ƒé è¿‘è¾“å‡ºçš„å±‚ï¼Œå³*å†…å®¹å±‚*ï¼Œæ¥è¾“å‡ºå›¾åƒçš„å†…å®¹ç‰¹å¾ã€‚ æˆ‘ä»¬è¿˜ä»VGGä¸­é€‰æ‹©ä¸åŒå±‚çš„è¾“å‡ºæ¥åŒ¹é…å±€éƒ¨å’Œå…¨å±€çš„é£æ ¼ï¼Œè¿™äº›å›¾å±‚ä¹Ÿç§°ä¸º*é£æ ¼å±‚*ã€‚ 

ä½¿ç”¨VGGå±‚æŠ½å–ç‰¹å¾æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦ç”¨åˆ°**ä»è¾“å…¥å±‚åˆ°æœ€é è¿‘è¾“å‡ºå±‚çš„å†…å®¹å±‚æˆ–é£æ ¼å±‚ä¹‹é—´çš„æ‰€æœ‰å±‚**ã€‚ ä¸‹é¢æ„å»ºä¸€ä¸ªæ–°çš„ç½‘ç»œ`net`ï¼Œå®ƒåªä¿ç•™éœ€è¦ç”¨åˆ°çš„VGGçš„æ‰€æœ‰å±‚ã€‚(å±‚çš„è£å‰ªï¼Œé˜²æ­¢è¿‡å¤šè¿ç®—)

ç»™å®šè¾“å…¥`X`ï¼Œå¦‚æœæˆ‘ä»¬ç®€å•åœ°è°ƒç”¨å‰å‘ä¼ æ’­`net(X)`ï¼Œåªèƒ½è·å¾—æœ€åä¸€å±‚çš„è¾“å‡ºã€‚ ç”±äºæˆ‘ä»¬è¿˜éœ€è¦ä¸­é—´å±‚çš„è¾“å‡ºï¼Œå› æ­¤è¿™é‡Œæˆ‘ä»¬é€å±‚è®¡ç®—ï¼Œå¹¶ä¿ç•™å†…å®¹å±‚å’Œé£æ ¼å±‚çš„è¾“å‡ºã€‚

```
# æˆ‘ä»¬ä½¿ç”¨åŸºäºImageNetæ•°æ®é›†é¢„è®­ç»ƒçš„VGG-19æ¨¡å‹æ¥æŠ½å–å›¾åƒç‰¹å¾
pretrained_net = torchvision.models.vgg19(pretrained=True)

style_layers, content_layers = [0, 5, 10, 19, 28], [25]

net = nn.Sequential(*[pretrained_net.features[i] for i in range(max(content_layers + style_layers) + 1)])

def extract_features(X,content_layers, style_layers):
	contents = []
    styles = []
    for i in range(len(net)):
    	X = net[i](X)
        if i in style_layers:
            styles.append(X)
        if i in content_layers:
            contents.append(X)
    return contents, styles
    
    
'''å¯¹å†…å®¹å›¾åƒæŠ½å–å†…å®¹ç‰¹å¾'''
def get_contents(image_shape, device):
    content_X = preprocess(content_img, image_shape).to(device)
    contents_Y, _ = extract_features(content_X, content_layers, style_layers)
    return content_X, contents_Y

def get_styles(image_shape, device):
    style_X = preprocess(style_img, image_shape).to(device)
    _, styles_Y = extract_features(style_X, content_layers, style_layers)
    return style_X, styles_Y

```

##### å®šä¹‰æŸå¤±å‡½æ•°

é£æ ¼è¿ç§»çš„æŸå¤±å‡½æ•°ã€‚ å®ƒç”±**å†…å®¹æŸå¤±ã€é£æ ¼æŸå¤±å’Œå…¨å˜åˆ†æŸå¤±**3éƒ¨åˆ†ç»„æˆã€‚

###### å†…å®¹æŸå¤±

```
def content_loss(Y_hat, Y):
    # æˆ‘ä»¬ä»åŠ¨æ€è®¡ç®—æ¢¯åº¦çš„æ ‘ä¸­åˆ†ç¦»ç›®æ ‡ï¼š
    # è¿™æ˜¯ä¸€ä¸ªè§„å®šçš„å€¼ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªå˜é‡ã€‚
    return torch.square(Y_hat - Y.detach()).mean()
```

###### é£æ ¼æŸå¤±

é€šè¿‡å¹³æ–¹è¯¯å·®å‡½æ•°è¡¡é‡åˆæˆå›¾åƒä¸é£æ ¼å›¾åƒåœ¨é£æ ¼ä¸Šçš„å·®å¼‚ã€‚ 

ä¸ºäº†è¡¨è¾¾é£æ ¼å±‚è¾“å‡ºçš„é£æ ¼ï¼Œæˆ‘ä»¬å…ˆé€šè¿‡`extract_features`å‡½æ•°è®¡ç®—é£æ ¼å±‚çš„è¾“å‡ºã€‚ å‡è®¾è¯¥è¾“å‡ºçš„æ ·æœ¬æ•°ä¸º1ï¼Œé€šé“æ•°ä¸ºğ‘ï¼Œé«˜å’Œå®½åˆ†åˆ«ä¸ºâ„å’Œğ‘¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ­¤è¾“å‡ºè½¬æ¢ä¸ºçŸ©é˜µğ‘‹ï¼Œå…¶æœ‰ğ‘è¡Œå’Œâ„ğ‘¤åˆ—ã€‚ 

è¿™ä¸ªçŸ©é˜µå¯ä»¥è¢«çœ‹ä½œç”±ğ‘ä¸ªé•¿åº¦ä¸ºâ„ğ‘¤çš„å‘é‡ğ‘¥1,â€¦,ğ‘¥ğ‘ç»„åˆè€Œæˆçš„ã€‚å…¶ä¸­å‘é‡ğ‘¥ğ‘–ä»£è¡¨äº†é€šé“ğ‘–ä¸Šçš„é£æ ¼ç‰¹å¾ã€‚

###### æ ¼æ‹‰å§†çŸ©é˜µï¼ˆGram matrixï¼‰

![image-20240725231641925](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240725231641925.png)

###### æ ¼æ‹‰å§†çŸ©é˜µå½’ä¸€åŒ–

![image-20240725231753335](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240725231753335.png)

```
def Gram(X):
	num_channels,n = X.shape[1],X.numel// X.shape[1]
	X = X.reshape((num_channels,n))
	return torch.matmul(X, X.T) / (num_channels * n)
def style_loss(Y_hat, gram_Y):
    return 
    torch.square(gram(Y_hat)-gram_Y.detach()).mean()
```

###### å…¨å˜åˆ†æŸå¤±

æœ‰æ—¶å€™ï¼Œæˆ‘ä»¬å­¦åˆ°çš„åˆæˆå›¾åƒé‡Œé¢æœ‰å¤§é‡é«˜é¢‘å™ªç‚¹ï¼Œå³æœ‰ç‰¹åˆ«äº®æˆ–è€…ç‰¹åˆ«æš—çš„é¢—ç²’åƒç´ ã€‚ ä¸€ç§å¸¸è§çš„å»å™ªæ–¹æ³•æ˜¯*å…¨å˜åˆ†å»å™ª*ï¼ˆtotal variation denoisingï¼‰ã€‚å…¨å˜åˆ†æŸå¤±çš„ç›®çš„æ˜¯é¼“åŠ±ç”Ÿæˆå›¾åƒçš„å¹³æ»‘æ€§ï¼ŒåŒæ—¶ä¿ç•™å›¾åƒçš„å…³é”®ç»“æ„ã€‚

![image-20240725232459534](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240725232459534.png)

![image-20240725232605643](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240725232605643.png)

```
def tv_loss(Y_hat):
    return 0.5 * (torch.abs(Y_hat[:, :, 1:, :] - Y_hat[:, :, :-1, :]).mean() +
                  torch.abs(Y_hat[:, :, :, 1:] - Y_hat[:, :, :, :-1]).mean())

```

æŸå¤±å‡½æ•°ï¼š**é£æ ¼è½¬ç§»çš„æŸå¤±å‡½æ•°æ˜¯å†…å®¹æŸå¤±ã€é£æ ¼æŸå¤±å’Œæ€»å˜åŒ–æŸå¤±çš„åŠ æƒå’Œ**

```
content_weight, style_weight, tv_weight = 1, 1e3, 10

def compute_loss(X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram):
    # åˆ†åˆ«è®¡ç®—å†…å®¹æŸå¤±ã€é£æ ¼æŸå¤±å’Œå…¨å˜åˆ†æŸå¤±
    contents_l = [content_loss(Y_hat, Y) * content_weight for Y_hat, Y in zip(
        contents_Y_hat, contents_Y)]
    styles_l = [style_loss(Y_hat, Y) * style_weight for Y_hat, Y in zip(
        styles_Y_hat, styles_Y_gram)]
    tv_l = tv_loss(X) * tv_weight
    # å¯¹æ‰€æœ‰æŸå¤±æ±‚å’Œ
    l = sum(10 * styles_l + contents_l + [tv_l])
    return contents_l, styles_l, tv_l, l
```

##### è®­ç»ƒæ¨¡å‹

```
def train(X, contents_Y, styles_Y, device, lr, num_epochs, lr_decay_epoch):
    X, styles_Y_gram, trainer = get_inits(X, device, lr, styles_Y)
    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_decay_epoch, 0.8)
    animator = d2l.Animator(xlabel='epoch', ylabel='loss',
                            xlim=[10, num_epochs],
                            legend=['content', 'style', 'TV'],
                            ncols=2, figsize=(7, 2.5))
    for epoch in range(num_epochs):
        trainer.zero_grad()
        contents_Y_hat, styles_Y_hat = extract_features(
            X, content_layers, style_layers)
        contents_l, styles_l, tv_l, l = compute_loss(
            X, contents_Y_hat, styles_Y_hat, contents_Y, styles_Y_gram)
        l.backward()
        trainer.step()
        scheduler.step()
        if (epoch + 1) % 10 == 0:
            animator.axes[1].imshow(postprocess(X))
            animator.add(epoch + 1, [float(sum(contents_l)),
                                     float(sum(styles_l)), float(tv_l)])
    return X
```



# å¾ªç¯ç¥ç»ç½‘ç»œ

## åºåˆ—æ¨¡å‹

### åºåˆ—æ•°æ®

- å®é™…ä¸­å¾ˆå¤šæ•°æ®æ˜¯æœ‰æ—¶åºçš„
- ç”µå½±çš„è¯„ä»·éšæ—¶é—´å˜åŒ–è€Œå˜åŒ–
  - æ‹¿äº†å¥–åè¯„åˆ†ä¸Šå‡ï¼Œç›´åˆ°å¥–é¡¹è¢«é—å¿˜
  - çœ‹äº†å¾ˆå¤šå¥½ç”µå½±åï¼Œäººä»¬çš„æœŸæœ›å˜é«˜
  - å­£èŠ‚æ€§ï¼šè´ºå²ç‰‡ï¼Œæš‘æœŸæ¡£
  - å¯¼æ¼”ã€æ¼”å‘˜çš„è´Ÿé¢æŠ¥é“å¯¼è‡´è¯„åˆ†å˜ä½

#### æ›´å¤šä¾‹å­

- éŸ³ä¹ã€æ–‡æœ¬ã€è¯­è¨€å’Œè§†é¢‘éƒ½æ˜¯è¿ç»­çš„
  - æ ‡é¢˜â€œç‹—å’¬äººâ€è¿œæ²¡æœ‰â€œäººå’¬ç‹—â€é‚£ä¹ˆä»¤äººæƒŠè®¶
- å¤§åœ°éœ‡å‘ç”Ÿåï¼Œå¾ˆæœ‰å¯èƒ½ä¼šæœ‰å‡ æ¬¡è¾ƒå°çš„ä½™éœ‡
- äººçš„äº’åŠ¨æ˜¯è¿ç»­çš„ï¼Œä»ç½‘ä¸Šåµæ¶å¯ä»¥çœ‹å‡º
- é¢„æµ‹æ˜å¤©çš„è‚¡ä»·è¦æ¯”å¡«è¡¥æ˜¨å¤©é—å¤±çš„è‚¡ä»·æ›´å›°éš¾

### ç»Ÿè®¡å·¥å…·

è¿™Tä¸ªæ•°æ®æ˜¯ä¸ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œè¿™æ˜¯åºåˆ—æ¨¡å‹ç‹¬ç‰¹çš„ä¸€ç‚¹ã€‚æˆ‘ä»¬å¯¹è¿™æ ·çš„å˜é‡åšæ¡ä»¶æ¦‚ç‡ã€‚

- åœ¨æ—¶é—´tè§‚å¯Ÿåˆ°[![X_{t}](https://camo.githubusercontent.com/a6b078b3e9cfbca5273206a921e9d5ca1c7164b9d0df475c706c0853ac54ce62/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f585f7b747d)](https://camo.githubusercontent.com/a6b078b3e9cfbca5273206a921e9d5ca1c7164b9d0df475c706c0853ac54ce62/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f585f7b747d)ï¼Œé‚£ä¹ˆå¾—åˆ°Tä¸ªä¸ç‹¬ç«‹çš„éšæœºå˜é‡ã€‚è¯·æ³¨æ„ï¼Œğ‘¡å¯¹äºæœ¬æ–‡ä¸­çš„åºåˆ—é€šå¸¸æ˜¯ç¦»æ•£çš„ï¼Œå¹¶åœ¨æ•´æ•°æˆ–å…¶å­é›†ä¸Šå˜åŒ–ã€‚ [![(X_{1},...X_{t})\sim p(X)](https://camo.githubusercontent.com/0823b3b6d3c561bf006d83ea097956be13243e4df9f6b1bc1822eef85c3f98fc/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f28585f7b317d2c2e2e2e585f7b747d295c73696d2673706163653b70285829)](https://camo.githubusercontent.com/0823b3b6d3c561bf006d83ea097956be13243e4df9f6b1bc1822eef85c3f98fc/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f28585f7b317d2c2e2e2e585f7b747d295c73696d2673706163653b70285829)

- ä½¿ç”¨æ¡ä»¶æ¦‚ç‡å±•å¼€

  ![p(a,b)=p(a)p(b|a)=p(b)p(a|b)](https://camo.githubusercontent.com/ae9f738f89f4a2a6e6da4e9214b40976dd46f21af02a1433bf2f7a5eadf5b5a2/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f7028612c62293d702861297028627c61293d702862297028617c6229)

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/51/51-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/51/51-01.png)

### åºåˆ—æ¨¡å‹

è‡ªå›å½’æ¨¡å‹ï¼šé¢„æµ‹æŸä¸ªæ•°æ®æ—¶ï¼Œä¸è°ƒç”¨å…¶ä»–æ•°æ®ï¼Œè€Œé‡‡ç”¨è¯¥æ•°æ®å‰é¢çš„æ•°æ®ã€‚



[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/51/51-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/51/51-02.png)

- å¯¹æ¡ä»¶æ¦‚ç‡å»ºæ¨¡

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/51/51-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/51/51-03.png)

#### æ–¹æ¡ˆA:é©¬å°”ç§‘å¤«å‡è®¾



[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/51/51-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/51/51-04.png)

- å‡è®¾å½“å‰æ•°æ®**åªè·ŸÏ„ä¸ªè¿‡å»æ•°æ®ç‚¹ç›¸å…³**

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/51/51-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/51/51-05.png)

![image-20240726113147509](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240726113147509.png)

#### æ–¹æ¡ˆB:æ½œå˜é‡æ¨¡å‹

æ˜¯ä¿ç•™ä¸€äº›å¯¹**è¿‡å»è§‚æµ‹çš„æ€»ç»“â„ğ‘¡**ï¼Œ **å¹¶ä¸”åŒæ—¶æ›´æ–°é¢„æµ‹ğ‘¥ğ‘¡å’Œæ€»ç»“â„ğ‘¡**ã€‚ è¿™å°±äº§ç”Ÿäº†åŸºäºğ‘¥^ğ‘¡=ğ‘ƒ(ğ‘¥ğ‘¡âˆ£â„ğ‘¡)ä¼°è®¡ğ‘¥ğ‘¡ï¼Œ ä»¥åŠå…¬å¼â„ğ‘¡=ğ‘”(â„ğ‘¡âˆ’1,ğ‘¥ğ‘¡âˆ’1)æ›´æ–°çš„æ¨¡å‹ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/51/51-06.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/51/51-06.png)

- å¼•å…¥æ½œå˜é‡ï¼Œæ½œå˜é‡æ˜¯å¯¹å†å²ä¿¡æ¯çš„è®°å½•ï¼›æ½œå˜é‡æ˜¯ç”±ä¸Šä¸€ä¸ªæ½œå˜é‡å’Œä¸Šä¸€ä¸ªæ—¶é—´ç‚¹æ¨ç®—å¾—å‡ºçš„ã€‚

  ![h_{t}](https://camo.githubusercontent.com/7c2a48b1354ae91f91c4bc95fc0bb6b8b1e97687dbeb2542811a438c934dace1/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685f7b747d)

  æ¥è¡¨ç¤ºè¿‡å»ä¿¡æ¯

  ![h_{t}=f(x_{1},...x_{t-1})](https://camo.githubusercontent.com/2097047baee3ee12ab5dd1a6c6da5ddb8e463184e83e46a2e2c58261dc2b1ce8/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f685f7b747d3d6628785f7b317d2c2e2e2e785f7b742d317d29)

  - è¿™æ ·[![x_{t}=p(x_{t}|h_{t})](https://camo.githubusercontent.com/c75dd808b220d03ff8eeba6a816465c31a9d10f6900f6f1f3e856efd62915ba0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f785f7b747d3d7028785f7b747d7c685f7b747d29)](https://camo.githubusercontent.com/c75dd808b220d03ff8eeba6a816465c31a9d10f6900f6f1f3e856efd62915ba0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f785f7b747d3d7028785f7b747d7c685f7b747d29)

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/51/51-07.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/51/51-07.png)

### æ€»ç»“

- æ—¶åºæ¨¡å‹ä¸­ï¼Œå½“å‰æ•°æ®è·Ÿä¹‹å‰è§‚å¯Ÿåˆ°çš„æ•°æ®ç›¸å…³
- è‡ªå›å½’æ¨¡å‹ä½¿ç”¨è‡ªèº«è¿‡å»æ•°æ®æ¥é¢„æµ‹æœªæ¥
- é©¬å°”ç§‘å¤«æ¨¡å‹å‡è®¾å½“å‰åªè·Ÿæœ€è¿‘å°‘æ•°æ•°æ®ç›¸å…³ï¼Œä»è€Œç®€åŒ–æ¨¡å‹
- æ½œå˜é‡æ¨¡å‹ä½¿ç”¨æ½œå˜é‡æ¥æ¦‚æ‹¬å†å²ä¿¡æ¯

### ä»£ç 

**ä½¿ç”¨é©¬å°”å¯å¤«å‡è®¾æ¥é¢„æµ‹æ¨¡å‹ï¼Œ**ä½¿ç”¨æ­£å¼¦å‡½æ•°å’Œä¸€äº›å¯åŠ æ€§å™ªå£°æ¥ç”Ÿæˆåºåˆ—æ•°æ®ï¼Œ æ—¶é—´æ­¥ä¸º1,2,â€¦,1000ã€‚

```
T = 1000
time = torch.arange(1,T+1,dtype = torch.float32)
X = torch.sin(0.01*T)+torch.normal(0,0.2,(T,))
```

å°†è¿™ä¸ªåºåˆ—è½¬æ¢ä¸ºæ¨¡å‹çš„*ç‰¹å¾ï¼æ ‡ç­¾*ï¼ˆfeature-labelï¼‰å¯¹ã€‚ åŸºäºåµŒå…¥ç»´åº¦ğœï¼Œæˆ‘ä»¬[**å°†æ•°æ®æ˜ å°„ä¸ºæ•°æ®å¯¹ğ‘¦ğ‘¡=ğ‘¥ğ‘¡ å’Œğ‘¥ğ‘¡=[ğ‘¥ğ‘¡âˆ’ğœ,â€¦,ğ‘¥ğ‘¡âˆ’1]ã€‚**] 

ç¼ºå°‘ğœä¸ªæ•°æ®æ ·æœ¬ï¼šä¸¢å¼ƒï¼›ç”¨0å¡«å……ã€‚

```
tau = 4
features = torch.zeros((T-tau,tau))
for i in range(tau):
	features[:,i] = X[i:i+T-tau]
labels = x[tau:].reshape((-1,1))
```

```
batch_size, n_train = 16, 600
# åªæœ‰å‰n_trainä¸ªæ ·æœ¬ç”¨äºè®­ç»ƒ
train_iter = d2l.load_array((features[:n_train], labels[:n_train]), batch_size, is_train=True)

'''åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬[ä½¿ç”¨ä¸€ä¸ªç›¸å½“ç®€å•çš„æ¶æ„è®­ç»ƒæ¨¡å‹ï¼š ä¸€ä¸ªæ‹¥æœ‰ä¸¤ä¸ªå…¨è¿æ¥å±‚çš„å¤šå±‚æ„ŸçŸ¥æœº]ï¼ŒReLUæ¿€æ´»å‡½æ•°å’Œå¹³æ–¹æŸå¤±ã€‚'''
# åˆå§‹åŒ–ç½‘ç»œæƒé‡çš„å‡½æ•°
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.xavier_uniform_(m.weight)

# ä¸€ä¸ªç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœº
def get_net():
    net = nn.Sequential(nn.Linear(4, 10),
                        nn.ReLU(),
                        nn.Linear(10, 1))
    net.apply(init_weights)
    return net

# å¹³æ–¹æŸå¤±ã€‚æ³¨æ„ï¼šMSELossè®¡ç®—å¹³æ–¹è¯¯å·®æ—¶ä¸å¸¦ç³»æ•°1/2
loss = nn.MSELoss(reduction='none')

# è®­ç»ƒæ¨¡å‹
def train(net, train_iter, loss, epochs, lr):
    trainer = torch.optim.Adam(net.parameters(), lr)
    for epoch in range(epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.sum().backward()
            trainer.step()
        print(f'epoch {epoch + 1}, '
              f'loss: {d2l.evaluate_loss(net, train_iter, loss):f}')

net = get_net()
train(net, train_iter, loss, 5, 0.01)
```

##### é¢„æµ‹

é¦–å…ˆæ˜¯æ£€æŸ¥[**æ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥**]çš„èƒ½åŠ›ï¼Œ ä¹Ÿå°±æ˜¯*å•æ­¥é¢„æµ‹*ï¼ˆone-step-ahead predictionï¼‰ã€‚

```
onestep_preds = net(features)
d2l.plot([time,time[tau:]],'time','x',legend = ['data','1-step preds'],xlim=[1,1000],figsize=(6,3))
```

é€šå¸¸ï¼Œå¯¹äºç›´åˆ°ğ‘¥ğ‘¡çš„è§‚æµ‹åºåˆ—ï¼Œå…¶åœ¨æ—¶é—´æ­¥ğ‘¡+ğ‘˜å¤„çš„é¢„æµ‹è¾“å‡ºğ‘¥^ğ‘¡+ğ‘˜ ç§°ä¸ºğ‘˜*æ­¥é¢„æµ‹*ï¼ˆğ‘˜-step-ahead-predictionï¼‰ã€‚ ç”±äºæˆ‘ä»¬çš„è§‚å¯Ÿå·²ç»åˆ°äº†ğ‘¥604ï¼Œå®ƒçš„ğ‘˜æ­¥é¢„æµ‹æ˜¯ğ‘¥^604+ğ‘˜ã€‚ æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬å¿…é¡»ä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„é¢„æµ‹ï¼ˆè€Œä¸æ˜¯åŸå§‹æ•°æ®ï¼‰æ¥[**è¿›è¡Œå¤šæ­¥é¢„æµ‹**]ã€‚ è®©æˆ‘ä»¬çœ‹çœ‹æ•ˆæœå¦‚ä½•ã€‚

```
multistep_preds = torch.zeros(T)
multistep_preds[: n_train + tau] = x[: n_train + tau]
for i in range(n_train + tau, T):
    multistep_preds[i] = net(
        multistep_preds[i - tau:i].reshape((1, -1)))
        
d2l.plot([time, time[tau:], time[n_train + tau:]],
         [x.detach().numpy(), onestep_preds.detach().numpy(),
          multistep_preds[n_train + tau:].detach().numpy()], 'time',
         'x', legend=['data', '1-step preds', 'multistep preds'],
         xlim=[1, 1000], figsize=(6, 3))
```

## æ–‡æœ¬é¢„å¤„ç†

æ•°æ®å­˜åœ¨è®¸å¤šç§å½¢å¼ï¼Œæ–‡æœ¬æ˜¯æœ€å¸¸è§ä¾‹å­ä¹‹ä¸€ã€‚ ä¾‹å¦‚ï¼Œä¸€ç¯‡æ–‡ç« å¯ä»¥è¢«ç®€å•åœ°çœ‹ä½œä¸€ä¸²å•è¯åºåˆ—ï¼Œç”šè‡³æ˜¯ä¸€ä¸²å­—ç¬¦åºåˆ—ã€‚ æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†è§£ææ–‡æœ¬çš„å¸¸è§é¢„å¤„ç†æ­¥éª¤ã€‚ è¿™äº›æ­¥éª¤é€šå¸¸åŒ…æ‹¬ï¼š

1. å°†æ–‡æœ¬ä½œä¸ºå­—ç¬¦ä¸²åŠ è½½åˆ°å†…å­˜ä¸­ã€‚
2. å°†å­—ç¬¦ä¸²æ‹†åˆ†ä¸ºè¯å…ƒï¼ˆå¦‚å•è¯å’Œå­—ç¬¦ï¼‰ã€‚
3. å»ºç«‹ä¸€ä¸ªè¯è¡¨ï¼Œå°†æ‹†åˆ†çš„è¯å…ƒæ˜ å°„åˆ°æ•°å­—ç´¢å¼•ã€‚
4. å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—ç´¢å¼•åºåˆ—ï¼Œæ–¹ä¾¿æ¨¡å‹æ“ä½œã€‚

#### è¯»å–æ•°æ®é›†

```
d2l.DATA_HUB["time_machine"] = (d2l.DATA_URL+"timemachine.txt"+'090b5e7e70c295757f55df93cb0a180b9691891a')

def read_time_machine():
	 with open(d2l.download('time_machine'), 'r') as f:
        lines = f.readlines()
    # import re: å¯¼å…¥ Python çš„æ­£åˆ™è¡¨è¾¾å¼åº“ï¼Œå…è®¸ä½ ä½¿ç”¨ re.sub() ç­‰å‡½æ•°
	return [re.sub('[^A-Za-z]+,'',line).strip().lower() for line in lines]
	
lines = read_time_machine()
print(f'# æ–‡æœ¬æ€»è¡Œæ•°: {len(lines)}')
print(lines[0])
print(lines[10])
```

#### è¯å…ƒåŒ–

- åˆ—è¡¨ä¸­çš„æ¯ä¸€ä¸ªâ€lineâ€œéƒ½æ˜¯ä¸€ä¸ªæ–‡æœ¬åºåˆ—/æ–‡æœ¬è¡Œ
- æ¯ä¸ªæ–‡æœ¬è¡Œä¼šè¢«æ‹†åˆ†æˆä¸€ä¸ªè¯å…ƒåˆ—è¡¨
- è¯å…ƒåˆ—è¡¨æ˜¯æ–‡æœ¬æœ€åŸºæœ¬çš„å•ä½

```
def tokennize(lines,token="word"):
	if token == "word":
		return [line.split() for line in lines]
	elif token == "char":
		return [list(line) for line in lines]
	else:
        print('é”™è¯¯ï¼šæœªçŸ¥è¯å…ƒç±»å‹ï¼š' + token)

tokens = tokenize(lines)
```

#### è¯è¡¨

**æ„å»ºä¸€ä¸ªå­—å…¸ï¼Œé€šå¸¸ä¹Ÿå«åšè¯è¡¨ï¼ˆvocabularyï¼‰ï¼Œ ç”¨æ¥å°†å­—ç¬¦ä¸²ç±»å‹çš„è¯å…ƒæ˜ å°„åˆ°ä»0å¼€å§‹çš„æ•°å­—ç´¢å¼•ä¸­**

å°†è®­ç»ƒé›†ä¸­çš„æ‰€æœ‰**æ–‡æ¡£åˆå¹¶**åœ¨ä¸€èµ·ï¼Œå¯¹å®ƒä»¬çš„**å”¯ä¸€è¯å…ƒè¿›è¡Œç»Ÿè®¡**ï¼Œ å¾—åˆ°çš„ç»Ÿè®¡ç»“æœç§°ä¹‹ä¸º***è¯­æ–™*ï¼ˆcorpusï¼‰**ã€‚ 

ç„¶åæ ¹æ®æ¯ä¸ªå”¯ä¸€è¯å…ƒçš„å‡ºç°é¢‘ç‡ï¼Œä¸ºå…¶**åˆ†é…ä¸€ä¸ªæ•°å­—ç´¢å¼•**ã€‚ å¾ˆå°‘å‡ºç°çš„è¯å…ƒé€šå¸¸è¢«ç§»é™¤ï¼Œè¿™å¯ä»¥é™ä½å¤æ‚æ€§ã€‚ å¦å¤–ï¼Œè¯­æ–™åº“ä¸­ä¸å­˜åœ¨æˆ–å·²åˆ é™¤çš„ä»»ä½•è¯å…ƒéƒ½å°†æ˜ å°„åˆ°ä¸€ä¸ªç‰¹å®šçš„æœªçŸ¥è¯å…ƒâ€œ<unk>â€ã€‚ æˆ‘ä»¬å¯ä»¥é€‰æ‹©å¢åŠ ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºä¿å­˜é‚£äº›è¢«ä¿ç•™çš„è¯å…ƒï¼Œ ä¾‹å¦‚ï¼šå¡«å……è¯å…ƒï¼ˆâ€œ<pad>â€ï¼‰ï¼› åºåˆ—å¼€å§‹è¯å…ƒï¼ˆâ€œ<bos>â€ï¼‰ï¼› åºåˆ—ç»“æŸè¯å…ƒï¼ˆâ€œ<eos>â€ï¼‰ã€‚

```python
class Vocab:
	def __init__(self,tokens=None,min_freq=0,reversed_token=None):
	if tokens is None:
        tokens = []
    if reserved_tokens is None:
        reserved_tokens = []
    counter = count_corpus(tokens)
    Counter = count_corpus(tokens)
    self._token_freqs = sorted(Counter.item(),key=lambda x:x[1],reversed=True)
    # æœªçŸ¥è¯å…ƒç´¢å¼•ä¸º 0
    self.idx_to_token = ['<unk>'] + reserved_tokens
    self.token_to_idx = {token:idx for idx,token in enumerate(self.idx_to_token)}
    
    for token,freq in self._token_freq:
        if freq < min_freq:
                break
         if token not in self.token_to_idx:
            self.idx_to_token.append(token)
            self.token_to_idx[token] = len(self.idx_to_token) - 1
              
    def __len__(self):
        return len(self.idx_to_token)

    def __getitem__(self, tokens):
        if not isinstance(tokens, (list, tuple)):
            return self.token_to_idx.get(tokens, self.unk)
        return [self.__getitem__(token) for token in tokens]
    
    def to_token(self,indices):
        if not isinstance(indices,(list,tuple))L
			return self.idx_to_token[indices]
		return [self.idx_to_token[index] for index in indices]   
    
    def unk(self):  # æœªçŸ¥è¯å…ƒçš„ç´¢å¼•ä¸º0
        return 0

    @property
    def token_freqs(self):
        return self._token_freqs
        
    
def count_corpus(tokens):
    """ç»Ÿè®¡è¯å…ƒçš„é¢‘ç‡"""
    if len(token) == 0 or isinstance(token[0],list):
        tokens = [token for line in tokens for token in line]
    return collection.Counter(tokens)
```

#### æ•´åˆæ‰€æœ‰åŠŸèƒ½

```
def load_corpus_time_machine(max_tokens=-1):  #@save
    """è¿”å›æ—¶å…‰æœºå™¨æ•°æ®é›†çš„è¯å…ƒç´¢å¼•åˆ—è¡¨å’Œè¯è¡¨"""
    # è¯»å–æ•°æ®é›†
    lines = read_time_machine()
    # è¯å…ƒåŒ–
    tokens = tokenize(lines, 'char')
    # æ„å»ºè¯è¡¨
    vocab = Vocab(tokens)
    # å› ä¸ºæ—¶å…‰æœºå™¨æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ–‡æœ¬è¡Œä¸ä¸€å®šæ˜¯ä¸€ä¸ªå¥å­æˆ–ä¸€ä¸ªæ®µè½ï¼Œ
    # æ‰€ä»¥å°†æ‰€æœ‰æ–‡æœ¬è¡Œå±•å¹³åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­
    corpus = [vocab[token] for line in tokens for token in line]
    if max_tokens > 0:
        corpus = corpus[:max_tokens]
    return corpus, vocab

corpus, vocab = load_corpus_time_machine()
len(corpus), len(vocab)
```

## è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›†

### ä»£ç 



## å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰

### ä½¿ç”¨æ½œå˜é‡

RNNä½¿ç”¨äº†éšè—å±‚æ¥è®°å½•è¿‡å»å‘ç”Ÿçš„æ‰€æœ‰äº‹ä»¶çš„ä¿¡æ¯ï¼Œä»è€Œå¼•å…¥æ—¶è®¸çš„ç‰¹æ€§ï¼Œå¹¶ä¸”é¿å…å¸¸è§„åºåˆ—æ¨¡å‹æ¯æ¬¡éƒ½è¦é‡æ–°è®¡ç®—å‰é¢æ‰€æœ‰å·²å‘ç”Ÿçš„äº‹ä»¶è€Œå¸¦æ¥çš„å·¨å¤§è®¡ç®—é‡ã€‚[![æˆªå±2022-02-12 ä¸‹åˆ2.17.32](https://github.com/kinza99/DeepLearning-MuLi-Notes/raw/main/imgs/54/54-01.png)](https://github.com/kinza99/DeepLearning-MuLi-Notes/blob/main/imgs/54/54-01.png)

xtä¸å½“å‰çŠ¶æ€çš„xt-1ä¸htç›¸å…³

htä¸å½“å‰çŠ¶æ€çš„xt-1ä¸ht-1ç›¸å…³

### RNN

- æˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°xï¼Œä¹Ÿæœ‰ä¸€ä¸ªæˆ‘ä»¬æ— æ³•è§‚å¯Ÿåˆ°ä½†æ˜¯å­˜åœ¨çš„hï¼ˆhidden_variableï¼‰
- æµç¨‹å¦‚ä¸‹ï¼Œé¦–å…ˆæœ‰ä¸€ä¸ªè¾“å…¥åºåˆ—ï¼Œå¯¹äºæ—¶åˆ»tï¼Œæˆ‘ä»¬ç”¨t-1æ—¶åˆ»çš„è¾“å…¥ x~t-1~ å’Œæ½œå˜é‡h~t-1~ æ¥è®¡ç®—æ–°çš„æ½œå˜é‡h~t~ã€‚åŒæ—¶ï¼Œç›´æ¥ä½¿ç”¨h~~t~~æ¥è®¡ç®—å¾—åˆ°tæ—¶åˆ»çš„è¾“å‡ºo~~t~~ã€‚æ³¨æ„ï¼Œè®¡ç®—ç¬¬ä¸€ä¸ªæ½œå˜é‡åªéœ€è¦è¾“å…¥å³å¯ï¼ˆå› ä¸ºå‰é¢å¹¶ä¸å­˜åœ¨ä»¥å¾€çš„æ½œå˜é‡ï¼‰ã€‚[![æˆªå±2022-02-12 ä¸‹åˆ2.34.14](https://github.com/kinza99/DeepLearning-MuLi-Notes/raw/main/imgs/54/54-02.png)](https://github.com/kinza99/DeepLearning-MuLi-Notes/blob/main/imgs/54/54-02.png)
- å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒRNNæœ¬è´¨ä¹Ÿæ˜¯ä¸€ç§MLPï¼Œå°¤å…¶æ˜¯å°†h~~t-1~~è¿™ä¸€é¡¹å»æ‰æ—¶å°±å®Œå…¨é€€åŒ–æˆäº†MLPã€‚RNNçš„æ ¸å¿ƒå…¶å®ä¹Ÿå°±æ˜¯h~~t-1~~è¿™ä¸€é¡¹ï¼Œå®ƒä½¿å¾—æ¨¡å‹å¯ä»¥å’Œå‰é¢çš„ä¿¡æ¯è”ç³»èµ·æ¥ï¼Œå°†æ—¶åºä¿¡æ¯å‚¨å­˜èµ·æ¥ï¼Œå¯ä»¥æŠŠRNNç†è§£ä¸ºæ˜¯åŒ…å«æ—¶åºä¿¡æ¯çš„MLPã€‚

### å›°æƒ‘åº¦

- ä¸ºäº†è¡¡é‡ä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„å¥½åï¼Œä¾‹å¦‚åˆ†ç±»æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨å¹³å‡äº¤å‰ç†µæ¥è¡¡é‡ï¼Œå°±æ˜¯å°†é¢„æµ‹æ¦‚ç‡çš„è´Ÿå¯¹æ•°å€¼æ±‚å’Œä¹‹åå†å»å¹³å‡ï¼Œå³å¸¸ç”¨çš„äº¤å‰ç†µæŸå¤±ã€‚ä½†æ˜¯ç”±äºæŸäº›å†å²åŸå› ï¼ŒNLPå¾€å¾€ä¸æ˜¯ç”¨è¿™ç§æ–¹å¼ï¼Œè€Œæ˜¯åœ¨è¿™ç§æ–¹å¼çš„åŸºç¡€ä¸Šæœ€åå†å–æŒ‡æ•°ï¼Œå³expï¼Œè¿™æ ·å¾—åˆ°çš„ç»“æœå¦‚æœæ˜¯1ï¼Œè¯´æ˜å®Œç¾ï¼›å¦‚æœæ˜¯æ— ç©·å¤§ï¼Œè¯´æ˜ç»“æœå¾ˆå·®ã€‚

### æ¢¯åº¦è£å‰ª

- åœ¨Tä¸ªæ—¶é—´æ­¥ä¸­è¿›è¡Œåå‘ä¼ æ’­ï¼Œä¼šç”±äºäº§ç”ŸO(T)é•¿åº¦çš„æ¢¯åº¦ä¹˜æ³•é“¾ï¼Œå¯¼è‡´å¯¼æ•°æ•°å€¼ä¸ç¨³å®š(æ¢¯åº¦çˆ†ç‚¸æˆ–æ¢¯åº¦æ¶ˆå¤±)ï¼Œè¿™é‡Œä½¿ç”¨ä¸€ä¸ªé™åˆ¶Î¸ï¼Œé€šå¸¸ä¸º5åˆ°10ï¼Œæ¥æ§åˆ¶æ¢¯åº¦ä¹˜æ³•é“¾çš„é•¿åº¦ã€‚ä½¿ç”¨å¦‚ä¸‹çš„å…¬å¼[![æˆªå±2022-02-12 ä¸‹åˆ3.10.38](https://github.com/kinza99/DeepLearning-MuLi-Notes/raw/main/imgs/54/54-03.png)](https://github.com/kinza99/DeepLearning-MuLi-Notes/blob/main/imgs/54/54-03.png)åœ¨è¿™ä¸ªå…¬å¼ä¸­ï¼Œå¦‚æœæ¢¯åº¦é•¿åº¦å¤§äºÎ¸ï¼Œæ¢¯åº¦gä¼šå˜ä¸º $$ \frac{\theta}{\Vert g \Vert} g $$ è¿™æ ·å†å¯¹gæ±‚2èŒƒå¼å°±å˜æˆäº†Î¸ï¼Œæ‰€ä»¥å¯ä»¥æŠŠæ¢¯åº¦é™åˆ¶åœ¨Î¸ä»¥ä¸‹ã€‚
- gä¸­è¡¨ç¤ºæ‰€æœ‰çš„æ¢¯åº¦åˆå¹¶åœ¨ä¸€èµ· 

### æ›´å¤šçš„åº”ç”¨RNNs

- åŸºæœ¬çš„åº”ç”¨å¦‚ä¸‹å›¾[![æˆªå±2022-02-12 ä¸‹åˆ3.36.29](https://github.com/kinza99/DeepLearning-MuLi-Notes/raw/main/imgs/54/54-04.png)](https://github.com/kinza99/DeepLearning-MuLi-Notes/blob/main/imgs/54/54-04.png)

### QAæ€»ç»“

- å¾ªç¯ç¥ç»ç½‘ç»œæ›´é€‚åˆå¤„ç†smoothçš„sequence
- å°è§„æ¨¡çš„æ¨¡å‹æ„å»ºåœ¨æ²¡æœ‰ç¡¬ä»¶æ”¯æŒçš„æƒ…å†µä¸‹æ›´é€‚åˆå»åšåº”ç”¨

### å¾ªç¯ç¥ç»ç½‘ç»œçš„ä»é›¶å¼€å§‹å®ç°

RNNæœ¬è´¨ä¸Šè·Ÿå…¶ä»–æ¨¡å‹æœ€å¤§çš„åŒºåˆ«å°±æ˜¯å¼•å…¥äº†åºåˆ—æ¨¡å‹ä¸­çš„æ½œå˜é‡æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªä¿¡æ¯ã€‚å¯¹äºæ½œå˜é‡ä¸­çš„åºåˆ—é€‰æ‹©ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ªæ¯”è¾ƒå¤§çš„batchä¸­é€‰å‡ºminibatchï¼Œè¿™ä¸ªminibatchå¯ä»¥æ˜¯éšæœºé€‰æ‹©ä¹Ÿå¯ä»¥æ˜¯è¿ç»­åˆ†å¸ƒã€‚

##### è¯»å–æ•°æ®

```
import math
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l

batch_size,num_step = 32,35
train_iter,vocab = d2l.load_data_time_machine(batch_size,num_steps)
```

##### one_hot encode

æˆ‘ä»¬å°†è¯å…ƒæ˜ å°„ä¸ºæ•°å­—ç´¢å¼•ï¼Œå†å°†å…¶é€šè¿‡**ç‹¬çƒ­ç¼–ç **è½¬å˜æˆæ›´å…·è¡¨ç°åŠ›çš„ç‰¹å¾å‘é‡ï¼šå°†æ¯ä¸ªç´¢å¼•æ˜ å°„ä¸ºç›¸äº’ä¸åŒçš„å•ä½å‘é‡ï¼š å‡è®¾è¯è¡¨ä¸­ä¸åŒè¯å…ƒçš„æ•°ç›®ä¸ºğ‘ï¼ˆå³`len(vocab)`ï¼‰ï¼Œ è¯å…ƒç´¢å¼•çš„èŒƒå›´ä¸º0åˆ°ğ‘âˆ’1ã€‚ å¦‚æœè¯å…ƒçš„ç´¢å¼•æ˜¯æ•´æ•°ğ‘–ï¼Œ é‚£ä¹ˆæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªé•¿åº¦ä¸ºğ‘çš„å…¨0å‘é‡ï¼Œ å¹¶å°†ç¬¬ğ‘–å¤„çš„å…ƒç´ è®¾ç½®ä¸º1ã€‚ æ­¤å‘é‡æ˜¯åŸå§‹è¯å…ƒçš„ä¸€ä¸ªç‹¬çƒ­å‘é‡ã€‚

```
X = torch.arange(10).reshape((2, 5))
F.one_hot(X.T, 28).shape
```

##### åˆå§‹åŒ–æ¨¡å‹å‚æ•°

ç‰¹åˆ«çš„åœ°æ–¹åœ¨äºéšè—å•å…ƒç»„çš„å¼•å…¥ï¼Œnum_hiddensæ˜¯ä¸€ä¸ªå¯è°ƒçš„è¶…å‚æ•°ï¼š

```
def get_param(vocab_size, num_hiddens, device):
	num_inputs = num_outputs = vocab_size
	def normal(shape):
		return torch.randn(size=shape,device=device).*0.0.1
		
	W_xh = normal((num_inputs,num_hiddens))
	W_hh = normal((num_hiddens,num_hiddens))
	b_h = torch.zeros(num_hiddens, device=device)
	
	W_hq = normal((num_hiddens, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)
    
    params = [W_xh, W_hh, b_h, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
    return params
```

é¦–å…ˆéœ€è¦[**ä¸€ä¸ª`init_rnn_state`å‡½æ•°åœ¨åˆå§‹åŒ–æ—¶è¿”å›éšçŠ¶æ€**]

```
def int__rnn_state(batch_size,num_hiddens,device):
	return (torch,zeros((batch_size,num_hiddens),device=device),)
```

**å®šä¹‰äº†å¦‚ä½•åœ¨ä¸€ä¸ªæ—¶é—´æ­¥å†…è®¡ç®—éšçŠ¶æ€å’Œè¾“å‡ºã€‚**è¿™é‡Œä½¿ç”¨tanhå‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚

```
def rnn(inputs,state,device):
	# inputs (æ—¶é—´æ­¥æ•°é‡ï¼Œæ‰¹é‡å¤§å°ï¼Œè¯è¡¨å¤§å°)
	W_xh, W_hh, W_hq, b_h, b_q = params
	H, = state
    outputs = []
    for X in inputs:
        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)
        Y = torch.mm(H, W_hq) + b_q
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H,)
```

**åˆ›å»ºä¸€ä¸ªç±»æ¥åŒ…è£…è¿™äº›å‡½æ•°**

```
class RNNModelScratch:
	def __init__(self,volcab_size,num_hiddens,device,gget_params,init_state,forward_fn):
	# å¯¹äºrnnï¼šè§„å®šè¯è¡¨å¤§å°ï¼Œéšå˜é‡æ•°é‡ï¼Œå„ç§è¿ç®—æ¨å¯¼å‚æ•°
	self.vocab_size, self.num_hiddens = vocab_size, num_hiddens
        self.params = get_params(vocab_size, num_hiddens, device)
        self.init_state, self.forward_fn = init_state, forward_fn
        
    def __call__(self,X,state):
    	X = F.one_hot(X.T,self.vocab_size).type(torch.float32)
    	
    def begin_state(self, batch_size, device):
    	return self.init_state(batch_size,self.num_hiddens,device)
```

#### é¢„æµ‹

**é¦–å…ˆå®šä¹‰é¢„æµ‹å‡½æ•°æ¥ç”Ÿæˆ`prefix`ä¹‹åçš„æ–°å­—ç¬¦**

å…¶ä¸­çš„`prefix`æ˜¯ä¸€ä¸ªç”¨æˆ·æä¾›çš„åŒ…å«å¤šä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚ åœ¨å¾ªç¯éå†`prefix`ä¸­çš„å¼€å§‹å­—ç¬¦æ—¶ï¼Œ æˆ‘ä»¬ä¸æ–­åœ°å°†éšçŠ¶æ€ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œä½†æ˜¯ä¸ç”Ÿæˆä»»ä½•è¾“å‡ºã€‚ è¿™è¢«ç§°ä¸º***é¢„çƒ­*ï¼ˆwarm-upï¼‰æœŸ**ï¼Œ å› ä¸ºåœ¨æ­¤æœŸé—´æ¨¡å‹ä¼šè‡ªæˆ‘æ›´æ–°ï¼ˆä¾‹å¦‚ï¼Œæ›´æ–°éšçŠ¶æ€ï¼‰ï¼Œ ä½†ä¸ä¼šè¿›è¡Œé¢„æµ‹ã€‚ é¢„çƒ­æœŸç»“æŸåï¼ŒéšçŠ¶æ€çš„å€¼é€šå¸¸æ¯”åˆšå¼€å§‹çš„åˆå§‹å€¼æ›´é€‚åˆé¢„æµ‹ï¼Œ ä»è€Œé¢„æµ‹å­—ç¬¦å¹¶è¾“å‡ºå®ƒä»¬ã€‚**æ›´æ–°å‚æ•°ã€‚**

```
def predict_ch8(prefix,num_preds,net,vocab,device):
	state = net.begin_state(batch_size=1,device=device)
	outputs[vocab[prefix[0]]]
	get_input = lambda torch.tensor([outputs[-1]],device=device).reshape(1,1)
	for y in prefix[1:]:
		_,state = net(get_input(),state)
		# å…ˆè½¬åŒ–æˆç´¢å¼•ï¼Œæœ‰åˆ©äºåæœŸé¢„æµ‹
		outputs.append(vocab[y])
	for _ in range(num_preds):
		y,state = net(get_input(),state)
		outputs.append(y.argmax(dim=1).reshape(1))
	return ''.join([vocab.idx_to_token[i] for i in outputs])
```

#### æ¢¯åº¦è£å‰ª

é€šè¿‡å°†æ¢¯åº¦ğ‘”æŠ•å½±å›ç»™å®šåŠå¾„ ï¼ˆä¾‹å¦‚ğœƒï¼‰çš„çƒæ¥è£å‰ªæ¢¯åº¦ğ‘”ã€‚ å¦‚ä¸‹å¼ï¼š

![image-20240727111721132](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240727111721132.png)

é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬çŸ¥é“**æ¢¯åº¦èŒƒæ•°æ°¸è¿œä¸ä¼šè¶…è¿‡ğœƒ**ï¼Œ å¹¶ä¸”æ›´æ–°åçš„æ¢¯åº¦å®Œå…¨ä¸ğ‘”çš„åŸå§‹æ–¹å‘å¯¹é½ã€‚ å®ƒè¿˜æœ‰ä¸€ä¸ªå€¼å¾—æ‹¥æœ‰çš„å‰¯ä½œç”¨ï¼Œ **å³é™åˆ¶ä»»ä½•ç»™å®šçš„å°æ‰¹é‡æ•°æ®ï¼ˆä»¥åŠå…¶ä¸­ä»»ä½•ç»™å®šçš„æ ·æœ¬ï¼‰å¯¹å‚æ•°å‘é‡çš„å½±å“**ï¼ˆæ„æ€å°±æ˜¯é™ä½å¼‚å¸¸ç‚¹çš„å½±å“ï¼‰ï¼Œ è¿™èµ‹äºˆäº†æ¨¡å‹ä¸€å®šç¨‹åº¦çš„ç¨³å®šæ€§ã€‚ æ¢¯åº¦è£å‰ªæä¾›äº†ä¸€ä¸ªå¿«é€Ÿä¿®å¤æ¢¯åº¦çˆ†ç‚¸çš„æ–¹æ³•ï¼Œ è™½ç„¶å®ƒå¹¶ä¸èƒ½å®Œå…¨è§£å†³é—®é¢˜ï¼Œä½†å®ƒæ˜¯ä¼—å¤šæœ‰æ•ˆçš„æŠ€æœ¯ä¹‹ä¸€ã€‚

```
def grad_clipping(net,theta):
	 if isinstance(net, nn.Module):
        params = [p for p in net.parameters() if p.requires_grad]
    else:
        params = net.params
    norm = torch.sqrt(torch.sum(p.grad**2) for p in params)
    if norm>theta:
		for param in params:
			param.grad[:]*=theta/norm
```

#### è®­ç»ƒ

##### **å®šä¹‰ä¸€ä¸ªå‡½æ•°åœ¨ä¸€ä¸ªè¿­ä»£å‘¨æœŸå†…è®­ç»ƒæ¨¡å‹**

1. åºåˆ—æ•°æ®çš„ä¸åŒé‡‡æ ·æ–¹æ³•ï¼ˆéšæœºé‡‡æ ·å’Œé¡ºåºåˆ†åŒºï¼‰å°†å¯¼è‡´éšçŠ¶æ€åˆå§‹åŒ–çš„å·®å¼‚ã€‚
2. æˆ‘ä»¬åœ¨æ›´æ–°æ¨¡å‹å‚æ•°ä¹‹å‰è£å‰ªæ¢¯åº¦ã€‚ è¿™æ ·çš„æ“ä½œçš„ç›®çš„æ˜¯ï¼Œå³ä½¿è®­ç»ƒè¿‡ç¨‹ä¸­æŸä¸ªç‚¹ä¸Šå‘ç”Ÿäº†æ¢¯åº¦çˆ†ç‚¸ï¼Œä¹Ÿèƒ½ä¿è¯æ¨¡å‹ä¸ä¼šå‘æ•£ã€‚
3. æˆ‘ä»¬ç”¨å›°æƒ‘åº¦æ¥è¯„ä»·æ¨¡å‹ã€‚å¦‚ :numref:`subsec_perplexity`æ‰€è¿°ï¼Œ è¿™æ ·çš„åº¦é‡ç¡®ä¿äº†ä¸åŒé•¿åº¦çš„åºåˆ—å…·æœ‰å¯æ¯”æ€§ã€‚

```
#@save
def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):
    """è®­ç»ƒç½‘ç»œä¸€ä¸ªè¿­ä»£å‘¨æœŸï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰"""
    state, timer = None, d2l.Timer()
    metric = d2l.Accumulator(2)  # è®­ç»ƒæŸå¤±ä¹‹å’Œ,è¯å…ƒæ•°é‡
    for X, Y in train_iter:
        if state is None or use  _random_iter:
            # åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æˆ–ä½¿ç”¨éšæœºæŠ½æ ·æ—¶åˆå§‹åŒ–state
            state = net.begin_state(batch_size=X.shape[0], device=device)
        else:
            if isinstance(net, nn.Module) and not isinstance(state, tuple):
                # stateå¯¹äºnn.GRUæ˜¯ä¸ªå¼ é‡
                state.detach_()
            else:
                # stateå¯¹äºnn.LSTMæˆ–å¯¹äºæˆ‘ä»¬ä»é›¶å¼€å§‹å®ç°çš„æ¨¡å‹æ˜¯ä¸ªå¼ é‡
                for s in state:
                    s.detach_()
        y = Y.T.reshape(-1)
        X, y = X.to(device), y.to(device)
        y_hat, state = net(X, state)
        l = loss(y_hat, y.long()).mean()
        if isinstance(updater, torch.optim.Optimizer):
            updater.zero_grad()
            l.backward()
            grad_clipping(net, 1)
            updater.step()
        else:
            l.backward()
            grad_clipping(net, 1)
            # å› ä¸ºå·²ç»è°ƒç”¨äº†meanå‡½æ•°
            updater(batch_size=1)
        metric.add(l * y.numel(), y.numel())
    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()
```

[**å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹çš„è®­ç»ƒå‡½æ•°æ—¢æ”¯æŒä»é›¶å¼€å§‹å®ç°ï¼Œ ä¹Ÿå¯ä»¥ä½¿ç”¨é«˜çº§APIæ¥å®ç°ã€‚**]

```
#@save
def train_ch8(net, train_iter, vocab, lr, num_epochs, device,
              use_random_iter=False):
    """è®­ç»ƒæ¨¡å‹ï¼ˆå®šä¹‰è§ç¬¬8ç« ï¼‰"""
    loss = nn.CrossEntropyLoss()
    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',
                            legend=['train'], xlim=[10, num_epochs])
    # åˆå§‹åŒ–
    if isinstance(net, nn.Module):
        updater = torch.optim.SGD(net.parameters(), lr)
    else:
        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)
    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)
    # è®­ç»ƒå’Œé¢„æµ‹
    for epoch in range(num_epochs):
        ppl, speed = train_epoch_ch8(
            net, train_iter, loss, updater, device, use_random_iter)
        if (epoch + 1) % 10 == 0:
            print(predict('time traveller'))
            animator.add(epoch + 1, [ppl])
    print(f'å›°æƒ‘åº¦ {ppl:.1f}, {speed:.1f} è¯å…ƒ/ç§’ {str(device)}')
    print(predict('time traveller'))
    print(predict('traveller'))
```

### å¾ªç¯ç¥ç»ç½‘ç»œçš„ç®€æ´å®ç°

```
num_hiddens = 256
rnn_layer = nn.RNN(len(vocab),num_hiddens)

state = torch.zeros(1,batch_size,num_hiddens)

'''é€šè¿‡ä¸€ä¸ªéšçŠ¶æ€å’Œä¸€ä¸ªè¾“å…¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨æ›´æ–°åçš„éšçŠ¶æ€è®¡ç®—è¾“å‡ºã€‚'''
X = torch.rand(size=(num_steps, batch_size, len(vocab)))
Y, state_new = rnn_layer(X, state)
```

[**æˆ‘ä»¬ä¸ºä¸€ä¸ªå®Œæ•´çš„å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰äº†ä¸€ä¸ª`RNNModel`ç±»**]ã€‚ æ³¨æ„ï¼Œ`rnn_layer`åªåŒ…å«éšè—çš„å¾ªç¯å±‚ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„è¾“å‡ºå±‚ã€‚

```
#@save
class RNNModel(nn.Module):
    """å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹"""
    def __init__(self, rnn_layer, vocab_size, **kwargs):
        super(RNNModel, self).__init__(**kwargs)
        self.rnn = rnn_layer
        self.vocab_size = vocab_size
        self.num_hiddens = self.rnn.hidden_size
        # å¦‚æœRNNæ˜¯åŒå‘çš„ï¼ˆä¹‹åå°†ä»‹ç»ï¼‰ï¼Œnum_directionsåº”è¯¥æ˜¯2ï¼Œå¦åˆ™åº”è¯¥æ˜¯1
        if not self.rnn.bidirectional:
            self.num_directions = 1
            self.linear = nn.Linear(self.num_hiddens, self.vocab_size)
        else:
            self.num_directions = 2
            self.linear = nn.Linear(self.num_hiddens * 2, self.vocab_size)

    def forward(self, inputs, state):
        X = F.one_hot(inputs.T.long(), self.vocab_size)
        X = X.to(torch.float32)
        Y, state = self.rnn(X, state)
        # å…¨è¿æ¥å±‚é¦–å…ˆå°†Yçš„å½¢çŠ¶æ”¹ä¸º(æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°,éšè—å•å…ƒæ•°)
        # å®ƒçš„è¾“å‡ºå½¢çŠ¶æ˜¯(æ—¶é—´æ­¥æ•°*æ‰¹é‡å¤§å°,è¯è¡¨å¤§å°)ã€‚
        output = self.linear(Y.reshape((-1, Y.shape[-1])))
        return output, state

    def begin_state(self, device, batch_size=1):
        if not isinstance(self.rnn, nn.LSTM):
            # nn.GRUä»¥å¼ é‡ä½œä¸ºéšçŠ¶æ€
            return  torch.zeros((self.num_directions * self.rnn.num_layers,
                                 batch_size, self.num_hiddens),
                                device=device)
        else:
            # nn.LSTMä»¥å…ƒç»„ä½œä¸ºéšçŠ¶æ€
            return (torch.zeros((
                self.num_directions * self.rnn.num_layers,
                batch_size, self.num_hiddens), device=device),
                    torch.zeros((
                        self.num_directions * self.rnn.num_layers,
                        batch_size, self.num_hiddens), device=device))
```



# ç°ä»£å¾ªç¯ç¥ç»ç½‘ç»œ

## GRU

### åŠ¨æœºï¼šå¦‚ä½•å…³æ³¨ä¸€ä¸ªåºåˆ—



- ä¸æ˜¯æ¯ä¸ªè§‚å¯Ÿå€¼éƒ½æ˜¯åŒç­‰é‡è¦

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/56/56-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/56/56-01.png)

æ¯”å¦‚ä¸Šå›¾ä¸­çš„åºåˆ—ï¼Œè‹¥å¹²ä¸ªçŒ«ä¸­å‡ºç°äº†ä¸€ä¸ªé¼ ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥é‡ç‚¹å…³æ³¨è¿™ä¸ªé¼ ï¼Œè€Œä¸­é—´é‡å¤å‡ºç°çš„çŒ«åˆ™å‡å°‘å…³æ³¨ã€‚æ–‡æœ¬åºåˆ—åŒç†ï¼Œé€šå¸¸é•¿æ–‡æœ¬æˆ‘ä»¬éœ€è¦å…³æ³¨çš„æ˜¯å‡ ä¸ªå…³é”®è¯ï¼Œå…³é”®å¥ã€‚

- æƒ³åªè®°ä½ç›¸å…³çš„è§‚å¯Ÿéœ€è¦ï¼š
  - èƒ½**å…³æ³¨**çš„æœºåˆ¶ï¼ˆ**æ›´æ–°é—¨**ï¼‰ï¼šé¡¾åæ€ä¹‰ï¼Œæ˜¯å¦éœ€è¦æ ¹æ®æˆ‘çš„è¾“å…¥ï¼Œæ›´æ–°éšè—çŠ¶æ€
  - èƒ½**é—å¿˜**çš„æœºåˆ¶ï¼ˆ**é‡ç½®é—¨**ï¼‰ï¼šæ›´æ–°å€™é€‰é¡¹æ—¶ï¼Œæ˜¯å¦è¦è€ƒè™‘å‰ä¸€éšè—çŠ¶æ€ã€‚

### é—¨çš„æ¦‚å¿µ

- æ›´æ–°é—¨Ztï¼Œé‡ç½®é—¨Rtçš„å…¬å¼å¤§ä½“ç›¸åŒï¼Œå”¯ä¸€ä¸åŒçš„æ˜¯å­¦ä¹ åˆ°çš„å‚æ•°ã€‚
- éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè®¡ç®—é—¨çš„æ–¹å¼å’ŒåŸæ¥RNNçš„å®ç°ä¸­è®¡ç®—æ–°çš„éšçŠ¶æ€ç›¸ä¼¼ï¼Œåªæ˜¯æ¿€æ´»å‡½æ•°æ”¹æˆäº†sigmoidã€‚
- é—¨æœ¬æ¥æ˜¯ç”µè·¯ä¸­çš„ä¸€ä¸ªæ¦‚å¿µï¼Œ0,1ä»£è¡¨ä¸åŒçš„ç”µå¹³ï¼Œå¯ä»¥ç”¨äºæ§åˆ¶ç”µè·¯çš„é€šæ–­ã€‚æ­¤å¤„sigmoidå°†é—¨çš„æ•°å€¼å½’ä¸€åŒ–åˆ°0åˆ°1ä¹‹é—´ï¼Œæ˜¯ä¸€ç§"è½¯æ›´æ–°"æ–¹å¼ã€‚è€Œä»åé¢çš„å…¬å¼ä¸Šå¯ä»¥çœ‹å‡ºï¼Œæœ¬è®²è¯¾ç¨‹é‡‡ç”¨çš„æ˜¯ä½ç”µå¹³æœ‰æ•ˆï¼ˆè¶Šé è¿‘0ï¼Œé—¨çš„ä½œç”¨è¶Šæ˜æ˜¾ï¼‰çš„æ–¹å¼æ§åˆ¶ã€‚

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/56/56-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/56/56-02.png)

### å€™é€‰éšçŠ¶æ€

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/56/56-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/56/56-03.png)

- å€™é€‰éšçŠ¶æ€ï¼Œå¦‚æœæŠ›å¼€å…¬å¼ä¸­çš„$R_{t}$é—å¿˜é—¨æ¥è¯´ï¼Œè¿™ä¸ªå’Œä¹‹å‰RNNä¸­è®¡ç®—å½“å‰æ­¥çš„éšçŠ¶æ€æ²¡æœ‰å·®åˆ«ã€‚
- ä½†æ˜¯è¿™é‡Œå¼•å…¥äº†é—å¿˜é—¨ï¼Œå¦‚æœ$R_{t}$æ— é™æ¥è¿‘äº0ï¼Œé‚£ä¹ˆæ­¤æ—¶å€™é€‰éšçŠ¶æ€å°†ä¸å†è€ƒè™‘å‰ä¸€éšçŠ¶æ€çš„å½±å“ï¼Œä¹Ÿå°±æ˜¯å’ŒMLPæ²¡æœ‰åŒºåˆ«ï¼Œèµ·åˆ°â€œé—å¿˜â€çš„ä½œç”¨ï¼›
- åä¹‹ï¼Œå¦‚æœ$R_{t}$æ— é™æ¥è¿‘äº1ï¼Œé‚£ä¹ˆä¸RNNè®¡ç®—éšçŠ¶æ€çš„è¿‡ç¨‹æ²¡æœ‰å·®åˆ«ï¼Œä¸è¿›è¡Œé—å¿˜ã€‚
- å…¬å¼ä¸­çš„âŠ™è¡¨ç¤ºé€å…ƒç´ ä¹˜ç§¯ã€‚

> ä¸ºä»€ä¹ˆå«å€™é€‰éšçŠ¶æ€ï¼Ÿ
>
> åœ¨RNNä¸­ï¼Œè¿™ä¸ªæ‰€è°“çš„å€™é€‰éšçŠ¶æ€å°±æ˜¯å½“å‰æ­¥çš„éšçŠ¶æ€ï¼ˆ$R_{t}$æ— é™æ¥è¿‘1æ—¶ï¼‰ã€‚ä½†æ˜¯ç”±äºå¼•å…¥äº†æ›´æ–°é—¨ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘æ˜¯ç›´æ¥æ²¿ç”¨ä¸Šä¸€æ­¥çš„éšè—çŠ¶æ€ï¼Œè¿˜æ˜¯åƒRNNä¸€æ ·ä½¿ç”¨å½“å‰æ­¥è®¡ç®—çš„éšçŠ¶æ€ã€‚æ‰€ä»¥è¿™ä¸ªç»“åˆäº†å½“å‰è¾“å…¥è®¡ç®—çš„éšçŠ¶æ€ï¼Œä¸èƒ½ç«‹é©¬å˜æˆå½“å‰çš„$H_{t}$ï¼Œè€Œæ˜¯éœ€è¦ç”¨æ›´æ–°é—¨å’Œå‰ä¸€éšçŠ¶æ€$H_{t-1}$åšä¸€ä¸ªåŠ æƒï¼Œæ‰€ä»¥å®ƒæ˜¯ä¸€ä¸ªå€™é€‰é¡¹ã€‚

### éšçŠ¶æ€

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/56/56-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/56/56-04.png)

ç”¨æ›´æ–°é—¨å¯¹**å€™é€‰éšçŠ¶æ€**å’Œ**å‰ä¸€éšçŠ¶æ€**åšåŠ æƒï¼Œå¾—åˆ°å½“å‰æ­¥**éšçŠ¶æ€**çš„å€¼ã€‚

å¦‚æœ$Z_{t}$æ— é™æ¥è¿‘äº0ï¼Œæ›´æ–°èµ·ä½œç”¨ï¼Œå€™é€‰éšçŠ¶æ€â€œè½¬æ­£â€ï¼Œå˜ä¸ºå½“å‰éšçŠ¶æ€ã€‚

å¦‚æœ$Z_{t}$æ— é™æ¥è¿‘äº1ï¼Œæ›´æ–°ä¸èµ·ä½œç”¨ï¼Œå½“å‰éšçŠ¶æ€è¿˜æ˜¯æ²¿ç”¨å‰ä¸€éšçŠ¶æ€ã€‚

### æ€»ç»“

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/56/56-05.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/56/56-05.png)

ä¸Šå›¾å››è¡Œå…¬å¼æ¦‚æ‹¬äº†GRUæ¨¡å‹ã€‚åœ¨RNNçš„åŸºç¡€ä¸Šï¼Œæœ€é‡è¦çš„æ˜¯å¼•å…¥äº†**æ›´æ–°é—¨å’Œé‡ç½®é—¨**ï¼Œæ¥å†³å®šå‰ä¸€éšçŠ¶æ€å¯¹å½“å‰éšçŠ¶æ€çš„å½±å“ã€‚ä»¥æœ€å¼€å§‹çš„çŒ«é¼ åºåˆ—çš„ä¾‹å­æ¥è¯´ï¼Œå¦‚æœæˆ‘çš„æ¨¡å‹ä¸€ç›´çœ‹åˆ°çŒ«ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°éšçŠ¶æ€ä¸æ€ä¹ˆå»æ›´æ–°ï¼Œäºæ˜¯éšçŠ¶æ€ä¸€ç›´ä¿ç•™äº†çŒ«çš„ä¿¡æ¯ï¼Œè€Œçœ‹åˆ°è€é¼ ï¼ŒéšçŠ¶æ€æ‰è¿›è¡Œæ›´æ–°ã€‚

- å¯¹äºä¸€ä¸ªæ›´å…·ä½“çš„ä¾‹å­è€Œè¨€(è¯­è¨€æ¨¡å‹)ï¼š

â€œThe cat, which already ate â€¦â€¦, __(is/ was) full.â€ï¼Œå‡è®¾æˆ‘çš„å¥å­å¾ˆé•¿ï¼Œé¢„æµ‹å®Œå‰é¢çš„è¯åéœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯isè¿˜æ˜¯wasï¼Œå¦‚æœå¼•å…¥è¿™ç§æ›´æ–°/é‡ç½®çš„æœºåˆ¶ï¼Œé‚£æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥åœ¨wasè¿™ä¸ªè¯ä¹‹å‰å°½å¯èƒ½å»ä¿æŒéšçŠ¶æ€çš„ä¿¡æ¯ï¼Œä»è€Œå³ä½¿é˜…è¯»äº†ä¸€ä¸ªå¾ˆé•¿çš„å®šè¯­ä»å¥ï¼Œä½†æˆ‘ä»¬è¿˜æ˜¯ä¿ç•™äº†catè¿™ä¸ªè¯çš„å•æ•°ä¿¡æ¯ï¼Œä»è€Œæ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ä¸º'was'ã€‚

- ä¸€ä¸ªä¸RNNçš„è”åŠ¨åœ¨äºï¼š

å¦‚æœæ›´æ–°é—¨å®Œå…¨å‘æŒ¥ä½œç”¨ï¼ˆæ— é™æ¥è¿‘äº0ï¼‰ï¼Œé‡ç½®é—¨ä¸èµ·ä½œç”¨ï¼ˆæ— é™æ¥è¿‘äº1ï¼‰ï¼Œæ­¤æ—¶GRUæ¨¡å‹é€€åŒ–ä¸ºRNNæ¨¡å‹ã€‚

## LSTM/é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ

### é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼š

- å¿˜è®°é—¨ï¼šå°†å€¼æœ0å‡å°‘
- è¾“å…¥é—¨ï¼šå†³å®šæ˜¯ä¸æ˜¯å¿½ç•¥æ‰è¾“å…¥æ•°æ®
- è¾“å‡ºé—¨ï¼šå†³å®šæ˜¯ä¸æ˜¯ä½¿ç”¨éšçŠ¶æ€

å¯ä»¥è¯´ï¼Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„è®¾è®¡çµæ„Ÿæ¥è‡ªäºè®¡ç®—æœºçš„é€»è¾‘é—¨ã€‚ é•¿çŸ­æœŸè®°å¿†ç½‘ç»œå¼•å…¥äº†*è®°å¿†å…ƒ*ï¼ˆmemory cellï¼‰ï¼Œæˆ–ç®€ç§°ä¸º*å•å…ƒ*ï¼ˆcellï¼‰ã€‚ æœ‰äº›æ–‡çŒ®è®¤ä¸ºè®°å¿†å…ƒæ˜¯éšçŠ¶æ€çš„ä¸€ç§ç‰¹æ®Šç±»å‹ï¼Œ å®ƒä»¬ä¸éšçŠ¶æ€å…·æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼Œå…¶è®¾è®¡ç›®çš„æ˜¯ç”¨äºè®°å½•é™„åŠ çš„ä¿¡æ¯ã€‚ ä¸ºäº†æ§åˆ¶è®°å¿†å…ƒï¼Œæˆ‘ä»¬éœ€è¦è®¸å¤šé—¨ã€‚ å…¶ä¸­ä¸€ä¸ªé—¨ç”¨æ¥ä»å•å…ƒä¸­è¾“å‡ºæ¡ç›®ï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸º*è¾“å‡ºé—¨*ï¼ˆoutput gateï¼‰ã€‚ å¦å¤–ä¸€ä¸ªé—¨ç”¨æ¥å†³å®šä½•æ—¶å°†æ•°æ®è¯»å…¥å•å…ƒï¼Œæˆ‘ä»¬å°†å…¶ç§°ä¸º*è¾“å…¥é—¨*ï¼ˆinput gateï¼‰ã€‚ æˆ‘ä»¬è¿˜éœ€è¦ä¸€ç§æœºåˆ¶æ¥é‡ç½®å•å…ƒçš„å†…å®¹ï¼Œç”±*é—å¿˜é—¨*ï¼ˆforget gateï¼‰æ¥ç®¡ç†ï¼Œ è¿™ç§è®¾è®¡çš„åŠ¨æœºä¸é—¨æ§å¾ªç¯å•å…ƒç›¸åŒï¼Œ èƒ½å¤Ÿé€šè¿‡ä¸“ç”¨æœºåˆ¶å†³å®šä»€ä¹ˆæ—¶å€™è®°å¿†æˆ–å¿½ç•¥éšçŠ¶æ€ä¸­çš„è¾“å…¥ã€‚ è®©æˆ‘ä»¬çœ‹çœ‹è¿™åœ¨å®è·µä¸­æ˜¯å¦‚ä½•è¿ä½œçš„ã€‚

#### é—¨ï¼š

è¾“å…¥é—¨ï¼š[![I_{t}=\sigma (X_{t}W_{xi}+H_{t-1}W_{hi}+b_{i})](https://camo.githubusercontent.com/5d35b6208b87b36a2fa57656db4d4e55d39d25dc8fc186a457e6c069822d04c3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f495f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78697d2b485f7b742d317d575f7b68697d2b625f7b697d29)](https://camo.githubusercontent.com/5d35b6208b87b36a2fa57656db4d4e55d39d25dc8fc186a457e6c069822d04c3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f495f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78697d2b485f7b742d317d575f7b68697d2b625f7b697d29)

å¿˜è®°é—¨ï¼š[![F_{t}=\sigma (X_{t}W_{xf}+H_{t-1}W_{hf}+b_{f})](https://camo.githubusercontent.com/edf8b8b9552b05ac6d234ebff09ed29f5839e6bb99ff8b01f612b82454df07b7/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f465f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78667d2b485f7b742d317d575f7b68667d2b625f7b667d29)](https://camo.githubusercontent.com/edf8b8b9552b05ac6d234ebff09ed29f5839e6bb99ff8b01f612b82454df07b7/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f465f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78667d2b485f7b742d317d575f7b68667d2b625f7b667d29)

è¾“å‡ºé—¨ï¼š[![O_{t}=\sigma (X_{t}W_{xo}+H_{t-1}W_{ho}+b_{o})](https://camo.githubusercontent.com/a3dd8360210665449e6f9cea6c7a021e02b9e073b3be3304647ee3aaf52649b0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f4f5f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b786f7d2b485f7b742d317d575f7b686f7d2b625f7b6f7d29)](https://camo.githubusercontent.com/a3dd8360210665449e6f9cea6c7a021e02b9e073b3be3304647ee3aaf52649b0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f4f5f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b786f7d2b485f7b742d317d575f7b686f7d2b625f7b6f7d29)

è¿™ä¸‰ä¸ªé—¨çš„ç®—å¼å’Œæ™®é€šRNNè®¡ç®—Htç®—å¼ç›¸åŒã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/57/57-1.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/57/57-1.png)

#### å€™é€‰è®°å¿†å•å…ƒ

[![\widetilde{C_{t}}=tanh(X_{t}W_{xc}+H_{t-1}W_{hc}+b_{c})](https://camo.githubusercontent.com/f3810cde80830d3ebbd78d3d2f1f446743b756a60d8c50ad08a536894f1e16dd/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7769646574696c64657b435f7b747d7d3d74616e6828585f7b747d575f7b78637d2b485f7b742d317d575f7b68637d2b625f7b637d29)](https://camo.githubusercontent.com/f3810cde80830d3ebbd78d3d2f1f446743b756a60d8c50ad08a536894f1e16dd/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7769646574696c64657b435f7b747d7d3d74616e6828585f7b747d575f7b78637d2b485f7b742d317d575f7b68637d2b625f7b637d29)

ç›¸å½“äºåœ¨ht-1åˆ°htçš„é¢„æµ‹ä¸­åˆåŠ äº†ä¸€å±‚éšè—å•å…ƒ

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/57/57-2.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/57/57-2.png)

#### è®°å¿†å•å…ƒ

[![C_{t}=F_{t}\odot C_{t-1}+I_{t}\odot \widetilde{C_{t}}](https://camo.githubusercontent.com/2adb443364832f22654c66bd08dabd2395344bb6a810e5478ec7f5a4bb32baf9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f435f7b747d3d465f7b747d5c6f646f742673706163653b435f7b742d317d2b495f7b747d5c6f646f742673706163653b5c7769646574696c64657b435f7b747d7d)](https://camo.githubusercontent.com/2adb443364832f22654c66bd08dabd2395344bb6a810e5478ec7f5a4bb32baf9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f435f7b747d3d465f7b747d5c6f646f742673706163653b435f7b742d317d2b495f7b747d5c6f646f742673706163653b5c7769646574696c64657b435f7b747d7d)

å¦‚æœé—å¿˜é—¨å§‹ç»ˆä¸º(1)ä¸”è¾“å…¥é—¨å§‹ç»ˆä¸º(0)ï¼Œ åˆ™è¿‡å»çš„è®°å¿†å…ƒ å°†éšæ—¶é—´è¢«ä¿å­˜å¹¶ä¼ é€’åˆ°å½“å‰æ—¶é—´æ­¥ã€‚ å¼•å…¥è¿™ç§è®¾è®¡æ˜¯ä¸ºäº†ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œ å¹¶æ›´å¥½åœ°æ•è·åºåˆ—ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/57/57-3.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/57/57-3.png)

#### éšçŠ¶æ€

[![H_{t}=O_{t}\odot tanh(C_{t})](https://camo.githubusercontent.com/baa39d3236644373134e79171faadd419e322913e8c6cf72dd1260c793dcb8ea/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f485f7b747d3d4f5f7b747d5c6f646f742673706163653b74616e6828435f7b747d29)](https://camo.githubusercontent.com/baa39d3236644373134e79171faadd419e322913e8c6cf72dd1260c793dcb8ea/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f485f7b747d3d4f5f7b747d5c6f646f742673706163653b74616e6828435f7b747d29)

æœ€åï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰å¦‚ä½•è®¡ç®—éšçŠ¶æ€ï¼Œ è¿™å°±æ˜¯è¾“å‡ºé—¨å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚ åœ¨é•¿çŸ­æœŸè®°å¿†ç½‘ç»œä¸­ï¼Œå®ƒä»…ä»…æ˜¯è®°å¿†å…ƒçš„çš„é—¨æ§ç‰ˆæœ¬ã€‚ è¿™å°±ç¡®ä¿äº†Htçš„å€¼å§‹ç»ˆåœ¨åŒºé—´((-1, 1))å†….

åªè¦è¾“å‡ºé—¨æ¥è¿‘1ï¼Œæˆ‘ä»¬å°±èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†æ‰€æœ‰è®°å¿†ä¿¡æ¯ä¼ é€’ç»™é¢„æµ‹éƒ¨åˆ†ï¼Œ è€Œå¯¹äºè¾“å‡ºé—¨æ¥è¿‘(0)ï¼Œæˆ‘ä»¬åªä¿ç•™è®°å¿†å…ƒå†…çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè€Œä¸éœ€è¦æ›´æ–°éšçŠ¶æ€ã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/57/57-4.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/57/57-4.png)

#### æ€»ç»“

LSTMçš„è®¡ç®—æµç¨‹ï¼š

[![I_{t}=\sigma (X_{t}W_{xi}+H_{t-1}W_{hi}+b_{i})](https://camo.githubusercontent.com/5d35b6208b87b36a2fa57656db4d4e55d39d25dc8fc186a457e6c069822d04c3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f495f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78697d2b485f7b742d317d575f7b68697d2b625f7b697d29)](https://camo.githubusercontent.com/5d35b6208b87b36a2fa57656db4d4e55d39d25dc8fc186a457e6c069822d04c3/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f495f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78697d2b485f7b742d317d575f7b68697d2b625f7b697d29)

[![F_{t}=\sigma (X_{t}W_{xf}+H_{t-1}W_{hf}+b_{f})](https://camo.githubusercontent.com/edf8b8b9552b05ac6d234ebff09ed29f5839e6bb99ff8b01f612b82454df07b7/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f465f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78667d2b485f7b742d317d575f7b68667d2b625f7b667d29)](https://camo.githubusercontent.com/edf8b8b9552b05ac6d234ebff09ed29f5839e6bb99ff8b01f612b82454df07b7/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f465f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b78667d2b485f7b742d317d575f7b68667d2b625f7b667d29)

[![O_{t}=\sigma (X_{t}W_{xo}+H_{t-1}W_{ho}+b_{o})](https://camo.githubusercontent.com/a3dd8360210665449e6f9cea6c7a021e02b9e073b3be3304647ee3aaf52649b0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f4f5f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b786f7d2b485f7b742d317d575f7b686f7d2b625f7b6f7d29)](https://camo.githubusercontent.com/a3dd8360210665449e6f9cea6c7a021e02b9e073b3be3304647ee3aaf52649b0/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f4f5f7b747d3d5c7369676d612673706163653b28585f7b747d575f7b786f7d2b485f7b742d317d575f7b686f7d2b625f7b6f7d29)

[![\widetilde{C_{t}}=tanh(X_{t}W_{xc}+H_{t-1}W_{hc}+b_{c})](https://camo.githubusercontent.com/f3810cde80830d3ebbd78d3d2f1f446743b756a60d8c50ad08a536894f1e16dd/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7769646574696c64657b435f7b747d7d3d74616e6828585f7b747d575f7b78637d2b485f7b742d317d575f7b68637d2b625f7b637d29)](https://camo.githubusercontent.com/f3810cde80830d3ebbd78d3d2f1f446743b756a60d8c50ad08a536894f1e16dd/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f5c7769646574696c64657b435f7b747d7d3d74616e6828585f7b747d575f7b78637d2b485f7b742d317d575f7b68637d2b625f7b637d29)

[![C_{t}=F_{t}\odot C_{t-1}+I_{t}\odot \widetilde{C_{t}}](https://camo.githubusercontent.com/2adb443364832f22654c66bd08dabd2395344bb6a810e5478ec7f5a4bb32baf9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f435f7b747d3d465f7b747d5c6f646f742673706163653b435f7b742d317d2b495f7b747d5c6f646f742673706163653b5c7769646574696c64657b435f7b747d7d)](https://camo.githubusercontent.com/2adb443364832f22654c66bd08dabd2395344bb6a810e5478ec7f5a4bb32baf9/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f435f7b747d3d465f7b747d5c6f646f742673706163653b435f7b742d317d2b495f7b747d5c6f646f742673706163653b5c7769646574696c64657b435f7b747d7d)

[![H_{t}=O_{t}\odot tanh(C_{t})](https://camo.githubusercontent.com/baa39d3236644373134e79171faadd419e322913e8c6cf72dd1260c793dcb8ea/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f485f7b747d3d4f5f7b747d5c6f646f742673706163653b74616e6828435f7b747d29)](https://camo.githubusercontent.com/baa39d3236644373134e79171faadd419e322913e8c6cf72dd1260c793dcb8ea/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e696d6167653f485f7b747d3d4f5f7b747d5c6f646f742673706163653b74616e6828435f7b747d29)

### ä»é›¶å®ç°

åŠ è½½æ—¶å…‰æœºå™¨æ•°æ®é›†

```
import torch
from torch import nn
from d2l import torch as d2l

batch_size, num_steps = 32, 35
train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)
```



#### åˆå§‹åŒ–æ¨¡å‹å‚æ•°



```
def get_lstm_params(vocab_size, num_hiddens, device):
    num_inputs = num_outputs = vocab_size

    def normal(shape):
        return torch.randn(size=shape, device=device)*0.01

    def three():
        return (normal((num_inputs, num_hiddens)),
                normal((num_hiddens, num_hiddens)),
                torch.zeros(num_hiddens, device=device))

    W_xi, W_hi, b_i = three()  # è¾“å…¥é—¨å‚æ•°
    W_xf, W_hf, b_f = three()  # é—å¿˜é—¨å‚æ•°
    W_xo, W_ho, b_o = three()  # è¾“å‡ºé—¨å‚æ•°
    W_xc, W_hc, b_c = three()  # å€™é€‰è®°å¿†å…ƒå‚æ•°
    # è¾“å‡ºå±‚å‚æ•°
    W_hq = normal((num_hiddens, num_outputs))
    b_q = torch.zeros(num_outputs, device=device)
    # é™„åŠ æ¢¯åº¦
    params = [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,
              b_c, W_hq, b_q]
    for param in params:
        param.requires_grad_(True)
    return params
```

#### å®šä¹‰æ¨¡å‹

åœ¨åˆå§‹åŒ–å‡½æ•°ä¸­ï¼Œ é•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„éšçŠ¶æ€éœ€è¦è¿”å›ä¸€ä¸ª*é¢å¤–*çš„è®°å¿†å…ƒï¼Œ å•å…ƒçš„å€¼ä¸º0ï¼Œå½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œéšè—å•å…ƒæ•°ï¼‰ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹çš„çŠ¶æ€åˆå§‹åŒ–ã€‚

```
def init_lstm_state(batch_size, num_hiddens, device):
    return (torch.zeros((batch_size, num_hiddens), device=device),
            torch.zeros((batch_size, num_hiddens), device=device))
```



å®é™…æ¨¡å‹çš„å®šä¹‰ä¸æˆ‘ä»¬å‰é¢è®¨è®ºçš„ä¸€æ ·ï¼š æä¾›ä¸‰ä¸ªé—¨å’Œä¸€ä¸ªé¢å¤–çš„è®°å¿†å…ƒã€‚ è¯·æ³¨æ„ï¼Œåªæœ‰éšçŠ¶æ€æ‰ä¼šä¼ é€’åˆ°è¾“å‡ºå±‚ï¼Œ è€Œè®°å¿†å…ƒ(\mathbf{C}_t)ä¸ç›´æ¥å‚ä¸è¾“å‡ºè®¡ç®—ã€‚

```
def lstm(inputs, state, params):
    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,
     W_hq, b_q] = params
    (H, C) = state
    outputs = []
    for X in inputs:
        I = torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)
        F = torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)
        O = torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)
        C_tilda = torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)
        C = F * C + I * C_tilda
        H = O * torch.tanh(C)
        Y = (H @ W_hq) + b_q
        outputs.append(Y)
    return torch.cat(outputs, dim=0), (H, C)
```

#### è®­ç»ƒå’Œé¢„æµ‹



```
vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()
num_epochs, lr = 500, 1
model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params,
                            init_lstm_state, lstm)
d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)
```

## æ·±å±‚å¾ªç¯ç¥ç»ç½‘ç»œ

### æ·±å±‚å¾ªç¯ç¥ç»ç½‘ç»œ



ä¹‹å‰è®²çš„RNNéƒ½åªæœ‰ä¸€ä¸ªéšè—å±‚ï¼ˆåºåˆ—å˜é•¿ä¸ç®—æ˜¯æ·±åº¦ï¼‰ï¼Œè€Œä¸€ä¸ªéšè—å±‚çš„RNNä¸€æ—¦åšçš„å¾ˆå®½å°±å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆã€‚å› æ­¤æˆ‘ä»¬è€ƒè™‘å°†ç½‘ç»œåšçš„æ›´æ·±è€Œéæ›´å®½ï¼Œæ¯å±‚éƒ½åªåšä¸€ç‚¹éçº¿æ€§ï¼Œé å±‚æ•°å åŠ å¾—åˆ°æ›´åŠ éçº¿æ€§çš„æ¨¡å‹ã€‚

æµ…RNNï¼šè¾“å…¥-éšå±‚-è¾“å‡º

æ·±RNNï¼šè¾“å…¥-éšå±‚-éšå±‚-...-è¾“å‡º

[![58-01](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/58/58-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/58/58-01.png)

ï¼ˆè¯¾ç¨‹è§†é¢‘ä¸­çš„å›¾ç‰‡æœ‰é”™è¯¯ï¼Œæœ€åè¾“å‡ºå±‚åä¸€æ—¶é—´æ­¥æ˜¯ä¸å—å‰ä¸€æ­¥å½±å“çš„ï¼Œå³æ²¡æœ‰ç®­å¤´ï¼‰

### å…¬å¼



[![img](https://camo.githubusercontent.com/9b91a12f1badf10aafaa7b2e12217ed91e3a40727e8f37ae90bf14cd9f440213/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436d6174686266253742482537445f74253545313d665f31282535436d6174686266253742485f253742742d31253744253545312537442c2535436d6174686266253742585f7425374429)](https://camo.githubusercontent.com/9b91a12f1badf10aafaa7b2e12217ed91e3a40727e8f37ae90bf14cd9f440213/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436d6174686266253742482537445f74253545313d665f31282535436d6174686266253742485f253742742d31253744253545312537442c2535436d6174686266253742585f7425374429)

*ç¬¬ä¸€å±‚çš„ç¬¬tæ­¥çŠ¶æ€æ˜¯å…³äºç¬¬ä¸€å±‚ç¬¬t-1æ­¥çŠ¶æ€å’Œç¬¬tæ­¥è¾“å…¥çš„å‡½æ•°*

[![img](https://camo.githubusercontent.com/9abfa1b6a822c9430f2f0d49337c239c2ec75ad481332296f63ad52f6300f8f8/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436d6174686266253742482537445f742535456a3d665f6a282535436d6174686266253742485f253742742d312537442535456a2537442c2535436d6174686266253742485f253742742537442535452537426a2d3125374429253744)](https://camo.githubusercontent.com/9abfa1b6a822c9430f2f0d49337c239c2ec75ad481332296f63ad52f6300f8f8/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436d6174686266253742482537445f742535456a3d665f6a282535436d6174686266253742485f253742742d312537442535456a2537442c2535436d6174686266253742485f253742742537442535452537426a2d3125374429253744)

*ç¬¬jå±‚çš„ç¬¬tæ­¥çŠ¶æ€æ˜¯å…³äºå½“å‰å±‚ä¸Šä¸€æ­¥æ­¥çŠ¶æ€å’Œä¸Šä¸€å±‚å½“å‰æ­¥çš„å‡½æ•°*

[![img](https://camo.githubusercontent.com/589fc00237965860b1afdb8c28ca04cffd0e18718bd273ae110640115e73a01c/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436d61746862662537424f2537445f743d67282535436d6174686266253742482537445f742535454c29)](https://camo.githubusercontent.com/589fc00237965860b1afdb8c28ca04cffd0e18718bd273ae110640115e73a01c/687474703a2f2f6c617465782e636f6465636f67732e636f6d2f7376672e6c617465783f2535436d61746862662537424f2537445f743d67282535436d6174686266253742482537445f742535454c29)

*ç”±æœ€åä¸€ä¸ªéšè—å±‚å¾—åˆ°è¾“å‡º*

### æ€»ç»“



- æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œä½¿ç”¨å¤šä¸ªéšè—å±‚æ¥è·å¾—æ›´å¤šçš„éçº¿æ€§æ€§

å°†RNN/GRU/LSTMåšæ·±éƒ½æ˜¯ä¸€ä¸ªé“ç†ï¼Œä¸‰è€…åªæ˜¯ä½¿ç”¨çš„å‡½æ•°fä¸åŒã€‚

## ç¼–ç å™¨-è§£ç å™¨æ¶æ„

### CNNä¸­çš„è§£é‡Š



è€ƒè™‘ä¸€ä¸ªCNNæ¨¡å‹ï¼š

[![CNN](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/61/CNN.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/61/CNN.png)

æ•´ä¸ªCNNå®é™…ä¸Šå¯ä»¥çœ‹ä½œä¸€ä¸ªç¼–ç å™¨ï¼Œè§£ç å™¨ä¸¤éƒ¨åˆ†ã€‚

- åº•å±‚çš„ç¥ç»ç½‘ç»œï¼Œä¹Ÿå°±æ˜¯ç¼–ç å™¨å°†è¾“å…¥ç¼–ç æˆèƒ½è¢«æ¨¡å‹è¯†åˆ«çš„ä¸­é—´è¡¨è¾¾å½¢å¼ï¼Œä¹Ÿå°±æ˜¯ç‰¹å¾
- è§£ç å™¨å°†ä¸­é—´ç»“æœè§£ç ä¸ºè¾“å‡º

### RNNä¸­çš„è§£é‡Š

å¯¹äºRNNè€Œè¨€ï¼ŒåŒæ ·æœ‰ç€ç±»ä¼¼çš„åˆ’åˆ†

[![RNN](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/61/RNN.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/61/RNN.png)

- ç¼–ç å™¨å°†è¾“å…¥æ–‡æœ¬è¡¨ç¤ºä¸ºå‘é‡
- è§£ç å™¨å°†å‘é‡è¡¨ç¤ºä¸ºè¾“å‡º

### æŠ½è±¡çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„

æŒ‡ä¸€ä¸ªæ¨¡å‹è¢«åˆ†ä¸ºä¸¤å—ï¼š

- ä¸€å—æ˜¯ç¼–ç å™¨ï¼Œä¹Ÿå«encoderï¼Œç”¨äºå°†è¾“å…¥å¤„ç†ä¸ºä¸€ä¸ªä¸­é—´çŠ¶æ€
- ä¸€å—æ˜¯è§£ç å™¨ï¼Œä¹Ÿå«decoderï¼Œç”¨äºå°†ä¸­é—´çŠ¶æ€è¡¨ç¤ºä¸ºè¾“å‡º
- è§£ç å™¨ä¹Ÿå¯ä»¥æœ‰é¢å¤–çš„è¾“å…¥æä¾›ä¿¡æ¯

[![encoder-decoder](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/61/encoder-decoder.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/61/encoder-decoder.png)

### ä»£ç 

```
from torch import nn

class EncoderDecoder(nn.Mudule):
	def __init__(self,encoder,decoder,**kwargs):
	super(EncoderDecoder,self).__init__(**kwargs)
	self.encoder=encoder
	self.decoder=decoder
	
	def forward(self,enc_X,dec_X,*args):
	enc_outputs = self.encoder(enc_X,*args)
	dec_state=self.decoder(enc_outputs,*args)
	return self.decoder(dec_X,dec_state)
```

## åºåˆ—åˆ°åºåˆ—å­¦ä¹ 

### åº”ç”¨ä¸¾ä¾‹ï¼šæœºå™¨ç¿»è¯‘

- ç»™å®šä¸€ä¸ªæºè¯­è¨€çš„å¥å­ï¼Œè‡ªåŠ¨ç¿»è¯‘æˆç›®æ ‡è¯­è¨€
- è¿™ä¸¤ä¸ªå¥å­å¯ä»¥æœ‰ä¸åŒçš„é•¿åº¦

### æ¨¡å‹æ¶æ„ï¼šSeq2seq

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/62/62-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/62/62-01.png)

- åºåˆ—åˆ°åºåˆ—æ¨¡å‹ç”±**ç¼–ç å™¨-è§£ç å™¨**æ„æˆã€‚
- **ç¼–ç å™¨**RNNå¯ä»¥æ˜¯**åŒå‘**ï¼Œç”±äºè¾“å…¥çš„å¥å­æ˜¯å®Œæ•´åœ°ï¼Œå¯ä»¥æ­£ç€çœ‹ï¼Œä¹Ÿå¯ä»¥åç€çœ‹ï¼›è€Œ**è§£ç å™¨**åªèƒ½æ˜¯**å•å‘**ï¼Œç”±äºé¢„æµ‹æ—¶ï¼Œåªèƒ½æ­£ç€å»é¢„æµ‹ã€‚
- ç¼–ç å™¨ï¼Œè§£ç å™¨é‡‡ç”¨**ä¸åŒçš„RNN**ï¼Œæ­¤RNNä¹Ÿå¯ä»¥æ˜¯GRUï¼ŒLSTMç­‰ã€‚

### ç¼–ç å™¨-è§£ç å™¨ç»†èŠ‚

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/62/62-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/62/62-02.png)

- ç¼–ç å™¨ï¼Œå°†é•¿åº¦ä¸å®šçš„è¾“å…¥å€¼æ”¾å…¥RNNï¼ˆæˆ–è€…å…¶ä»–æ¨¡å‹ï¼‰ï¼Œå°†å…¶è½¬åŒ–ä¸ºå›ºå®šå½¢çŠ¶çš„éšçŠ¶æ€ã€‚

![image-20240727224619101](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240727224619101.png)

- è§£ç å™¨çš„ç‰¹å®šè®¾è®¡å†³å®šï¼š1. <bos>è¡¨ç¤ºåºåˆ—å¼€å§‹è¯å…ƒï¼Œ<eos>è¡¨ç¤ºæ¨¡å‹åœæ­¢é¢„æµ‹ã€‚2.**ç¼–ç å™¨**çš„**æœ€åæ—¶é—´æ­¥çš„éšçŠ¶æ€**ç”¨ä½œ**è§£ç å™¨**çš„**åˆå§‹éšçŠ¶æ€**ï¼ˆå›¾ä¸­ç®­å¤´çš„ä¼ é€’ï¼‰ã€‚ç¼–ç å™¨è¿˜åŠ å…¥äº†è¾“å‡ºåºåˆ—å·²ç»ç”Ÿæˆè¯å…ƒæ¥è¿›è¡Œä¸‹ä¸€éƒ¨åˆ†çš„é¢„æµ‹ã€‚3.åœ¨å…¶ä»–è®¾è®¡ä¸­ï¼Œç¼–ç å™¨æœ€ç»ˆçš„éšè—å±‚åœ¨æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½å¯ä»¥ä½œä¸ºç¼–ç å™¨è¾“å…¥çŠ¶æ€çš„ä¸€éƒ¨åˆ†ã€‚

#### å®ç°å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨

ä½¿ç”¨äº†åµŒå…¥å±‚ï¼ˆembedding layerï¼‰æ¥è·å¾—è¾“å…¥åºåˆ—ä¸­æ¯ä¸ªè¯å…ƒçš„ç‰¹å¾å‘é‡ã€‚  åµŒå…¥å±‚çš„æƒé‡æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œ å…¶è¡Œæ•°ç­‰äºè¾“å…¥è¯è¡¨çš„å¤§å°ï¼ˆ`vocab_size`ï¼‰ï¼Œ å…¶åˆ—æ•°ç­‰äºç‰¹å¾å‘é‡çš„ç»´åº¦ï¼ˆ`embed_size`ï¼‰ã€‚ å¯¹äºä»»æ„è¾“å…¥è¯å…ƒçš„ç´¢å¼•ğ‘–ï¼Œ åµŒå…¥å±‚è·å–æƒé‡çŸ©é˜µçš„ç¬¬ğ‘–è¡Œï¼ˆä»0å¼€å§‹ï¼‰ä»¥è¿”å›å…¶ç‰¹å¾å‘é‡ã€‚ 

```
class seq2seqEncoder(d2l.Encoder):
	def __init__(self, vocab_size, embed_size, num_hiddens, 					num_layers, dropout=0, **kwargs):
        super(Seq2SeqEncoder, self).__init__(**kwargs)
        # åµŒå…¥å±‚
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,
                          dropout=dropout)
    def forward(self,X,*args):
    # åœ¨å¾ªç¯ç¥ç»ç½‘ç»œæ¨¡å‹ä¸­ï¼Œç¬¬ä¸€ä¸ªè½´å¯¹åº”äºæ—¶é—´æ­¥
   		X = self.embedding(X)
        X = X.permute(1,0,2)
        output,state = self.rnn(X)
        return output,state
    # output:ï¼ˆæ—¶é—´æ­¥æ•°ï¼Œæ‰¹é‡å¤§å°ï¼Œéšè—å•å…ƒæ•°ï¼‰
```

#### å®ç°å¾ªç¯ç¥ç»ç½‘ç»œç¼–ç å™¨

```
class Seq2SeqDecoder(d2l.Decoder):
    """ç”¨äºåºåˆ—åˆ°åºåˆ—å­¦ä¹ çš„å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨"""
	def __init__(self, vocab_size, embed_size, num_hiddens, 				num_layers, dropout=0, **kwargs):
        super(Seq2SeqDecoder, self).__init__(**kwargs)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(embed_size+num_hiddens, num_hiddens, 
        					num_layers, dropout=dropout)
        self.dense = nn.Linear(num_hiddens,vocab_size)
	def forward(self,X,*args):
   		X = self.embedding(X).permute(1,0,2)
   		# å¹¿æ’­contextï¼Œä½¿å…¶å…·æœ‰ä¸Xç›¸åŒçš„num_steps
   		context = state[-1].reshape(X.shape[0],1,1)
   		X_and_context = torch.cat((X,context),2)
   		output,state = self.rnn(X_and_context,state)
   		output = self.dense(output).permute(1,0,2)
   	return output,state
```

#### æŸå¤±å‡½æ•°

`sec_machine_translation`ä¸­ï¼Œ ç‰¹å®šçš„å¡«å……è¯å…ƒè¢«æ·»åŠ åˆ°åºåˆ—çš„æœ«å°¾ï¼Œ å› æ­¤ä¸åŒé•¿åº¦çš„åºåˆ—å¯ä»¥ä»¥ç›¸åŒå½¢çŠ¶çš„å°æ‰¹é‡åŠ è½½ã€‚ ä½†æ˜¯ï¼Œæˆ‘ä»¬åº”è¯¥å°†å¡«å……è¯å…ƒçš„é¢„æµ‹æ’é™¤åœ¨æŸå¤±å‡½æ•°çš„è®¡ç®—ä¹‹å¤–ã€‚

ä½¿ç”¨ä¸‹é¢çš„`sequence_mask`å‡½æ•° [**é€šè¿‡é›¶å€¼åŒ–å±è”½ä¸ç›¸å…³çš„é¡¹**]ï¼Œ ä»¥ä¾¿åé¢ä»»ä½•ä¸ç›¸å…³é¢„æµ‹çš„è®¡ç®—éƒ½æ˜¯ä¸é›¶çš„ä¹˜ç§¯ï¼Œç»“æœéƒ½ç­‰äºé›¶ã€‚ 

```python
def sequence_mask(X,valid_len,value=0):
	maxlen=X[1]
	mask = torch.arange(maxlen,dtype=torch.float32)[None,:]<valid_len[:,None]
	X[~mask] = value
	
class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):
    """å¸¦é®è”½çš„softmaxäº¤å‰ç†µæŸå¤±å‡½æ•°"""
    # predçš„å½¢çŠ¶ï¼š(batch_size,num_steps,vocab_size)
    # labelçš„å½¢çŠ¶ï¼š(batch_size,num_steps)
    # valid_lençš„å½¢çŠ¶ï¼š(batch_size,)
    def forward(self, pred, label, valid_len):
        weights = torch.one_like(label)
        weights = sequence(weight,valid_len)
        self.reduction='none'
        # pytorch éœ€è¦æŠŠé¢„æµ‹/è¾“å‡ºçš„ç»´åº¦æ”¾åˆ°ä¸­é—´
        unweighted_loss = super().forward(pred.permute(0, 2, 1), label)
        weighted_loss = (unweighted_loss * weights).mean(dim=1)
        return weighted_loss
```

### è®­ç»ƒå’Œæ¨ç†

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/62/62-03.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/62/62-03.png)

- æŸå¤±å‡½æ•°çš„è®¡ç®—åªå…³æ³¨è§£ç å™¨çš„è¾“å‡ºå±‚ã€‚
- è®­ç»ƒå’Œé¢„æµ‹ï¼ˆæ¨ç†ï¼‰æœ‰åŒºåˆ«çš„ï¼Œè®­ç»ƒæ—¶è§£ç å™¨ä½¿ç”¨ç›®æ ‡å¥å­ï¼ˆçœŸå€¼ï¼‰ä½œä¸ºè¾“å…¥ï¼Œä»¥æŒ‡å¯¼æ¨¡å‹è®­ç»ƒï¼›è€Œæ¨ç†æ—¶æ— æ³•æå‰å¾—çŸ¥çœŸå€¼ï¼Œéœ€è¦ä¸€æ­¥ä¸€æ­¥è¿›è¡Œé¢„æµ‹ã€‚

```
def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):
    """è®­ç»ƒåºåˆ—åˆ°åºåˆ—æ¨¡å‹"""
    # åˆå§‹åŒ–æƒé‡
    def xavier_init_weights(m):
    # é’ˆå¯¹å…¨è¿æ¥å±‚
        if type(m) == nn.Linear:
            nn.init.xavier_uniform_(m.weight)
    # é’ˆå¯¹RNN
        if type(m) == nn.GRU:
            for param in m._flat_weights_names:
                if "weight" in param:
                    nn.init.xavier_uniform_(m._parameters[param])

    net.apply(xavier_init_weights)
    net.to(device)
    optimizer = torch.optim.Adam(net.parameters(), lr=lr)
    # å¼•å…¥æ©ç äº¤å‰ç†µ
    loss = MaskedSoftmaxCELoss()
    net.train()
    animator = d2l.Animator(xlabel='epoch', ylabel='loss',
                     xlim=[10, num_epochs])
    for epoch in range(num_epochs):
        timer = d2l.Timer()
        metric = d2l.Accumulator(2)  # è®­ç»ƒæŸå¤±æ€»å’Œï¼Œè¯å…ƒæ•°é‡
        for batch in data_iter:
            optimizer.zero_grad()
            
            # è¾“å…¥åºåˆ— Xï¼Œè¾“å…¥åºåˆ—çš„æœ‰æ•ˆé•¿åº¦ X_valid_lenï¼Œç›®æ ‡åºåˆ— Yï¼Œå’Œç›®æ ‡åºåˆ—çš„æœ‰æ•ˆé•¿åº¦ Y_valid_len
            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]
            # Y.shape[0]æ˜¯ä»£è¡¨æœ‰å¤šå°‘ä¸ªè¾“å‡ºè¯­å¥ï¼Œåˆ™å¯¹åº”æˆ‘ä»¬æœ‰å¤šå°‘ä¸ªboså¼€å§‹ï¼Œæœ€ååšæˆä¸€åˆ—
            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],
                          device=device).reshape(-1, 1)
            # å°†å¼€å§‹ç¬¦å·boså’Œæˆ‘ä»¬çš„Yç›®æ ‡åºåˆ—ï¼Œå»é™¤æ‰æœ€åä¸€ä¸ªæˆ‘ä»¬éœ€è¦é¢„æµ‹çš„éƒ¨åˆ†
            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # å¼ºåˆ¶æ•™å­¦
            # ç”Ÿæˆé¢„æµ‹å€¼
            Y_hat, _ = net(X, dec_input, X_valid_len)
            # Y_valid_len éå¿…è¦éƒ¨åˆ†ä¸ç®—loss
            l = loss(Y_hat, Y, Y_valid_len)
            
            l.sum().backward()	# æŸå¤±å‡½æ•°çš„æ ‡é‡è¿›è¡Œâ€œåå‘ä¼ æ’­â€
            d2l.grad_clipping(net, 1)
            num_tokens = Y_valid_len.sum()
            optimizer.step()
            with torch.no_grad():
                metric.add(l.sum(), num_tokens)
        if (epoch + 1) % 10 == 0:
            animator.add(epoch + 1, (metric[0] / metric[1],))
    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '
        f'tokens/sec on {str(device)}')
```

#### é¢„æµ‹

```
def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,
                    device, save_attention_weights=False):
    """åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„é¢„æµ‹"""
    # åœ¨é¢„æµ‹æ—¶å°†netè®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    net.eval()
    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [ src_vocab['<eos>']]
    enc_valid_len = torch.tensor([len(src_tokens)], device=device)
    
    â€™â€˜â€™
    è¿™å¥è¯çš„ä½œç”¨æ˜¯å°†è¾“å…¥çš„æºåºåˆ— src_tokens æˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šé•¿åº¦ num_stepsã€‚
	å¦‚æœ src_tokens çš„é•¿åº¦å°äº num_stepsï¼Œåˆ™ä½¿ç”¨ src_vocab['<pad>']ï¼ˆå¡«å……æ ‡è®°ï¼‰å¡«å……è‡³ num_stepsã€‚
	å¦‚æœé•¿åº¦è¶…è¿‡ num_stepsï¼Œåˆ™å°†åºåˆ—æˆªæ–­åˆ° num_steps çš„é•¿åº¦ã€‚
	â€˜â€™â€˜
    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])
    
    # æ·»åŠ æ‰¹é‡è½´
    # torch.unsqueeze ç”¨äºåœ¨æŒ‡å®šçš„ç»´åº¦ä¸Šå¢åŠ ä¸€ä¸ªç»´åº¦ã€‚
    enc_X = torch.unsqueeze(
        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)
        
    enc_outputs = net.encoder(enc_X, enc_valid_len)
    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)
    # æ·»åŠ æ‰¹é‡è½´
    dec_X = torch.unsqueeze(torch.tensor(
        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)
    output_seq, attention_weight_seq = [], []
    for _ in range(num_steps):
        Y, dec_state = net.decoder(dec_X, dec_state)
        # æˆ‘ä»¬ä½¿ç”¨å…·æœ‰é¢„æµ‹æœ€é«˜å¯èƒ½æ€§çš„è¯å…ƒï¼Œä½œä¸ºè§£ç å™¨åœ¨ä¸‹ä¸€æ—¶é—´æ­¥çš„è¾“å…¥
        dec_X = Y.argmax(dim=2)
        # å‡å°‘ç»´åº¦ï¼Œè·å–æ•°æ®å¹¶ä»å¼ é‡è½¬å˜æˆæ ‡é‡
        pred = dec_X.squeeze(dim=0).type(torch.int32).item()
        # ä¿å­˜æ³¨æ„åŠ›æƒé‡ï¼ˆç¨åè®¨è®ºï¼‰
        if save_attention_weights:
            attention_weight_seq.append(net.decoder.attention_weights)
        # ä¸€æ—¦åºåˆ—ç»“æŸè¯å…ƒè¢«é¢„æµ‹ï¼Œè¾“å‡ºåºåˆ—çš„ç”Ÿæˆå°±å®Œæˆäº†
        if pred == tgt_vocab['<eos>']:
            break
        output_seq.append(pred)
    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq
```

### è¡¡é‡ç”Ÿæˆåºåˆ—çš„å¥½åï¼šBLEU

#### BLUEå€¼å®šä¹‰ï¼š

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/62/62-04.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/62/62-04.png)

```
def bleu(pred_seq, label_seq, k): 
    """è®¡ç®—BLEU"""
    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')
    len_pred, len_label = len(pred_tokens), len(label_tokens)
    score = math.exp(min(0, 1 - len_label / len_pred))
    for n in range(1, k + 1):
        num_matches, label_subs = 0, collections.defaultdict(int)
        # è®¡ç®—åŒ¹é…å€¼
        for i in range(len_label - n + 1):
            label_subs[' '.join(label_tokens[i: i + n])] += 1
        # è®¡ç®—ç½šå€¼
        for i in range(len_pred - n + 1):
            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:
                num_matches += 1
                label_subs[' '.join(pred_tokens[i: i + n])] -= 1
        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))
    return score
```

#### å®šä¹‰å¼è§£æ

[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/62/62-06.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/62/62-06.png)

BLEUå€¼è¡¡é‡çš„æ˜¯ç²¾ç¡®ç‡ï¼Œè€Œä¸”å¯¹ä¸åŒn-gramè¿›è¡Œé›†æˆæ‰“åˆ†ã€‚

- BPæƒ©ç½šå› å­ï¼šä¸ºäº†æƒ©ç½šè¿‡çŸ­çš„å¥å­ï¼Œç”±äºè¿‡çŸ­çš„å¥å­åŸºæ•°å°ï¼Œç²¾ç¡®ç‡å®¹æ˜“æå‡ï¼Œæ‰€ä»¥åŠ ä¸Šä¸€ä¸ªBPä¹˜å­ï¼Œå½“é¢„æµ‹å¥å­é•¿åº¦<å‚è€ƒå¥å­é•¿åº¦ï¼Œåˆ™BP<1ã€‚
- wnçš„é€‰æ‹©ï¼šææ²è€å¸ˆè¯¾ç¨‹ä¸­æ˜¯é‡‡ç”¨äº†$\frac{1}{2^n}$ä½œä¸ºåŠ æƒå› å­ï¼Œnè¶Šå¤§ï¼ŒåŠ æƒå› å­è¶Šå°ï¼Œä½†ç”±äºpn<1ï¼Œèµ‹äºˆçš„æƒé‡è¶Šå¤§ï¼Œå³é•¿åŒ¹é…å…·æœ‰æ›´é«˜çš„æƒé‡ã€‚





## æŸæœç´¢

åœ¨åºåˆ—ç”Ÿæˆé—®é¢˜ä¸­ï¼Œå¸¸ç”¨çš„æ–¹æ³•æ˜¯ä¸€ä¸ªä¸ªè¯å…ƒåœ°è¿›è¡Œç”Ÿæˆï¼Œä½†æ˜¯å…ˆå‰æ­¥ç”Ÿæˆçš„è¯å…ƒä¼šå½±å“ä¹‹åè¯å…ƒçš„æ¦‚ç‡åˆ†å¸ƒï¼Œä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨æœç´¢ç®—æ³•æ¥å¾—åˆ°ä¸€ä¸ªè¾ƒå¥½çš„åºåˆ—

### è´ªå¿ƒæœç´¢

è´ªå¿ƒæœç´¢å³æ¯ä¸ªæ—¶é—´æ­¥éƒ½é€‰æ‹©å…·æœ‰æœ€é«˜æ¡ä»¶æ¦‚ç‡çš„è¯å…ƒã€‚ $$ y_{t'} = \operatorname*{argmax}*{y \in \mathcal{Y}} P(y \mid y_1, \ldots, y*{t'-1}, \mathbf{c}) $$ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªæœ€æœ‰åºåˆ—ï¼Œä»–çš„è”åˆæ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯æ¯æ­¥ä¹‹é—´çš„æ¡ä»¶æ¦‚ç‡çš„ä¹˜ç§¯ï¼Œæœ€å¤§ã€‚ $$ \prod_{t'=1}^{T'} P(y_{t'} \mid y_1, \ldots, y_{t'-1}, \mathbf{c}) $$ ç„¶è€Œï¼Œè´ªå¿ƒæœç´¢å¾ˆå¯èƒ½æœç´¢åˆ°çš„ä¸æ˜¯æœ€ä¼˜è§£ï¼Œä¾‹å¦‚ï¼š[![img](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/63/Greedy_or_not.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/63/Greedy_or_not.png)

å·¦ä¾§çš„æœç´¢æ–¹å¼ä¸ºè´ªå¿ƒæœç´¢ï¼Œæ¯æ¬¡æ‰¾åˆ°å½“å‰æ¡ä»¶æ¦‚ç‡æœ€å¤§çš„é€‰é¡¹è¿›è¡Œé¢„æµ‹ï¼Œä½†æ˜¯è¿™æ ·å¯èƒ½ä¼šå¯¼è‡´ä¹‹åçš„æ¡ä»¶æ¦‚ç‡è¾ƒå°ï¼Œä»è€Œå¯¼è‡´æœ€ç»ˆçš„è”åˆæ¦‚ç‡è¾ƒå°ï¼Œç”Ÿæˆçš„åºåˆ—ä¸ä¼˜ã€‚

è€Œå³ä¾§çš„é€‰æ‹©æ–¹å¼è™½ç„¶åœ¨ç¬¬äºŒæ­¥é€‰æ‹©äº†è¾ƒå°çš„é€‰é¡¹ï¼Œä½†ä¹‹ååœ¨ç¬¬ä¸‰æ­¥æ—¶æœ‰äº†æ¡ä»¶æ¦‚ç‡ä¸º0.6é€‰é¡¹ï¼Œæœ€ç»ˆç»“æœåè€Œæ›´å¥½ã€‚

### ç©·ä¸¾æœç´¢

ç©·ä¸¾æœç´¢æšä¸¾æ‰€æœ‰å¯èƒ½çš„è¾“å‡ºåºåˆ—åŠå…¶æ¦‚ç‡ï¼Œç„¶åé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„ä½œä¸ºæœ€ç»ˆçš„è¾“å‡ºï¼Œæšä¸¾æœç´¢å¯ä»¥ä¿è¯å¾—åˆ°æœ€ä¼˜è§£ï¼Œä½†æ˜¯è®¡ç®—å¤æ‚åº¦å¾ˆé«˜ï¼Œéš¾ä»¥å®ç°

### æŸæœç´¢ï¼ˆbeam searchï¼‰

æŸæœç´¢ç»¼åˆäº†è´ªå¿ƒæœç´¢å’Œç©·ä¸¾æœç´¢ï¼Œåœ¨èƒ½æ¥å—çš„è®¡ç®—æˆæœ¬ä¸‹å¾—åˆ°æ¯”è´ªå¿ƒæœç´¢æ›´å¥½çš„ç»“æœã€‚

æŸæœç´¢æœ‰ä¸€ä¸ªè¶…å‚æ•°ï¼Œåä¸º**æŸå®½ï¼ˆbeam sizeï¼‰**ğ‘˜ï¼ŒæŸæœç´¢çš„å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š

- 1ï¼šåœ¨ç¬¬ä¸€æ—¶é—´æ­¥é€‰æ‹©æ¡ä»¶æ¦‚ç‡æœ€é«˜çš„kä¸ªé€‰é¡¹
- 2ï¼šå¯¹éšåçš„æ¯ä¸ªæ—¶é—´æ­¥ï¼ŒåŸºäºä¸Šä¸€æ—¶é—´æ­¥çš„kä¸ªå€™é€‰è¾“å‡ºåºåˆ—é¢„æµ‹è¿™ä¸€æ—¶é—´æ­¥çš„æ‰€æœ‰å¯èƒ½é€‰é¡¹çš„æ¡ä»¶æ¦‚ç‡ï¼Œä»ä¸­å–kä¸ªæœ€å¤§çš„
- 3ï¼šæœ€ååŸºäºæ¯æ­¥å¾—åˆ°çš„åºåˆ—ï¼Œåˆ å»æˆªæ­¢ç¬¦å’Œå…¶åå…ƒç´ ï¼Œè·å¾—æœ€ç»ˆå€™é€‰åºåˆ—é›†åˆï¼Œå–å‡ºåŠ æƒæ¡ä»¶æ¦‚ç‡æœ€å¤§çš„

åŠ æƒæ¡ä»¶æ¦‚ç‡å…¬å¼å¦‚ä¸‹ï¼š $$ \frac{1}{L^\alpha} \log P(y_1, \ldots, y_{L}\mid \mathbf{c}) = \frac{1}{L^\alpha} \sum_{t'=1}^L \log P(y_{t'} \mid y_1, \ldots, y_{t'-1}, \mathbf{c}), $$ å¼ä¸­$\frac{1}{L^\alpha}$ç”¨äºè°ƒæ•´é•¿åºåˆ—çš„è¯„ä¼°å€¼ä½¿å¾—é•¿çŸ­åºåˆ—é—´çš„æ¯”è¾ƒå…¬å¹³

æŸå®½kçš„é€‰æ‹©ï¼š

- k=1æ—¶å®é™…ä¸ºè´ªå¿ƒæœç´¢
- kè¶Šå°æœç´¢é€Ÿåº¦è¶Šå¿«ï¼Œä½†ç»“æœè¶Šå·®ï¼Œkè¶Šå¤§åˆ™æœç´¢é€Ÿåº¦è¶Šæ…¢ï¼Œä½†ç»“æœè¶Šå¥½

æŸæœç´¢åªåœ¨æµ‹è¯•æ—¶ä½¿ç”¨





# æ³¨æ„åŠ›æœºåˆ¶

## æ³¨æ„åŠ›æœºåˆ¶

## æ³¨æ„åŠ›åˆ†æ•°

### ç†è®ºå†…å®¹

### ä»£ç ä¸å…·ä½“æ“ä½œ

åœ¨ä¸Šä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨**é«˜æ–¯æ ¸**æ¥å¯¹æŸ¥è¯¢å’Œé”®ä¹‹é—´çš„å…³ç³»å»ºæ¨¡ã€‚æˆ‘ä»¬å¯ä»¥å°†ä¸Šä¸€èŠ‚ä¸­çš„é«˜æ–¯æ ¸å‡½æ•°éƒ¨åˆ†è§†ä¸ºæ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ï¼Œç®€ç§°è¯„åˆ†å‡½æ•°ï¼Œç„¶åæŠŠè¿™ä¸ªå‡½æ•°çš„è¾“å‡ºç»“æœè¾“å…¥åˆ°softmaxå‡½æ•°ä¸­è¿›è¡Œè¿ç®—ã€‚ é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œæˆ‘ä»¬å°†å¾—åˆ°ä¸é”®å¯¹åº”çš„å€¼çš„æ¦‚ç‡åˆ†å¸ƒï¼ˆå³æ³¨æ„åŠ›æƒé‡ï¼‰ã€‚ æœ€åï¼Œæ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºå°±æ˜¯åŸºäºè¿™äº›æ³¨æ„åŠ›æƒé‡çš„å€¼çš„åŠ æƒå’Œã€‚

```
import math
import torch
from torch import nn
from d2l import torch as d2l
```

#### æ©è”½softmaxæ“ä½œ

æ­£å¦‚ä¸Šé¢æåˆ°çš„ï¼Œ**softmaxæ“ä½œç”¨äºè¾“å‡ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒä½œä¸ºæ³¨æ„åŠ›æƒé‡**ã€‚ åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¹¶éæ‰€æœ‰çš„å€¼éƒ½åº”è¯¥è¢«çº³å…¥åˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚ ä¾‹å¦‚ï¼Œä¸ºäº†åœ¨ [9.5èŠ‚](https://zh-v2.d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html#sec-machine-translation)ä¸­é«˜æ•ˆå¤„ç†å°æ‰¹é‡æ•°æ®é›†ï¼Œ æŸäº›æ–‡æœ¬åºåˆ—è¢«å¡«å……äº†æ²¡æœ‰æ„ä¹‰çš„ç‰¹æ®Šè¯å…ƒã€‚ ä¸ºäº†ä»…å°†æœ‰æ„ä¹‰çš„è¯å…ƒä½œä¸ºå€¼æ¥è·å–æ³¨æ„åŠ›æ±‡èšï¼Œ æˆ‘ä»¬å¯ä»¥æŒ‡å®šä¸€ä¸ª**æœ‰æ•ˆåºåˆ—é•¿åº¦ï¼ˆå³è¯å…ƒçš„ä¸ªæ•°ï¼‰ï¼Œ ä»¥ä¾¿åœ¨è®¡ç®—softmaxæ—¶è¿‡æ»¤æ‰è¶…å‡ºæŒ‡å®šèŒƒå›´çš„ä½ç½®ã€‚** é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸‹é¢çš„`masked_softmax`å‡½æ•°ä¸­ å®ç°è¿™æ ·çš„***æ©è”½softmaxæ“ä½œ*ï¼ˆmasked softmax operationï¼‰**ï¼Œ å…¶ä¸­ä»»ä½•è¶…å‡ºæœ‰æ•ˆé•¿åº¦çš„ä½ç½®éƒ½è¢«æ©è”½å¹¶ç½®ä¸º0ã€‚

```python
def masked_softmax(X,valid_lens):
	  if valid_lens == None:
	  	return nn.functional.softmax(X,dim=-1)
	  	
	  else:
      	shape = X.shape
        
	  	if valid_lens.dim() == 1:
            #å°†valid_lensçš„æ¯ä¸€ä¸ªå…ƒç´ é‡å¤shape[1]æ¬¡
            valid_lens = torch.repeat_interleave(valid_lens, shape[1])
	  	else:
	  		valid_lens = valid_lens.reshape(-1)
	  	X = d2l.sequence_mask(X.reshape(-1,X.shape[-1]),valid_lens,value=1e-6)
        
	  	return nn.functional.softmax(X,dim=-1)
```

#### åŠ æ€§æ³¨æ„åŠ›

- ä¸€èˆ¬æ¥è¯´ï¼Œå½“æŸ¥è¯¢å’Œé”®æ˜¯ä¸åŒé•¿åº¦çš„çŸ¢é‡æ—¶ï¼Œ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ æ€§æ³¨æ„åŠ›ä½œä¸ºè¯„åˆ†å‡½æ•°ã€‚
- æˆ‘ä»¬æœ‰ä¸‰ä¸ªå€¼ï¼Œq,k,v
- å°†æŸ¥è¯¢å’Œé”®è¿ç»“èµ·æ¥åè¾“å…¥åˆ°ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ä¸­ï¼Œæ„ŸçŸ¥æœºåŒ…å«ä¸€ä¸ªéšè—å±‚ï¼Œå…¶éšè—å•å…ƒæ•°æ˜¯ä¸€ä¸ªè¶…å‚æ•°â„ã€‚ é€šè¿‡ä½¿ç”¨tanhä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¹¶ä¸”ç¦ç”¨åç½®é¡¹ã€‚
- ![image-20240728141052516](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728141052516.png)

```
class AdditiveAttention(nn.module):
	def __init__(self,key_size,query_size,num_hiddens,dropout,**kwargs):
	super( AdditiveAttention,self).__init__(**kwargs)
	self.W_k = nn.Linear(key_size,num_hiddens,bias=false)
	self.W_q = nn.Linear(query_size,num_hiddens,bias=false)
	self.W_v = nn.Linear(num_hiddens,1,bias=false)
	self.dropout = nn.Dropout(dropout)


#valid_lens:æœ‰å¤šå°‘key-value pairæ˜¯æœ‰äººéœ€è¦çš„
	def forward(self, queries, keys, values, valid_lens):
		queries,keys=self.W_q(queries),self.W_k(keys)
		features = queries.unsqueeze(2) + keys.unsqueeze(1)
        features = torch.tanh(features)
        # self.w_vä»…æœ‰ä¸€ä¸ªè¾“å‡ºï¼Œå› æ­¤ä»å½¢çŠ¶ä¸­ç§»é™¤æœ€åé‚£ä¸ªç»´åº¦ã€‚
         # scoresçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œâ€œé”®-å€¼â€å¯¹çš„ä¸ªæ•°)
        scores = self.w_v(features).squeeze(-1)
        self.attention_weights = masked_softmax(scores,valid_lens)
        return torch.bmm(self.dropout(self.attention_weights), values)
```

#### ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›

ä½¿ç”¨ç‚¹ç§¯å¯ä»¥å¾—åˆ°è®¡ç®—æ•ˆç‡æ›´é«˜çš„è¯„åˆ†å‡½æ•°ï¼Œ ä½†æ˜¯ç‚¹ç§¯æ“ä½œè¦æ±‚æŸ¥è¯¢å’Œé”®å…·æœ‰ç›¸åŒçš„é•¿åº¦*d*ã€‚ å‡è®¾æŸ¥è¯¢å’Œé”®çš„æ‰€æœ‰å…ƒç´ éƒ½æ˜¯ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œ å¹¶ä¸”éƒ½æ»¡è¶³é›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œ é‚£ä¹ˆä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯çš„å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º*d*ã€‚ ä¸ºç¡®ä¿æ— è®ºå‘é‡é•¿åº¦å¦‚ä½•ï¼Œ ç‚¹ç§¯çš„æ–¹å·®åœ¨ä¸è€ƒè™‘å‘é‡é•¿åº¦çš„æƒ…å†µä¸‹ä»ç„¶æ˜¯1ï¼Œ æˆ‘ä»¬å°†ç‚¹ç§¯é™¤ä»¥âˆšd,åœ¨ä¸‹é¢çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æš‚é€€æ³•è¿›è¡Œæ¨¡å‹æ­£åˆ™åŒ–ã€‚

```
#@save
class DotProductAttention(nn.Module):
    """ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›"""
    def __init__(self, dropout, **kwargs):
        super(DotProductAttention, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)

    # queriesçš„å½¢çŠ¶ï¼š(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œd)
    # keysçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œd)
    # valuesçš„å½¢çŠ¶ï¼š(batch_sizeï¼Œâ€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œå€¼çš„ç»´åº¦)
    # valid_lensçš„å½¢çŠ¶:(batch_sizeï¼Œ)æˆ–è€…(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°)
    def forward(self, queries, keys, values, valid_lens=None):
        d = queries.shape[-1]
        # è®¾ç½®transpose_b=Trueä¸ºäº†äº¤æ¢keysçš„æœ€åä¸¤ä¸ªç»´åº¦
        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)
        self.attention_weights = masked_softmax(scores, valid_lens)
        return torch.bmm(self.dropout(self.attention_weights), values)
```

#### å°ç»“

- å°†æ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºè®¡ç®—å¯ä»¥ä½œä¸ºå€¼çš„åŠ æƒå¹³å‡ï¼Œé€‰æ‹©ä¸åŒçš„æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ä¼šå¸¦æ¥ä¸åŒçš„æ³¨æ„åŠ›æ±‡èšæ“ä½œã€‚
- å½“æŸ¥è¯¢å’Œé”®æ˜¯ä¸åŒé•¿åº¦çš„çŸ¢é‡æ—¶ï¼Œå¯ä»¥ä½¿ç”¨å¯åŠ æ€§æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ã€‚å½“å®ƒä»¬çš„é•¿åº¦ç›¸åŒæ—¶ï¼Œä½¿ç”¨ç¼©æ”¾çš„â€œç‚¹ï¼ç§¯â€æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°çš„è®¡ç®—æ•ˆç‡æ›´é«˜ã€‚

## ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶çš„seq2seq

æ”¹å˜ä¸Šä¸‹æ–‡å˜é‡ï¼šåœ¨é¢„æµ‹è¯å…ƒæ—¶ï¼Œå¦‚æœä¸æ˜¯æ‰€æœ‰è¾“å…¥è¯å…ƒéƒ½ç›¸å…³ï¼Œæ¨¡å‹å°†ä»…å¯¹é½ï¼ˆæˆ–å‚ä¸ï¼‰è¾“å…¥åºåˆ—ä¸­ä¸å½“å‰é¢„æµ‹ç›¸å…³çš„éƒ¨åˆ†ã€‚è¿™æ˜¯é€šè¿‡å°†ä¸Šä¸‹æ–‡å˜é‡è§†ä¸ºæ³¨æ„åŠ›é›†ä¸­çš„è¾“å‡ºæ¥å®ç°çš„ã€‚

### Bahdanauæ³¨æ„åŠ›æ¨¡å‹

å‡è®¾è¾“å…¥åºåˆ—ä¸­æœ‰ğ‘‡ä¸ªè¯å…ƒï¼Œ è§£ç æ—¶é—´æ­¥ğ‘¡â€²çš„ä¸Šä¸‹æ–‡å˜é‡æ˜¯æ³¨æ„åŠ›é›†ä¸­çš„è¾“å‡ºï¼š

![image-20240728163531954](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728163531954.png)

![image-20240728163604947](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728163604947.png)



### è‡ªå®šä¹‰æ³¨æ„åŠ›è§£ç å™¨æ³¨æ„åŠ›

#### **å¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶è§£ç å™¨çš„åŸºæœ¬æ¥å£**

```
class AttentionDecoder(d2l.Decoder):
    """å¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶è§£ç å™¨çš„åŸºæœ¬æ¥å£"""
    def __init__(self, **kwargs):
        super(AttentionDecoder, self).__init__(**kwargs)

    @property
    def attention_weights(self):
        raise NotImplementedError
```



#### **å®ç°å¸¦æœ‰Bahdanauæ³¨æ„åŠ›çš„å¾ªç¯ç¥ç»ç½‘ç»œè§£ç å™¨**

- åˆå§‹åŒ–è§£ç å™¨çš„çŠ¶æ€
- å°†æ¯ä¸€ä¸ªæ—¶é—´æ­¥æœ€ç»ˆéšè—å±‚çš„çŠ¶æ€ä½œä¸ºæ³¨æ„åŠ›çš„key/value
- ä¸Šä¸€æ—¶é—´æ­¥éšè—å±‚çš„å…¨çŠ¶æ€å°†åˆå§‹è§£ç å™¨çš„çŠ¶æ€
- è§£ç å™¨ä¸Šä¸€æ—¶é—´æ­¥çš„æœ€ç»ˆéšè—å±‚å°†ä½œä¸ºquery

```
class Seq2SeqAttentionDecoder(AttentionDecoder):
	def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,
                 dropout=0, **kwargs):
        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)
        self.attention = d2l.AdditiveAttention(
            num_hiddens, num_hiddens, num_hiddens, dropout)
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.rnn = nn.GRU(
            embed_size + num_hiddens, num_hiddens, num_layers,
            dropout=dropout)
        self.dense = nn.Linear(num_hiddens, vocab_size)
        
    def init_state(self,enc_X,enc_valid_len,*args):
    	# outputs = (batch_sizeï¼Œnum_stepsï¼Œnum_hiddens)
    	# hidden_stateçš„å½¢çŠ¶ä¸º(num_layersï¼Œbatch_sizeï¼Œnum_hiddens)
    	outputs, hidden_state = enc_outputs
    	return (outputs.permute(1,0,2),hidden_state,enc_valid_lens)
    
    def forward(self, X, state):
    	# enc_outputsçš„å½¢çŠ¶ä¸º(batch_size,num_steps,num_hiddens).
        # hidden_stateçš„å½¢çŠ¶ä¸º(num_layers,batch_size,
        # num_hiddens)
        enc_outputs, hidden_state, enc_valid_lens = state
    	# è¾“å‡ºXçš„å½¢çŠ¶ä¸º(num_steps,batch_size,embed_size)
    	X = self.embedding(X).permute(1,0,2)
    	outputs, self._attention_weights = [], []
    	
    	for x in X:
    		# queryçš„å½¢çŠ¶ä¸º(batch_size,1,num_hiddens)
    		query = torch.unsqueeze(hidden_state[-1],dim=1)
    		# context = (batch_size,1,num_hiddens)
    		context = self.attention(query,enc_outputs,enc_outputs,enc_valid_lens)
    		# åœ¨ç‰¹å¾ç»´åº¦ä¸Šè¿æ¥
    		x = torch.cat(context,torch.unsqueeze(x,dim=1),dim=-1)
    		 # å°†xå˜å½¢ä¸º(1,batch_size,embed_size+num_hiddens)
            out, hidden_state = self.rnn(x.permute(1, 0, 2), hidden_state)
            outputs.append(out)
            self._attention_weights.append(self.attention.attention_weights)
    # å…¨è¿æ¥å±‚å˜æ¢åï¼Œoutputsçš„å½¢çŠ¶ä¸º
        # (num_steps,batch_size,vocab_size)
        outputs = self.dense(torch.cat(outputs, dim=0))
        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,
                                          enc_valid_lens]
    
    @property
    def attention_weights(self):
        return self._attention_weights
```

## å¤šå¤´æ³¨æ„åŠ›

å…è®¸æ³¨æ„åŠ›æœºåˆ¶ç»„åˆä½¿ç”¨æŸ¥è¯¢ã€é”®å’Œå€¼çš„ä¸åŒ *å­ç©ºé—´è¡¨ç¤º*ï¼ˆrepresentation subspacesï¼‰ï¼šæ¨¡å‹åŸºäºç›¸åŒçš„æ³¨æ„åŠ›å»å­¦ä¹ ä¸åŒçš„è¡Œä¸ºå’ŒçŸ¥è¯†ï¼Œæœ€åå°†è¿™äº›ä¸åŒçš„çŸ¥è¯†ç»„åˆåœ¨ä¸€èµ·ã€‚

å¤šå¤´æ³¨æ„åŠ›ï¼šhç»„å…¨è¿æ¥å±‚æ¥åˆ†åˆ«å˜åŒ–k,q,vï¼ˆç‹¬ç«‹å­¦ä¹ ä¸åŒçš„è¡Œä¸ºï¼‰ï¼Œæœ€åå°†q,k,vå¹¶è¡Œé€åˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚æœ€ç»ˆå°†hä¸ªæ³¨æ„åŠ›æ±‡èšçš„è¾“å‡ºæ‹¼æ¥åˆ°ä¸€èµ·ï¼Œé€šè¿‡ä¸€ä¸ªçº¿æ€§æŠ•å½±è¿›è¡Œå˜æ¢ã€‚

![image-20240728190956824](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728190956824.png)

### æ•°å­¦è¡¨è¾¾

åœ¨å®ç°å¤šå¤´æ³¨æ„åŠ›ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ç”¨æ•°å­¦è¯­è¨€å°†è¿™ä¸ªæ¨¡å‹å½¢å¼åŒ–åœ°æè¿°å‡ºæ¥ã€‚ç»™å®šæŸ¥è¯¢$\mathbf{q} \in \mathbb{R}^{d_q}$ã€é”®$\mathbf{k} \in \mathbb{R}^{d_k}$å’Œå€¼$\mathbf{v} \in \mathbb{R}^{d_v}$ï¼Œæ¯ä¸ªæ³¨æ„åŠ›å¤´$\mathbf{h}_i$ï¼ˆ$i = 1, \ldots, h$ï¼‰çš„è®¡ç®—æ–¹æ³•ä¸ºï¼š

$$\mathbf{h}_i = f(\mathbf W_i^{(q)}\mathbf q, \mathbf W_i^{(k)}\mathbf k,\mathbf W_i^{(v)}\mathbf v) \in \mathbb R^{p_v},$$

å…¶ä¸­ï¼Œå¯å­¦ä¹ çš„å‚æ•°åŒ…æ‹¬
$\mathbf W_i^{(q)}\in\mathbb R^{p_q\times d_q}$ã€$\mathbf W_i^{(k)}\in\mathbb R^{p_k\times d_k}$å’Œ$\mathbf W_i^{(v)}\in\mathbb R^{p_v\times d_v}$ï¼Œä»¥åŠä»£è¡¨æ³¨æ„åŠ›æ±‡èšçš„å‡½æ•°$f$ã€‚$f$å¯ä»¥æ˜¯ :numref:`sec_attention-scoring-functions`ä¸­çš„**åŠ æ€§æ³¨æ„åŠ›å’Œç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›**ã€‚å¤šå¤´æ³¨æ„åŠ›çš„è¾“å‡ºéœ€è¦ç»è¿‡å¦ä¸€ä¸ªçº¿æ€§è½¬æ¢ï¼Œå®ƒå¯¹åº”ç€$h$ä¸ªå¤´è¿ç»“åçš„ç»“æœï¼Œå› æ­¤å…¶å¯å­¦ä¹ å‚æ•°æ˜¯
$\mathbf W_o\in\mathbb R^{p_o\times h p_v}$ï¼š

$$\mathbf W_o \begin{bmatrix}\mathbf h_1\\\vdots\\\mathbf h_h\end{bmatrix} \in \mathbb{R}^{p_o}.$$

åŸºäºè¿™ç§è®¾è®¡ï¼Œæ¯ä¸ªå¤´éƒ½å¯èƒ½ä¼šå…³æ³¨è¾“å…¥çš„ä¸åŒéƒ¨åˆ†ï¼Œå¯ä»¥è¡¨ç¤ºæ¯”ç®€å•åŠ æƒå¹³å‡å€¼æ›´å¤æ‚çš„å‡½æ•°ã€‚

### å®ç°

```
class MultiHeadAttention:
	def __init__(self,key_size,query_size,vocab_size,num_hiddens,num_heads,dropout,bias=False,**kwargs):
	self.num_heads = num_heads
	self.attention = d2l.DotProductAttention(dropout)
	self.W_q = nn.Linear(query_size,num_hiddens,bias=bias)
	self.W_v = nn.Linear(vocab_size,num_hiddens,bias=bias)
	self.W_k = nn.Linear(key_size,num_hiddens,bias=bias)
	self.W_o = nn.Linear(num_hiddens,num_hiddens,bias=bias)
	
	def forward(self, queries, keys, values, valid_lens):
		# queriesï¼Œkeysï¼Œvaluesçš„å½¢çŠ¶:
        # (batch_sizeï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens)
        # valid_lensã€€çš„å½¢çŠ¶:
        # (batch_sizeï¼Œ)æˆ–(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°)
        # ç»è¿‡å˜æ¢åï¼Œè¾“å‡ºçš„queriesï¼Œkeysï¼Œvaluesã€€çš„å½¢çŠ¶:
        # (batch_size*num_headsï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens/num_heads)
        # æœ€å¤§çš„ä¸åŒå°±æ˜¯æŠŠä¸€ç»„é”®å€¼æ”¾åœ¨å¤šä¸ªæ³¨æ„åŠ›å†…è®¡ç®—
        queries = transpose_qkv(self.W_q(queries), self.num_heads)
        keys = transpose_qkv(self.W_k(keys), self.num_heads)
        values = transpose_qkv(self.W_v(values), self.num_heads)
        
        if valid_lens is not None:
        	# åœ¨è½´0ï¼Œå°†ç¬¬ä¸€é¡¹ï¼ˆæ ‡é‡æˆ–è€…çŸ¢é‡ï¼‰å¤åˆ¶num_headsæ¬¡ï¼Œå¦‚æ­¤é‡å¤ç¬¬äºŒé¡¹
        	valid_lens = torch.repeat_interleave(valid_lens,repeat=num_heads,dim=0)
        	
        # outputçš„å½¢çŠ¶:(batch_size*num_headsï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œnum_hiddens/num_heads)	
        output = self.attention(queries, keys, values, valid_lens)
        
        # output_concatçš„å½¢çŠ¶:(batch_sizeï¼ŒæŸ¥è¯¢çš„ä¸ªæ•°ï¼Œnum_hiddens)
        output_concat = transpose_output(output,self.num_heads)
        
        return self.W_o(output_concat)
```

```
def transpose_qkv(X, num_heads):
    """ä¸ºäº†å¤šæ³¨æ„åŠ›å¤´çš„å¹¶è¡Œè®¡ç®—è€Œå˜æ¢å½¢çŠ¶"""
    # è¾“å…¥Xçš„å½¢çŠ¶:(batch_sizeï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_hiddens)
    # è¾“å‡ºXçš„å½¢çŠ¶:(batch_sizeï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°ï¼Œnum_headsï¼Œ
    # num_hiddens/num_heads)
    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)

    # è¾“å‡ºXçš„å½¢çŠ¶:(batch_sizeï¼Œnum_headsï¼ŒæŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°,
    # num_hiddens/num_heads)
    X = X.permute(0, 2, 1, 3)

    # æœ€ç»ˆè¾“å‡ºçš„å½¢çŠ¶:(batch_size*num_heads,æŸ¥è¯¢æˆ–è€…â€œé”®ï¼å€¼â€å¯¹çš„ä¸ªæ•°,
    # num_hiddens/num_heads)
    return X.reshape(-1, X.shape[2], X.shape[3])


#@save
def transpose_output(X, num_heads):
    """é€†è½¬transpose_qkvå‡½æ•°çš„æ“ä½œ"""
    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])
    X = X.permute(0, 2, 1, 3)
    return X.reshape(X.shape[0], X.shape[1], -1)
```

## è‡ªæ³¨æ„åŠ›å’Œä½ç½®ç¼–ç 

æ¯ä¸ªæŸ¥è¯¢éƒ½ä¼šå…³æ³¨æ‰€æœ‰çš„é”®ï¼å€¼å¯¹å¹¶ç”Ÿæˆä¸€ä¸ªæ³¨æ„åŠ›è¾“å‡ºã€‚ ç”±äºæŸ¥è¯¢ã€é”®å’Œå€¼æ¥è‡ªåŒä¸€ç»„è¾“å…¥ï¼Œå› æ­¤è¢«ç§°ä¸º *è‡ªæ³¨æ„åŠ›*ï¼ˆself-attentionï¼‰

### è‡ªæ³¨æ„åŠ›

![image-20240728190211948](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728190211948.png)

```
num_hiddens, num_heads = 100, 5
attention = d2l.MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, 0.5)
attention.eval()
```

### æ¯”è¾ƒå·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œå’Œè‡ªæ³¨æ„åŠ›

![image-20240728192821220](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728192821220.png)

![image-20240728192844134](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728192844134.png)

### ä½ç½®ç¼–ç 

- å­æ³¨æ„åŠ›å¹¶æ²¡æœ‰è®°å½•ä½ç½®ä¿¡æ¯

- ä½ç½®ç¼–ç å°†ä½ç½®ä¿¡æ¯æ³¨å…¥åˆ°è¾“å…¥å½“ä¸­

- å‡è®¾æœ‰$\mathbf{n} \in \mathbb{R}^{n*d}$,é‚£ä¹ˆä½¿ç”¨ä½ç½®ç¼–ç ä¿¡æ¯$\mathbf{P} \in \mathbb{R}^{n*d}$ï¼Œæ¥è¾“å‡ºX+Pä½œä¸ºè‡ªç¼–ç è¾“å…¥

- ![image-20240728194354551](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728194354551.png)

  ï¼ˆåŸºäºæ­£å¼¦å‡½æ•°å’Œä½™å¼¦å‡½æ•°çš„å›ºå®šä½ç½®ç¼–ç ï¼‰

```python
class PositionalEncodeing(nn.Module):
	def __init__(delf,num_hiddens,dropout,max_len=1000):
	super(PositionalEncodeing,self).__init__()
	self.dropout = nn.Dropout(dropout)
	self.P = torch.zeros((1,max_len,num_hiddens))
    X = torch.arange(max_len,dtype=torch.float32).reshape(-1,1)/(torch.pow(10000,torch.arange(0,num_hiddens, 2, dtype=torch.float32)/num_hiddens))
    self.P[:,:,0::2] = torch.sin(X)
    self.P[:,:,1::2] = torch.cos(X)
    
     def forward(self, X):
        X = X + self.P[:, :X.shape[1], :].to(X.device)
        return self.dropout(X)
    
    
    
    
X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))encoding_dim, num_steps = 32, 60
pos_encoding = PositionalEncoding(encoding_dim, 0)
pos_encoding.eval()
X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))
P = pos_encoding.P[:, :X.shape[1], :]
d2l.plot(torch.arange(num_steps), P[0, :, 6:10].T, xlabel='Row (position)',
         figsize=(6, 2.5), legend=["Col %d" % d for d in torch.arange(6, 10)])
```

#### ç»å¯¹ä½ç½®ä¿¡æ¯

åœ¨äºŒè¿›åˆ¶è¡¨ç¤ºä¸­ï¼Œ**è¾ƒé«˜æ¯”ç‰¹ä½çš„äº¤æ›¿é¢‘ç‡ä½äºè¾ƒä½æ¯”ç‰¹ä½**ï¼Œ ä¸ä¸‹é¢çš„çƒ­å›¾æ‰€ç¤ºç›¸ä¼¼ï¼Œåªæ˜¯ä½ç½®ç¼–ç é€šè¿‡ä½¿ç”¨ä¸‰è§’å‡½æ•°[**åœ¨ç¼–ç ç»´åº¦ä¸Šé™ä½é¢‘ç‡**]ã€‚ ç”±äºè¾“å‡ºæ˜¯æµ®ç‚¹æ•°ï¼Œå› æ­¤æ­¤ç±»è¿ç»­è¡¨ç¤ºæ¯”äºŒè¿›åˆ¶è¡¨ç¤ºæ³•æ›´èŠ‚çœç©ºé—´ã€‚

#### ç›¸å¯¹ä½ç½®ä¿¡æ¯

é™¤äº†æ•è·ç»å¯¹ä½ç½®ä¿¡æ¯ä¹‹å¤–ï¼Œä¸Šè¿°çš„ä½ç½®ç¼–ç è¿˜å…è®¸æ¨¡å‹å­¦ä¹ å¾—åˆ°è¾“å…¥åºåˆ—ä¸­ç›¸å¯¹ä½ç½®ä¿¡æ¯ã€‚ è¿™æ˜¯å› ä¸ºå¯¹äºä»»ä½•ç¡®å®šçš„ä½ç½®åç§»ğ›¿ï¼Œä½ç½®ğ‘–+ğ›¿å¤„ çš„ä½ç½®ç¼–ç å¯ä»¥çº¿æ€§æŠ•å½±ä½ç½®ğ‘–å¤„çš„ä½ç½®ç¼–ç æ¥è¡¨ç¤ºã€‚(å¹³ç§»ä¸å˜æ€§)

è¿™ç§æŠ•å½±çš„æ•°å­¦è§£é‡Šæ˜¯ï¼Œä»¤ğœ”ğ‘—=1/100002ğ‘—/ğ‘‘ï¼Œ å¯¹äºä»»ä½•ç¡®å®šçš„ä½ç½®åç§»ğ›¿ï¼Œ :eqref:`eq_positional-encoding-def`ä¸­çš„ä»»ä½•ä¸€å¯¹ (ğ‘ğ‘–,2ğ‘—,ğ‘ğ‘–,2ğ‘—+1)éƒ½å¯ä»¥çº¿æ€§æŠ•å½±åˆ° (ğ‘ğ‘–+ğ›¿,2ğ‘—,ğ‘ğ‘–+ğ›¿,2ğ‘—+1)ï¼š

![image-20240728210621574](C:/Users/Y9000p/AppData/Roaming/Typora/typora-user-images/image-20240728210621574.png)

2Ã—2æŠ•å½±çŸ©é˜µä¸ä¾èµ–äºä»»ä½•ä½ç½®çš„ç´¢å¼•ğ‘–ã€‚

## transformeræ¶æ„

- åŸºäºencoder-decoderæ¶æ„æ¥å¤„ç†åºåˆ—å¯¹
- è·Ÿä½¿ç”¨æ³¨æ„åŠ›çš„seq2seqä¸åŒï¼Œtransformeræ˜¯çº¯åŸºäºæ³¨æ„åŠ›

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/68/68-01.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/68/68-01.png)

### å¤šå¤´æ³¨æ„åŠ›

- å¯¹åŒä¸€keyï¼Œvalueï¼Œqueryï¼Œå¸Œæœ›æŠ½å–ä¸åŒçš„ä¿¡æ¯

  - ä¾‹å¦‚çŸ­è·ç¦»å…³ç³»å’Œé•¿è·ç¦»å…³ç³»

- å¤šå¤´æ³¨æ„åŠ›ä½¿ç”¨hä¸ªç‹¬ç«‹çš„æ³¨æ„åŠ›æ± åŒ–

  - åˆå¹¶å„ä¸ªå¤´ï¼ˆheadï¼‰è¾“å‡ºå¾—åˆ°æœ€ç»ˆè¾“å‡º
  - [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/68/68-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/68/68-02.png)

- æ•°å­¦è¡¨è¾¾å¼

  [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/68/68-02.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/68/68-02.png)

### æœ‰æ©ç çš„å¤šå¤´æ³¨æ„åŠ›

- è§£ç å™¨å¯¹åºåˆ—ä¸­ä¸€ä¸ªå…ƒç´ è¾“å‡ºçš„æ—¶å€™ï¼Œä¸åº”è¯¥è€ƒè™‘è¯¥å…ƒç´ ä¹‹åçš„å…ƒç´ 
- å¯ä»¥ç”¨æ©ç æ¥å®ç°
  - ä¹Ÿå°±æ˜¯è®¡ç®—$x_i$è¾“å‡ºçš„æ—¶å€™ï¼Œå‡è£…å½“å‰åºåˆ—é•¿åº¦ä¸ºi

### åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ

- å°†è¾“å…¥å½¢çŠ¶å˜åŒ–ï¼ˆb,n,dï¼‰å˜æ¢æˆï¼ˆbnï¼Œdï¼‰ï¼›è¾“å‡ºå½¢çŠ¶ç”±ï¼ˆbnï¼Œdï¼‰å˜æˆï¼ˆbï¼Œnï¼Œdï¼‰
- ä½œç”¨ä¸¤ä¸ªå…¨è¿æ¥å±‚
- ç­‰ä»·äºä¸¤å±‚æ ¸çª—å£ä¸º1çš„ä¸€ç»´å·ç§¯å±‚ï¼ˆå…¨è¿æ¥ï¼‰



### å±‚å½’ä¸€åŒ–

- æ‰¹é‡å½’ä¸€åŒ–å¯¹æ¯ä¸ªç‰¹å¾/é€šé“é‡Œå…ƒç´ è¿›è¡Œå½’ä¸€åŒ–
  - ä¸é€‚åˆåºåˆ—é•¿åº¦ä¼šå˜çš„nlpåº”ç”¨
- å±‚å½’ä¸€åŒ–å¯¹æ¯ä¸ªæ ·æœ¬é‡Œé¢çš„å…ƒç´ è¿›è¡Œå½’ä¸€åŒ–ï¼ˆ layer norm ï¼‰

### ä¿¡æ¯ä¼ é€’

- å°†ç¼–ç å™¨è¾“å‡ºä½œä¸ºè§£ç ä¸­ç¬¬iä¸ªtransformerå—ä¸­å¤šå¤´æ³¨æ„åŠ›çš„keyå’Œvalue
  - queryæ¥è‡ªç›®æ ‡åºåˆ—
- æ„å‘³ç€ç¼–ç å™¨å’Œè§£ç å™¨ä¸­å—çš„ä¸ªæ•°ï¼Œè¾“å‡ºç»´åº¦éƒ½æ˜¯ä¸€æ ·çš„

### é¢„æµ‹

- é¢„æµ‹ç¬¬t+1ä¸ªè¾“å‡ºæ—¶
- è§£ç å™¨ä¸­è¾“å…¥å‰tä¸ªé¢„æµ‹å€¼ï¼ˆé¡ºåºï¼‰
  - åœ¨è‡ªæ³¨æ„åŠ›ä¸­ï¼Œå‰tä¸ªé¢„æµ‹å€¼ä½œä¸ºkeyå’Œvalueï¼Œç¬¬tä¸ªé¢„æµ‹å€¼è¿˜ä½œä¸ºquery

### æ€»ç»“

- transformeræ˜¯ä¸€ä¸ªçº¯ä½¿ç”¨æ³¨æ„åŠ›çš„encoder-decoder
- ç¼–ç å™¨å’Œè§£ç å™¨éƒ½æœ‰nä¸ªtransformerå—
- æ¯ä¸ªå—é‡Œé¢ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›ï¼ŒåŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œï¼Œå±‚å½’ä¸€åŒ–

### QA

- å¤šå¤´æ³¨æ„åŠ›ï¼Œconcatå’Œç›¸åŠ å–å¹³å‡æ€ä¹ˆé€‰æ‹©ï¼Ÿ
  - è€å¸ˆè®¤ä¸ºconcatä¿ç•™çš„ä¿¡æ¯æ›´å…¨é¢ï¼Œæ›´å¥½
- ä¸ºä»€ä¹ˆåœ¨è·å–è¯å‘é‡ä¹‹åï¼Œéœ€è¦å¯¹è¯å‘é‡è¿›è¡Œç¼©æ”¾ï¼ˆä¹˜ä»¥embedding sizeçš„å¼€æ–¹ä¹‹åå†åŠ ä¸ŠPEï¼‰
  - embeddingä¹‹åï¼Œå‘é‡é•¿åº¦å˜é•¿ï¼Œå…ƒç´ å€¼å˜å°ï¼Œä¹˜ä»¥ä¹‹åå¯ä»¥ä¿è¯åœ¨-1ï¼Œ1ä¹‹é—´ï¼Œå’Œpositionå¤§å°å·®ä¸å¤š
- num of headæ˜¯ä»€ä¹ˆï¼Ÿ
  - ç±»ä¼¼å·ç§¯çš„å¤šé€šé“ï¼Œå¤šä¸ªattentionå…³æ³¨çš„æ˜¯ä¸åŒçš„ç‰¹å¾



# è‡ªç„¶è¯­è¨€å¤„ç†

## bert

#### NLPé‡Œçš„è¿ç§»å­¦ä¹ 

- ä½¿ç”¨é¢„è®­ç»ƒå¥½çš„æ¨¡å‹æ¥æŠ½å–è¯ï¼Œå¥å­çš„ç‰¹å¾
  - ä¾‹å¦‚word2vecæˆ–è¯­è¨€æ¨¡å‹
- ä¸æ›´æ–°é¢„è®­ç»ƒå¥½çš„æ¨¡å‹
- éœ€è¦æ„å»ºæ–°çš„ç½‘ç»œæ¥æŠ“å–ä»»åŠ¡éœ€è¦çš„ä¿¡æ¯
  - Word2vecå¿½ç•¥äº†æ—¶åºä¿¡æ¯
  - è¯­è¨€æ¨¡å‹åªçœ‹äº†ä¸€ä¸ªæ–¹å‘

#### BERTçš„åŠ¨æœº

- åŸºäºå¾®è°ƒçš„NLPæ¨¡å‹
- é¢„è®­ç»ƒçš„æ¨¡å‹æŠ½å–äº†è¶³å¤Ÿå¤šçš„ä¿¡æ¯
- æ–°çš„ä»»åŠ¡åªéœ€è¦å¢åŠ ä¸€ä¸ªç®€å•åœ°è¾“å‡ºå±‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/69/69-1.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/69/69-1.png)

#### BERTæ¶æ„

- åªæœ‰ç¼–ç å™¨çš„Transformer
- ä¸¤ä¸ªç‰ˆæœ¬ï¼š
  - Base:#blocks=12,hidden size=768,#heads=12,#parameters=110M
  - Large:#blocks=24,hidden size=1024,#heads=16,#paramerter=340M
- åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šè®­ç»ƒ>3Bè¯

#### å¯¹è¾“å…¥çš„ä¿®æ”¹

- æ¯ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªå¥å­å¯¹
- åŠ å…¥é¢å¤–çš„ç‰‡æ®µåµŒå…¥
- ä½ç½®ç¼–ç å¯å­¦ä¹ 

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/69/69-2.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/69/69-2.png)

#### é¢„è®­ç»ƒä»»åŠ¡

#####  å¸¦æ©ç çš„è¯­è¨€æ¨¡å‹

- Transformerçš„ç¼–ç å™¨æ˜¯åŒå‘çš„ï¼Œæ ‡å‡†è¯­è¨€æ¨¡å‹è¦æ±‚å•å‘
- å¸¦æ©ç çš„è¯­è¨€æ¨¡å‹æ¯æ¬¡éšæœºï¼ˆ15%æ¦‚ç‡ï¼‰å°†ä¸€äº›è¯å…ƒæ¢æˆ
- [![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/57/57-5.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/57/57-5.png)

##### ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹

- é¢„æµ‹ä¸€ä¸ªå¥å­å¯¹ä¸­ä¸¤ä¸ªå¥å­æ˜¯ä¸æ˜¯ç›¸é‚»
- è®­ç»ƒæ ·æœ¬ä¸­ï¼š
  - 50%æ¦‚ç‡é€‰æ‹©ç›¸é‚»å¥å­å¯¹ï¼šthis movie is great i like it
  - 50%æ¦‚ç‡é€‰æ‹©éšæœºå¥å­å¯¹ï¼šthis movie is great hello world
- å°†å¯¹åº”çš„è¾“å‡ºæ”¾åˆ°ä¸€ä¸ªå…¨è¿æ¥å±‚æ¥é¢„æµ‹

#### æ€»ç»“

- BERTé’ˆå¯¹å¾®è°ƒè®¾è®¡
- åŸºäºTransformerçš„ç¼–ç å™¨åšäº†å¦‚ä¸‹ä¿®æ”¹
  - æ¨¡å‹æ›´å¤§ï¼Œè®­ç»ƒæ•°æ®æ›´å¤š
  - è¾“å…¥å¥å­å¯¹ï¼Œç‰‡æ®µåµŒå…¥ï¼Œå¯å­¦ä¹ çš„ä½ç½®ç¼–ç 
  - è®­ç»ƒæ—¶ä½¿ç”¨ä¸¤ä¸ªä»»åŠ¡ï¼š
    - å¸¦æ©ç çš„è¯­è¨€æ¨¡å‹
    - ä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹

### ä»£ç å®ç°

#### è·å–è¾“å…¥ï¼š

åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œæœ‰äº›ä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æï¼‰ä»¥å•ä¸ªæ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œè€Œæœ‰äº›ä»»åŠ¡ï¼ˆå¦‚è‡ªç„¶è¯­è¨€æ¨æ–­ï¼‰ä»¥ä¸€å¯¹æ–‡æœ¬åºåˆ—ä½œä¸ºè¾“å…¥ã€‚BERTè¾“å…¥åºåˆ—æ˜ç¡®åœ°è¡¨ç¤ºå•ä¸ªæ–‡æœ¬å’Œæ–‡æœ¬å¯¹ã€‚å½“è¾“å…¥ä¸ºå•ä¸ªæ–‡æœ¬æ—¶ï¼ŒBERTè¾“å…¥åºåˆ—æ˜¯ç‰¹æ®Šç±»åˆ«è¯å…ƒâ€œâ€ã€æ–‡æœ¬åºåˆ—çš„æ ‡è®°ã€ä»¥åŠç‰¹æ®Šåˆ†éš”è¯å…ƒâ€œâ€çš„è¿ç»“ã€‚å½“è¾“å…¥ä¸ºæ–‡æœ¬å¯¹æ—¶ï¼ŒBERTè¾“å…¥åºåˆ—æ˜¯â€œâ€ã€ç¬¬ä¸€ä¸ªæ–‡æœ¬åºåˆ—çš„æ ‡è®°ã€â€œâ€ã€ç¬¬äºŒä¸ªæ–‡æœ¬åºåˆ—æ ‡è®°ã€ä»¥åŠâ€œâ€çš„è¿ç»“ã€‚æˆ‘ä»¬å°†å§‹ç»ˆå¦‚ä¸€åœ°å°†æœ¯è¯­â€œBERTè¾“å…¥åºåˆ—â€ä¸å…¶ä»–ç±»å‹çš„â€œåºåˆ—â€åŒºåˆ†å¼€æ¥ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ª*BERTè¾“å…¥åºåˆ—*å¯ä»¥åŒ…æ‹¬ä¸€ä¸ª*æ–‡æœ¬åºåˆ—*æˆ–ä¸¤ä¸ª*æ–‡æœ¬åºåˆ—*ã€‚

ä¸ºäº†åŒºåˆ†æ–‡æœ¬å¯¹ï¼Œæ ¹æ®è¾“å…¥åºåˆ—å­¦åˆ°çš„ç‰‡æ®µåµŒå…¥eAå’ŒeBåˆ†åˆ«è¢«æ·»åŠ åˆ°ç¬¬ä¸€åºåˆ—å’Œç¬¬äºŒåºåˆ—çš„è¯å…ƒåµŒå…¥ä¸­ã€‚å¯¹äºå•æ–‡æœ¬è¾“å…¥ï¼Œä»…ä½¿ç”¨eAã€‚

ä¸‹é¢çš„`get_tokens_and_segments`å°†ä¸€ä¸ªå¥å­æˆ–ä¸¤ä¸ªå¥å­ä½œä¸ºè¾“å…¥ï¼Œç„¶åè¿”å›BERTè¾“å…¥åºåˆ—çš„æ ‡è®°åŠå…¶ç›¸åº”çš„ç‰‡æ®µç´¢å¼•ã€‚

```
 def get_tokens_and_segments(tokens_a, tokens_b=None):
    """è·å–è¾“å…¥åºåˆ—çš„è¯å…ƒåŠå…¶ç‰‡æ®µç´¢å¼•"""
    tokens = ['<cls>'] + tokens_a + ['<sep>']
    # 0å’Œ1åˆ†åˆ«æ ‡è®°ç‰‡æ®µAå’ŒB
    segments = [0] * (len(tokens_a) + 2)
    if tokens_b is not None:
        tokens += tokens_b + ['<sep>']
        segments += [1] * (len(tokens_b) + 1)
    return tokens, segments
```

BERTé€‰æ‹©Transformerç¼–ç å™¨ä½œä¸ºå…¶åŒå‘æ¶æ„ã€‚åœ¨Transformerç¼–ç å™¨ä¸­å¸¸è§æ˜¯ï¼Œä½ç½®åµŒå…¥è¢«åŠ å…¥åˆ°è¾“å…¥åºåˆ—çš„æ¯ä¸ªä½ç½®ã€‚ç„¶è€Œï¼Œä¸åŸå§‹çš„Transformerç¼–ç å™¨ä¸åŒï¼ŒBERTä½¿ç”¨*å¯å­¦ä¹ çš„*ä½ç½®åµŒå…¥ã€‚æ€»ä¹‹ï¼Œ ä¸‹å›¾è¡¨æ˜BERTè¾“å…¥åºåˆ—çš„åµŒå…¥æ˜¯è¯å…ƒåµŒå…¥ã€ç‰‡æ®µåµŒå…¥å’Œä½ç½®åµŒå…¥çš„å’Œã€‚

[![image](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/raw/main/imgs/69/69-3.png)](https://github.com/MLNLP-World/DeepLearning-MuLi-Notes/blob/main/imgs/69/69-3.png)

#### BERTå®ç°

ä¸‹é¢çš„`BERTEncoder`ç±»ç±»ä¼¼äº [10.7èŠ‚](https://zh-v2.d2l.ai/chapter_attention-mechanisms/transformer.html#sec-transformer)ä¸­å®ç°çš„`TransformerEncoder`ç±»ã€‚ä¸`TransformerEncoder`ä¸åŒï¼Œ`BERTEncoder`ä½¿ç”¨ç‰‡æ®µåµŒå…¥å’Œå¯å­¦ä¹ çš„ä½ç½®åµŒå…¥ã€‚

```
#@save
class BERTEncoder(nn.Module):
    """BERTç¼–ç å™¨"""
    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,
                 ffn_num_hiddens, num_heads, num_layers, dropout,
                 max_len=1000, key_size=768, query_size=768, value_size=768,
                 **kwargs):
        super(BERTEncoder, self).__init__(**kwargs)
        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)
        self.segment_embedding = nn.Embedding(2, num_hiddens)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module(f"{i}", d2l.EncoderBlock(
                key_size, query_size, value_size, num_hiddens, norm_shape,
                ffn_num_input, ffn_num_hiddens, num_heads, dropout, True))
        # åœ¨BERTä¸­ï¼Œä½ç½®åµŒå…¥æ˜¯å¯å­¦ä¹ çš„ï¼Œå› æ­¤æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè¶³å¤Ÿé•¿çš„ä½ç½®åµŒå…¥å‚æ•°
        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,
                                                      num_hiddens))

    def forward(self, tokens, segments, valid_lens):
        # åœ¨ä»¥ä¸‹ä»£ç æ®µä¸­ï¼ŒXçš„å½¢çŠ¶ä¿æŒä¸å˜ï¼šï¼ˆæ‰¹é‡å¤§å°ï¼Œæœ€å¤§åºåˆ—é•¿åº¦ï¼Œnum_hiddensï¼‰
        X = self.token_embedding(tokens) + self.segment_embedding(segments)
        X = X + self.pos_embedding.data[:, :X.shape[1], :]
        for blk in self.blks:
            X = blk(X, valid_lens)
        return X
```



å‡è®¾è¯è¡¨å¤§å°ä¸º10000ï¼Œä¸ºäº†æ¼”ç¤º`BERTEncoder`çš„å‰å‘æ¨æ–­ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå®ä¾‹å¹¶åˆå§‹åŒ–å®ƒçš„å‚æ•°ã€‚

```
vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4
norm_shape, ffn_num_input, num_layers, dropout = [768], 768, 2, 0.2
encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input,
                      ffn_num_hiddens, num_heads, num_layers, dropout)
```



æˆ‘ä»¬å°†`tokens`å®šä¹‰ä¸ºé•¿åº¦ä¸º8çš„2ä¸ªè¾“å…¥åºåˆ—ï¼Œå…¶ä¸­æ¯ä¸ªè¯å…ƒæ˜¯è¯è¡¨çš„ç´¢å¼•ã€‚ä½¿ç”¨è¾“å…¥`tokens`çš„`BERTEncoder`çš„å‰å‘æ¨æ–­è¿”å›ç¼–ç ç»“æœï¼Œå…¶ä¸­æ¯ä¸ªè¯å…ƒç”±å‘é‡è¡¨ç¤ºï¼Œå…¶é•¿åº¦ç”±è¶…å‚æ•°`num_hiddens`å®šä¹‰ã€‚æ­¤è¶…å‚æ•°é€šå¸¸ç§°ä¸ºTransformerç¼–ç å™¨çš„*éšè—å¤§å°*ï¼ˆéšè—å•å…ƒæ•°ï¼‰

```
tokens = torch.randint(0, vocab_size, (2, 8))
segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])
encoded_X = encoder(tokens, segments, None)
encoded_X.shape
```

#### é¢„è®­ç»ƒä»»åŠ¡

##### é®æ©è¯­è¨€æ¨¡å‹

æˆ‘ä»¬å®ç°äº†ä¸‹é¢çš„`MaskLM`ç±»æ¥é¢„æµ‹BERTé¢„è®­ç»ƒçš„æ©è”½è¯­è¨€æ¨¡å‹ä»»åŠ¡ä¸­çš„æ©è”½æ ‡è®°ã€‚é¢„æµ‹ä½¿ç”¨å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ˆ`self.mlp`ï¼‰ã€‚åœ¨å‰å‘æ¨æ–­ä¸­ï¼Œå®ƒéœ€è¦ä¸¤ä¸ªè¾“å…¥ï¼š`BERTEncoder`çš„ç¼–ç ç»“æœå’Œç”¨äºé¢„æµ‹çš„è¯å…ƒä½ç½®ã€‚è¾“å‡ºæ˜¯è¿™äº›ä½ç½®çš„é¢„æµ‹ç»“æœã€‚

```
#@save
class MaskLM(nn.Module):
    """BERTçš„æ©è”½è¯­è¨€æ¨¡å‹ä»»åŠ¡"""
    def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs):
        super(MaskLM, self).__init__(**kwargs)
        self.mlp = nn.Sequential(nn.Linear(num_inputs, num_hiddens),
                                 nn.ReLU(),
                                 nn.LayerNorm(num_hiddens),
                                 nn.Linear(num_hiddens, vocab_size))

    def forward(self, X, pred_positions):
        num_pred_positions = pred_positions.shape[1]
        pred_positions = pred_positions.reshape(-1)
        batch_size = X.shape[0]
        batch_idx = torch.arange(0, batch_size)
        # å‡è®¾batch_size=2ï¼Œnum_pred_positions=3
        # é‚£ä¹ˆbatch_idxæ˜¯np.arrayï¼ˆ[0,0,0,1,1]ï¼‰
        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)
        masked_X = X[batch_idx, pred_positions]
        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))
        mlm_Y_hat = self.mlp(masked_X)
        return mlm_Y_hat
```



ä¸ºäº†æ¼”ç¤º`MaskLM`çš„å‰å‘æ¨æ–­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†å…¶å®ä¾‹`mlm`å¹¶å¯¹å…¶è¿›è¡Œäº†åˆå§‹åŒ–ã€‚å›æƒ³ä¸€ä¸‹ï¼Œæ¥è‡ª`BERTEncoder`çš„æ­£å‘æ¨æ–­`encoded_X`è¡¨ç¤º2ä¸ªBERTè¾“å…¥åºåˆ—ã€‚æˆ‘ä»¬å°†`mlm_positions`å®šä¹‰ä¸ºåœ¨`encoded_X`çš„ä»»ä¸€è¾“å…¥åºåˆ—ä¸­é¢„æµ‹çš„3ä¸ªæŒ‡ç¤ºã€‚`mlm`çš„å‰å‘æ¨æ–­è¿”å›`encoded_X`çš„æ‰€æœ‰æ©è”½ä½ç½®`mlm_positions`å¤„çš„é¢„æµ‹ç»“æœ`mlm_Y_hat`ã€‚å¯¹äºæ¯ä¸ªé¢„æµ‹ï¼Œç»“æœçš„å¤§å°ç­‰äºè¯è¡¨çš„å¤§å°ã€‚

```
mlm = MaskLM(vocab_size, num_hiddens)
mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])
mlm_Y_hat = mlm(encoded_X, mlm_positions)
mlm_Y_hat.shape
```



é€šè¿‡æ©ç ä¸‹çš„é¢„æµ‹è¯å…ƒ`mlm_Y`çš„çœŸå®æ ‡ç­¾`mlm_Y_hat`ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—åœ¨BERTé¢„è®­ç»ƒä¸­çš„é®è”½è¯­è¨€æ¨¡å‹ä»»åŠ¡çš„äº¤å‰ç†µæŸå¤±ã€‚

```
mlm_Y = torch.tensor([[7, 8, 9], [10, 20, 30]])
loss = nn.CrossEntropyLoss(reduction='none')
mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))
mlm_l.shape
```

#####  ä¸‹ä¸€å¥é¢„æµ‹

ä¸‹é¢çš„`NextSentencePred`ç±»ä½¿ç”¨å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœºæ¥é¢„æµ‹ç¬¬äºŒä¸ªå¥å­æ˜¯å¦æ˜¯BERTè¾“å…¥åºåˆ—ä¸­ç¬¬ä¸€ä¸ªå¥å­çš„ä¸‹ä¸€ä¸ªå¥å­ã€‚ç”±äºTransformerç¼–ç å™¨ä¸­çš„è‡ªæ³¨æ„åŠ›ï¼Œç‰¹æ®Šè¯å…ƒâ€œâ€çš„BERTè¡¨ç¤ºå·²ç»å¯¹è¾“å…¥çš„ä¸¤ä¸ªå¥å­è¿›è¡Œäº†ç¼–ç ã€‚å› æ­¤ï¼Œå¤šå±‚æ„ŸçŸ¥æœºåˆ†ç±»å™¨çš„è¾“å‡ºå±‚ï¼ˆ`self.output`ï¼‰ä»¥`X`ä½œä¸ºè¾“å…¥ï¼Œå…¶ä¸­`X`æ˜¯å¤šå±‚æ„ŸçŸ¥æœºéšè—å±‚çš„è¾“å‡ºï¼Œè€ŒMLPéšè—å±‚çš„è¾“å…¥æ˜¯ç¼–ç åçš„â€œâ€è¯å…ƒã€‚

```
#@save
class NextSentencePred(nn.Module):
    """BERTçš„ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡"""
    def __init__(self, num_inputs, **kwargs):
        super(NextSentencePred, self).__init__(**kwargs)
        self.output = nn.Linear(num_inputs, 2)

    def forward(self, X):
        # Xçš„å½¢çŠ¶ï¼š(batchsize,num_hiddens)
        return self.output(X)
```



æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ`NextSentencePred`å®ä¾‹çš„å‰å‘æ¨æ–­è¿”å›æ¯ä¸ªBERTè¾“å…¥åºåˆ—çš„äºŒåˆ†ç±»é¢„æµ‹ã€‚

```
encoded_X = torch.flatten(encoded_X, start_dim=1)
# NSPçš„è¾“å…¥å½¢çŠ¶:(batchsizeï¼Œnum_hiddens)
nsp = NextSentencePred(encoded_X.shape[-1])
nsp_Y_hat = nsp(encoded_X)
nsp_Y_hat.shape
```

#### æ•´åˆä»£ç 

åœ¨é¢„è®­ç»ƒBERTæ—¶ï¼Œæœ€ç»ˆçš„æŸå¤±å‡½æ•°æ˜¯æ©è”½è¯­è¨€æ¨¡å‹æŸå¤±å‡½æ•°å’Œä¸‹ä¸€å¥é¢„æµ‹æŸå¤±å‡½æ•°çš„çº¿æ€§ç»„åˆã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥é€šè¿‡å®ä¾‹åŒ–ä¸‰ä¸ªç±»`BERTEncoder`ã€`MaskLM`å’Œ`NextSentencePred`æ¥å®šä¹‰`BERTModel`ç±»ã€‚å‰å‘æ¨æ–­è¿”å›ç¼–ç åçš„BERTè¡¨ç¤º`encoded_X`ã€æ©è”½è¯­è¨€æ¨¡å‹é¢„æµ‹`mlm_Y_hat`å’Œä¸‹ä¸€å¥é¢„æµ‹`nsp_Y_hat`ã€‚

```
#@save
class BERTModel(nn.Module):
    """BERTæ¨¡å‹"""
    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,
                 ffn_num_hiddens, num_heads, num_layers, dropout,
                 max_len=1000, key_size=768, query_size=768, value_size=768,
                 hid_in_features=768, mlm_in_features=768,
                 nsp_in_features=768):
        super(BERTModel, self).__init__()
        self.encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape,
                    ffn_num_input, ffn_num_hiddens, num_heads, num_layers,
                    dropout, max_len=max_len, key_size=key_size,
                    query_size=query_size, value_size=value_size)
        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),
                                    nn.Tanh())
        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)
        self.nsp = NextSentencePred(nsp_in_features)

    def forward(self, tokens, segments, valid_lens=None,
                pred_positions=None):
        encoded_X = self.encoder(tokens, segments, valid_lens)
        if pred_positions is not None:
            mlm_Y_hat = self.mlm(encoded_X, pred_positions)
        else:
            mlm_Y_hat = None
        # ç”¨äºä¸‹ä¸€å¥é¢„æµ‹çš„å¤šå±‚æ„ŸçŸ¥æœºåˆ†ç±»å™¨çš„éšè—å±‚ï¼Œ0æ˜¯â€œ<cls>â€æ ‡è®°çš„ç´¢å¼•
        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))
        return encoded_X, mlm_Y_hat, nsp_Y_hat
```

#### å°ç»“

- word2vecå’ŒGloVeç­‰è¯åµŒå…¥æ¨¡å‹ä¸ä¸Šä¸‹æ–‡æ— å…³ã€‚å®ƒä»¬å°†ç›¸åŒçš„é¢„è®­ç»ƒå‘é‡èµ‹ç»™åŒä¸€ä¸ªè¯ï¼Œè€Œä¸è€ƒè™‘è¯çš„ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚å®ƒä»¬å¾ˆéš¾å¤„ç†å¥½è‡ªç„¶è¯­è¨€ä¸­çš„ä¸€è¯å¤šä¹‰æˆ–å¤æ‚è¯­ä¹‰ã€‚
- å¯¹äºä¸Šä¸‹æ–‡æ•æ„Ÿçš„è¯è¡¨ç¤ºï¼Œå¦‚ELMoå’ŒGPTï¼Œè¯çš„è¡¨ç¤ºä¾èµ–äºå®ƒä»¬çš„ä¸Šä¸‹æ–‡ã€‚
- ELMoå¯¹ä¸Šä¸‹æ–‡è¿›è¡ŒåŒå‘ç¼–ç ï¼Œä½†ä½¿ç”¨ç‰¹å®šäºä»»åŠ¡çš„æ¶æ„ï¼ˆç„¶è€Œï¼Œä¸ºæ¯ä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡è®¾è®¡ä¸€ä¸ªç‰¹å®šçš„ä½“ç³»æ¶æ„å®é™…ä¸Šå¹¶ä¸å®¹æ˜“ï¼‰ï¼›è€ŒGPTæ˜¯ä»»åŠ¡æ— å…³çš„ï¼Œä½†æ˜¯ä»å·¦åˆ°å³ç¼–ç ä¸Šä¸‹æ–‡ã€‚
- BERTç»“åˆäº†è¿™ä¸¤ä¸ªæ–¹é¢çš„ä¼˜ç‚¹ï¼šå®ƒå¯¹ä¸Šä¸‹æ–‡è¿›è¡ŒåŒå‘ç¼–ç ï¼Œå¹¶ä¸”éœ€è¦å¯¹å¤§é‡è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡è¿›è¡Œæœ€å°çš„æ¶æ„æ›´æ”¹ã€‚
- BERTè¾“å…¥åºåˆ—çš„åµŒå…¥æ˜¯è¯å…ƒåµŒå…¥ã€ç‰‡æ®µåµŒå…¥å’Œä½ç½®åµŒå…¥çš„å’Œã€‚
- é¢„è®­ç»ƒåŒ…æ‹¬ä¸¤ä¸ªä»»åŠ¡ï¼šæ©è”½è¯­è¨€æ¨¡å‹å’Œä¸‹ä¸€å¥é¢„æµ‹ã€‚å‰è€…èƒ½å¤Ÿç¼–ç åŒå‘ä¸Šä¸‹æ–‡æ¥è¡¨ç¤ºå•è¯ï¼Œè€Œåè€…åˆ™æ˜¾å¼åœ°å»ºæ¨¡æ–‡æœ¬å¯¹ä¹‹é—´çš„é€»è¾‘å…³ç³»ã€‚